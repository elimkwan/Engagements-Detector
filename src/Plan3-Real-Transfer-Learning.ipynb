{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from statistics import mode\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics import f1_score\n",
    "from heapq import * \n",
    "import time\n",
    "import copy\n",
    "\n",
    "#Pytorch\n",
    "import torch\n",
    "import torchvision\n",
    "# import torchvision.transforms as transforms\n",
    "from torchvision import datasets, models, transforms\n",
    "from skimage import io\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader, ConcatDataset\n",
    "from sklearn.model_selection import KFold\n",
    "from scipy import stats\n",
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "\n",
    "import pytorch_model_summary as pms\n",
    "from torchviz import make_dot\n",
    "np.random.seed(42)\n",
    "\n",
    "# import tensorflow as tf\n",
    "NUM_CLASS = 2\n",
    "WINDOW = 5\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, root_dir=None, transform=None):\n",
    "        path = os.path.join(root_dir,'labels.csv')\n",
    "        self.ylabels = pd.read_csv(path)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.ylabels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        seq_len = 5\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    " \n",
    "        label = self.ylabels.iloc[idx,1]\n",
    "        label_str = str(label) + '/'\n",
    "        img_folder = os.path.join(self.root_dir, label_str)\n",
    "        \n",
    "        img_arr = np.zeros((5, 1, 64, 64))\n",
    "        for i in range (5):\n",
    "            img_name = img_folder + str(idx) + '-' + str(i) + '.jpg'\n",
    "            image = io.imread(img_name)\n",
    "            if self.transform:\n",
    "                image = self.transform(image)\n",
    "            img_arr[i][0] = image\n",
    "            \n",
    "        label_1hot = np.zeros(NUM_CLASS)\n",
    "        label_1hot[label] = 1.0\n",
    "        label_1hot = torch.Tensor(label_1hot)\n",
    "#         label = np.array([label])\n",
    "        label = torch.LongTensor(np.array([label]))\n",
    "        sample = {'images': img_arr, 'label': label_1hot}\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": [
     5,
     10,
     47
    ]
   },
   "outputs": [],
   "source": [
    "class Reshape1(torch.nn.Module):\n",
    "    def forward(self, x):\n",
    "        batch_size = torch.Size([1,5,1,64,64])\n",
    "        return x.view(batch_size, -1)\n",
    "    \n",
    "class Reshape2(torch.nn.Module):\n",
    "    def forward(self, x):\n",
    "        batch_size = torch.Size([1,1,64,64])\n",
    "        return x.view(batch_size, -1)\n",
    "\n",
    "def build_encoder():\n",
    "    encoder = nn.Sequential(\n",
    "        nn.Conv2d(in_channels=1, out_channels=192, kernel_size=3),\n",
    "        nn.BatchNorm2d(num_features=192),\n",
    "        nn.ReLU(),\n",
    "        nn.Conv2d(in_channels=192, out_channels=192, kernel_size=1),\n",
    "        nn.ReLU(),\n",
    "        \n",
    "        nn.Conv2d(in_channels=192, out_channels=192, kernel_size=3, stride=2),\n",
    "        nn.BatchNorm2d(num_features=192),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(p=0.5),\n",
    "        \n",
    "        nn.Conv2d(in_channels=192, out_channels=96, kernel_size=3),\n",
    "        nn.BatchNorm2d(num_features=96),\n",
    "        nn.ReLU(),\n",
    "        nn.Conv2d(in_channels=96, out_channels=96, kernel_size=1),\n",
    "        nn.ReLU(),\n",
    "        nn.Conv2d(in_channels=96, out_channels=96, kernel_size=1),\n",
    "        nn.ReLU(),\n",
    "        \n",
    "#         nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "        nn.Conv2d(in_channels=96, out_channels=96, kernel_size=3, stride=2),\n",
    "        nn.Dropout(p=0.3),\n",
    "        \n",
    "        nn.Conv2d(in_channels=96, out_channels=32, kernel_size=3),\n",
    "        nn.BatchNorm2d(num_features=32),\n",
    "        nn.ReLU(),\n",
    "        nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3),\n",
    "        nn.BatchNorm2d(num_features=32),\n",
    "        nn.ReLU(),\n",
    "#         nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, padding=2),\n",
    "#         nn.BatchNorm2d(num_features=32),\n",
    "#         nn.ReLU()\n",
    "    )\n",
    "    return encoder\n",
    "\n",
    "def build_decoder():\n",
    "    decoder = nn.Sequential(\n",
    "        nn.Conv2d(in_channels=32, out_channels=NUM_CLASS, kernel_size=1),\n",
    "        nn.AdaptiveAvgPool2d((1,1)),\n",
    "        nn.Softmax(dim=1)\n",
    "    )\n",
    "    return decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super(Net, self).__init__()\n",
    "        self.in_encoder = encoder\n",
    "        self.in_decoder = decoder\n",
    "        \n",
    "    def forward(self, x):\n",
    "        tmp = self.in_encoder(x)\n",
    "        y = self.in_decoder(tmp)\n",
    "        return y\n",
    "    def encoder(self, x):\n",
    "        return self.in_encoder(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def check_validation(model, valloader, loss_function):\n",
    "    # Evaluationfor this fold\n",
    "    correct, total = 0, 0\n",
    "    current_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        # Init the neural network\n",
    "        encoder = build_encoder()\n",
    "        decoder = build_decoder()\n",
    "        trained_net = Net(encoder, decoder)\n",
    "        trained_net.load_state_dict(model)\n",
    "        trained_net.to(device)\n",
    "\n",
    "        # Iterate over the test data and generate predictions\n",
    "        for i, data in enumerate(valloader, 0):\n",
    "\n",
    "            # Get inputs\n",
    "            inputs = data['images']\n",
    "            targets = data['label']\n",
    "\n",
    "            outputs = None\n",
    "            for index, xbatch in enumerate(inputs):\n",
    "\n",
    "                xbatch = xbatch.float().to(device)\n",
    "                output = sliding_window(xbatch, trained_net)\n",
    "\n",
    "                # Perform forward pass\n",
    "#                 output = trained_net(xbatch)\n",
    "                if index == 0:\n",
    "                    outputs = output\n",
    "                else:\n",
    "                    outputs = torch.vstack([outputs, output])\n",
    "\n",
    "            # Compute loss\n",
    "            ybatches = targets.to(device)\n",
    "            outputs = torch.reshape(outputs, (ybatches.shape[0],NUM_CLASS))\n",
    "            ybatches.squeeze_(1)\n",
    "            loss = loss_function(outputs, ybatches)\n",
    "            current_loss += loss.item()\n",
    "\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            _, truth = torch.max(ybatches, 1)\n",
    "            total += targets.size(0)\n",
    "            correct += (predicted == truth).sum().item()\n",
    "    val_loss = current_loss/(i+1)\n",
    "    val_acc = 100.0 * correct / total\n",
    "    return val_loss, val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def sliding_window(x, network):         \n",
    "    outputs = network(x)\n",
    "    outputs = torch.reshape(outputs,(-1,2))\n",
    "    final_out = torch.mean(outputs, 0)\n",
    "    return final_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoder = build_encoder()\n",
    "# decoder = build_decoder()\n",
    "# net = Net(encoder, decoder)\n",
    "# pms.summary(net, \n",
    "#     torch.zeros((1,1,64,64)), \n",
    "#     batch_size=1, \n",
    "#     show_hierarchical=True, \n",
    "#     print_summary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def train():\n",
    "    #---------------Config---------------\n",
    "    torch.manual_seed(42)\n",
    "    num_epochs = 50\n",
    "    k_folds = 5\n",
    "    patience = 10\n",
    "    batch_size = 32\n",
    "    #---------------Config---------------\n",
    "    \n",
    "    # Preparation\n",
    "    weight = torch.tensor([1,1]).to(device)\n",
    "    \n",
    "    loss_function = nn.BCELoss(weight=weight)\n",
    "\n",
    "    transformer = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5), (0.5)),\n",
    "    ])\n",
    "\n",
    "    train_data_dir = './Prepared_Data/Train/'\n",
    "    train_dataset = MyDataset(root_dir=train_data_dir, transform = transformer)\n",
    "\n",
    "    val_data_dir = './Prepared_Data/Validation/'\n",
    "    val_dataset = MyDataset(root_dir=val_data_dir, transform = transformer)\n",
    "\n",
    "    dataset = ConcatDataset([train_dataset, val_dataset])\n",
    "\n",
    "    kfold = KFold(n_splits=k_folds, shuffle=True)\n",
    "    \n",
    "    results = {}\n",
    "\n",
    "    # K-fold Cross Validation model evaluation\n",
    "    for fold, (train_ids, val_ids) in enumerate(kfold.split(dataset)):\n",
    "        training_details = []\n",
    "        best_model = None\n",
    "\n",
    "        # Print\n",
    "        print(f'FOLD {fold}')\n",
    "        print('--------------------------------')\n",
    "\n",
    "        # Sample elements randomly from a given list of ids, no replacement.\n",
    "        train_subsampler = torch.utils.data.SubsetRandomSampler(train_ids)\n",
    "        val_subsampler = torch.utils.data.SubsetRandomSampler(val_ids)\n",
    "\n",
    "        # Define data loaders for training and testing data in this fold\n",
    "        trainloader = torch.utils.data.DataLoader(\n",
    "                        dataset,\n",
    "                        batch_size=batch_size, sampler=train_subsampler)\n",
    "        valloader = torch.utils.data.DataLoader(\n",
    "                        dataset,\n",
    "                        batch_size=batch_size, sampler=val_subsampler)\n",
    "\n",
    "        # Init the neural network\n",
    "        encoder = build_encoder()\n",
    "        decoder = build_decoder()\n",
    "        network = Net(encoder, decoder)\n",
    "        network.to(device) #use GPU\n",
    "        use_gpu = True\n",
    "\n",
    "        # Initialize optimizer\n",
    "        optimizer = optim.Adam(network.parameters(), lr=0.001)\n",
    "        max_train_acc, max_val_acc = 0, 0\n",
    "        early_stop_count = 0\n",
    "        # Run the training loop for defined number of epochs\n",
    "        for epoch in range(0, num_epochs):\n",
    "\n",
    "            correct, total = 0, 0\n",
    "            # Print epoch\n",
    "            print(f'Starting epoch {epoch+1}')\n",
    "            # Set current loss value\n",
    "            current_loss = 0.0\n",
    "            epoch_loss = 0.0\n",
    "            # Iterate over the DataLoader for training data\n",
    "            for i, data in enumerate(trainloader, 0):\n",
    "            # Starting 1 cycle of mini-batch\n",
    "\n",
    "                # Get inputs\n",
    "                inputs = data['images']\n",
    "                targets = data['label']\n",
    "\n",
    "                outputs = None\n",
    "                for index, xbatch in enumerate(inputs):\n",
    "                    # Zero the gradients\n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "                    xbatch = xbatch.float().to(device)\n",
    "                    output = sliding_window(xbatch, network)\n",
    "\n",
    "                    # Perform forward pass\n",
    "                    if index == 0:\n",
    "                        outputs = output\n",
    "                    else:\n",
    "                        outputs = torch.vstack([outputs, output])\n",
    "\n",
    "                # Compute loss\n",
    "                ybatches = targets.to(device)\n",
    "                outputs = torch.reshape(outputs, (ybatches.shape[0],NUM_CLASS))\n",
    "                loss = loss_function(outputs, ybatches)\n",
    "\n",
    "                # Perform backward pass\n",
    "                loss.backward()\n",
    "\n",
    "                # Perform optimization\n",
    "                optimizer.step()\n",
    "\n",
    "                # Print statistics\n",
    "                current_loss += loss.item()\n",
    "                epoch_loss += loss.item()\n",
    "\n",
    "                # Compute Accuracy\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                _, truth = torch.max(ybatches, 1)\n",
    "                total += targets.size(0)\n",
    "                correct += (predicted == truth).sum().item()\n",
    "\n",
    "            epoch_loss = epoch_loss/(i+1)\n",
    "            epoch_acc = 100.0 * correct / total\n",
    "            print('Train Loss for Epoch %d: %.4f ' % (epoch, epoch_loss))\n",
    "            print('Train Accuracy for Epoch %d: %.2f %%' % (epoch, epoch_acc))\n",
    "            val_loss, val_acc = check_validation(network.state_dict(), valloader, loss_function)\n",
    "            print('Val Loss for Epoch %d: %.4f ' % (epoch, val_loss))\n",
    "            print('Val Accuracy for Epoch %d: %.2f %%' % (epoch, val_acc))\n",
    "            print('--------------------------------')\n",
    "\n",
    "            training_details.append([epoch_acc, epoch_loss, val_acc, val_loss])\n",
    "\n",
    "            stop_improving = False\n",
    "            if val_acc > max_val_acc:\n",
    "                max_val_acc = val_acc\n",
    "                early_stop_count = 0\n",
    "            else:\n",
    "                early_stop_count += 1\n",
    "                stop_improving = True\n",
    "                print(\"Early Stop Count Increased\")\n",
    "\n",
    "            if epoch_acc > max_train_acc and not stop_improving:\n",
    "                max_train_acc = copy.deepcopy(epoch_acc)\n",
    "                best_model = copy.deepcopy(network.state_dict())\n",
    "                print(\"Found better model...saving\")\n",
    "            \n",
    "            print(\"Early Stop Count\", early_stop_count)\n",
    "            if early_stop_count >= patience:\n",
    "                print(\"Early stopping at Epoch\", epoch)\n",
    "                break\n",
    "\n",
    "\n",
    "        # Process is complete.\n",
    "        print('Training process has finished. Saving trained model.')\n",
    "\n",
    "        # Print about testing\n",
    "        print('Starting testing')\n",
    "\n",
    "        # Saving the model\n",
    "        save_path = f'./models/model-fold-{fold}.pth'\n",
    "        save_path_csv = f'./models/model-fold-{fold}.csv'\n",
    "        torch.save(best_model, save_path)\n",
    "\n",
    "        training_details = np.array(training_details)\n",
    "        df = {'epoch acc': training_details[:,0], \n",
    "              'epoch loss': training_details[:,1], \n",
    "              'val acc': training_details[:,2], \n",
    "              'val loss': training_details[:,3], }\n",
    "        pd.DataFrame(df).to_csv(save_path_csv)\n",
    "\n",
    "        # Evaluationfor this fold\n",
    "        correct, total = 0, 0\n",
    "        with torch.no_grad():\n",
    "            val_loss, val_acc = check_validation(torch.load(save_path), valloader, loss_function)\n",
    "            # Print accuracy\n",
    "            print('Accuracy for fold %d: %.2f %%' % (fold, val_acc))\n",
    "            print('--------------------------------')\n",
    "            results[fold] = val_acc\n",
    "\n",
    "    # Print fold results\n",
    "    print(f'K-FOLD CROSS VALIDATION RESULTS FOR {k_folds} FOLDS')\n",
    "    print('--------------------------------')\n",
    "    sum = 0.0\n",
    "    for key, value in results.items():\n",
    "        print(f'Fold {key}: {value} %')\n",
    "        sum += value\n",
    "    print(f'Average: {sum/len(results.items())} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "--------------------------------\n",
      "Starting epoch 1\n",
      "Train Loss for Epoch 0: 0.6944 \n",
      "Train Accuracy for Epoch 0: 54.47 %\n",
      "Val Loss for Epoch 0: 0.6823 \n",
      "Val Accuracy for Epoch 0: 82.22 %\n",
      "--------------------------------\n",
      "Found better model...saving\n",
      "Early Stop Count 0\n",
      "Starting epoch 2\n",
      "Train Loss for Epoch 1: 0.6751 \n",
      "Train Accuracy for Epoch 1: 77.09 %\n",
      "Val Loss for Epoch 1: 0.6571 \n",
      "Val Accuracy for Epoch 1: 78.89 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Early Stop Count 1\n",
      "Starting epoch 3\n",
      "Train Loss for Epoch 2: 0.6551 \n",
      "Train Accuracy for Epoch 2: 78.21 %\n",
      "Val Loss for Epoch 2: 0.6389 \n",
      "Val Accuracy for Epoch 2: 80.00 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Early Stop Count 2\n",
      "Starting epoch 4\n",
      "Train Loss for Epoch 3: 0.6391 \n",
      "Train Accuracy for Epoch 3: 80.45 %\n",
      "Val Loss for Epoch 3: 0.6187 \n",
      "Val Accuracy for Epoch 3: 85.56 %\n",
      "--------------------------------\n",
      "Found better model...saving\n",
      "Early Stop Count 0\n",
      "Starting epoch 5\n",
      "Train Loss for Epoch 4: 0.6187 \n",
      "Train Accuracy for Epoch 4: 83.80 %\n",
      "Val Loss for Epoch 4: 0.5862 \n",
      "Val Accuracy for Epoch 4: 86.67 %\n",
      "--------------------------------\n",
      "Found better model...saving\n",
      "Early Stop Count 0\n",
      "Starting epoch 6\n",
      "Train Loss for Epoch 5: 0.5924 \n",
      "Train Accuracy for Epoch 5: 84.08 %\n",
      "Val Loss for Epoch 5: 0.6010 \n",
      "Val Accuracy for Epoch 5: 82.22 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Early Stop Count 1\n",
      "Starting epoch 7\n",
      "Train Loss for Epoch 6: 0.5692 \n",
      "Train Accuracy for Epoch 6: 84.64 %\n",
      "Val Loss for Epoch 6: 0.5490 \n",
      "Val Accuracy for Epoch 6: 86.67 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Early Stop Count 2\n",
      "Starting epoch 8\n",
      "Train Loss for Epoch 7: 0.5369 \n",
      "Train Accuracy for Epoch 7: 82.96 %\n",
      "Val Loss for Epoch 7: 0.5104 \n",
      "Val Accuracy for Epoch 7: 88.89 %\n",
      "--------------------------------\n",
      "Early Stop Count 0\n",
      "Starting epoch 9\n",
      "Train Loss for Epoch 8: 0.4962 \n",
      "Train Accuracy for Epoch 8: 89.11 %\n",
      "Val Loss for Epoch 8: 0.4695 \n",
      "Val Accuracy for Epoch 8: 88.89 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Early Stop Count 1\n",
      "Starting epoch 10\n",
      "Train Loss for Epoch 9: 0.4741 \n",
      "Train Accuracy for Epoch 9: 87.15 %\n",
      "Val Loss for Epoch 9: 0.4609 \n",
      "Val Accuracy for Epoch 9: 84.44 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Early Stop Count 2\n",
      "Starting epoch 11\n",
      "Train Loss for Epoch 10: 0.4287 \n",
      "Train Accuracy for Epoch 10: 91.34 %\n",
      "Val Loss for Epoch 10: 0.4044 \n",
      "Val Accuracy for Epoch 10: 92.22 %\n",
      "--------------------------------\n",
      "Found better model...saving\n",
      "Early Stop Count 0\n",
      "Starting epoch 12\n",
      "Train Loss for Epoch 11: 0.4033 \n",
      "Train Accuracy for Epoch 11: 92.46 %\n",
      "Val Loss for Epoch 11: 0.3870 \n",
      "Val Accuracy for Epoch 11: 93.33 %\n",
      "--------------------------------\n",
      "Found better model...saving\n",
      "Early Stop Count 0\n",
      "Starting epoch 13\n",
      "Train Loss for Epoch 12: 0.3703 \n",
      "Train Accuracy for Epoch 12: 90.50 %\n",
      "Val Loss for Epoch 12: 0.3614 \n",
      "Val Accuracy for Epoch 12: 91.11 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Early Stop Count 1\n",
      "Starting epoch 14\n",
      "Train Loss for Epoch 13: 0.3305 \n",
      "Train Accuracy for Epoch 13: 91.62 %\n",
      "Val Loss for Epoch 13: 0.4023 \n",
      "Val Accuracy for Epoch 13: 81.11 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Early Stop Count 2\n",
      "Starting epoch 15\n",
      "Train Loss for Epoch 14: 0.3904 \n",
      "Train Accuracy for Epoch 14: 85.75 %\n",
      "Val Loss for Epoch 14: 0.3912 \n",
      "Val Accuracy for Epoch 14: 86.67 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Early Stop Count 3\n",
      "Starting epoch 16\n",
      "Train Loss for Epoch 15: 0.3399 \n",
      "Train Accuracy for Epoch 15: 91.90 %\n",
      "Val Loss for Epoch 15: 0.3434 \n",
      "Val Accuracy for Epoch 15: 88.89 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Early Stop Count 4\n",
      "Starting epoch 17\n",
      "Train Loss for Epoch 16: 0.3190 \n",
      "Train Accuracy for Epoch 16: 91.90 %\n",
      "Val Loss for Epoch 16: 0.2970 \n",
      "Val Accuracy for Epoch 16: 88.89 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Early Stop Count 5\n",
      "Starting epoch 18\n",
      "Train Loss for Epoch 17: 0.2636 \n",
      "Train Accuracy for Epoch 17: 94.97 %\n",
      "Val Loss for Epoch 17: 0.2959 \n",
      "Val Accuracy for Epoch 17: 91.11 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Early Stop Count 6\n",
      "Starting epoch 19\n",
      "Train Loss for Epoch 18: 0.2541 \n",
      "Train Accuracy for Epoch 18: 94.69 %\n",
      "Val Loss for Epoch 18: 0.2854 \n",
      "Val Accuracy for Epoch 18: 90.00 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Early Stop Count 7\n",
      "Starting epoch 20\n",
      "Train Loss for Epoch 19: 0.2963 \n",
      "Train Accuracy for Epoch 19: 91.90 %\n",
      "Val Loss for Epoch 19: 0.2377 \n",
      "Val Accuracy for Epoch 19: 95.56 %\n",
      "--------------------------------\n",
      "Early Stop Count 0\n",
      "Starting epoch 21\n",
      "Train Loss for Epoch 20: 0.2216 \n",
      "Train Accuracy for Epoch 20: 96.09 %\n",
      "Val Loss for Epoch 20: 0.2494 \n",
      "Val Accuracy for Epoch 20: 92.22 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Early Stop Count 1\n",
      "Starting epoch 22\n",
      "Train Loss for Epoch 21: 0.2013 \n",
      "Train Accuracy for Epoch 21: 95.53 %\n",
      "Val Loss for Epoch 21: 0.2207 \n",
      "Val Accuracy for Epoch 21: 93.33 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Early Stop Count 2\n",
      "Starting epoch 23\n",
      "Train Loss for Epoch 22: 0.2036 \n",
      "Train Accuracy for Epoch 22: 94.97 %\n",
      "Val Loss for Epoch 22: 0.2340 \n",
      "Val Accuracy for Epoch 22: 91.11 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Early Stop Count 3\n",
      "Starting epoch 24\n",
      "Train Loss for Epoch 23: 0.1868 \n",
      "Train Accuracy for Epoch 23: 94.97 %\n",
      "Val Loss for Epoch 23: 0.2588 \n",
      "Val Accuracy for Epoch 23: 91.11 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Early Stop Count 4\n",
      "Starting epoch 25\n",
      "Train Loss for Epoch 24: 0.1402 \n",
      "Train Accuracy for Epoch 24: 97.77 %\n",
      "Val Loss for Epoch 24: 0.2080 \n",
      "Val Accuracy for Epoch 24: 94.44 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Early Stop Count 5\n",
      "Starting epoch 26\n",
      "Train Loss for Epoch 25: 0.1675 \n",
      "Train Accuracy for Epoch 25: 95.53 %\n",
      "Val Loss for Epoch 25: 0.2156 \n",
      "Val Accuracy for Epoch 25: 93.33 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Early Stop Count 6\n",
      "Starting epoch 27\n",
      "Train Loss for Epoch 26: 0.1452 \n",
      "Train Accuracy for Epoch 26: 97.21 %\n",
      "Val Loss for Epoch 26: 0.2315 \n",
      "Val Accuracy for Epoch 26: 90.00 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Early Stop Count 7\n",
      "Starting epoch 28\n",
      "Train Loss for Epoch 27: 0.1627 \n",
      "Train Accuracy for Epoch 27: 95.81 %\n",
      "Val Loss for Epoch 27: 0.2138 \n",
      "Val Accuracy for Epoch 27: 91.11 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Early Stop Count 8\n",
      "Starting epoch 29\n",
      "Train Loss for Epoch 28: 0.1307 \n",
      "Train Accuracy for Epoch 28: 96.93 %\n",
      "Val Loss for Epoch 28: 0.2239 \n",
      "Val Accuracy for Epoch 28: 91.11 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Early Stop Count 9\n",
      "Starting epoch 30\n",
      "Train Loss for Epoch 29: 0.1361 \n",
      "Train Accuracy for Epoch 29: 96.37 %\n",
      "Val Loss for Epoch 29: 0.2034 \n",
      "Val Accuracy for Epoch 29: 90.00 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Early Stop Count 10\n",
      "Early stopping at Epoch 29\n",
      "Training process has finished. Saving trained model.\n",
      "Starting testing\n",
      "Accuracy for fold 0: 93.33 %\n",
      "--------------------------------\n",
      "FOLD 1\n",
      "--------------------------------\n",
      "Starting epoch 1\n",
      "Train Loss for Epoch 0: 0.7160 \n",
      "Train Accuracy for Epoch 0: 48.04 %\n",
      "Val Loss for Epoch 0: 0.6811 \n",
      "Val Accuracy for Epoch 0: 57.78 %\n",
      "--------------------------------\n",
      "Found better model...saving\n",
      "Early Stop Count 0\n",
      "Starting epoch 2\n",
      "Train Loss for Epoch 1: 0.6805 \n",
      "Train Accuracy for Epoch 1: 62.57 %\n",
      "Val Loss for Epoch 1: 0.6788 \n",
      "Val Accuracy for Epoch 1: 73.33 %\n",
      "--------------------------------\n",
      "Found better model...saving\n",
      "Early Stop Count 0\n",
      "Starting epoch 3\n",
      "Train Loss for Epoch 2: 0.6714 \n",
      "Train Accuracy for Epoch 2: 68.44 %\n",
      "Val Loss for Epoch 2: 0.6760 \n",
      "Val Accuracy for Epoch 2: 70.00 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Early Stop Count 1\n",
      "Starting epoch 4\n",
      "Train Loss for Epoch 3: 0.6597 \n",
      "Train Accuracy for Epoch 3: 76.82 %\n",
      "Val Loss for Epoch 3: 0.6683 \n",
      "Val Accuracy for Epoch 3: 70.00 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Early Stop Count 2\n",
      "Starting epoch 5\n",
      "Train Loss for Epoch 4: 0.6431 \n",
      "Train Accuracy for Epoch 4: 77.37 %\n",
      "Val Loss for Epoch 4: 0.6691 \n",
      "Val Accuracy for Epoch 4: 61.11 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Early Stop Count 3\n",
      "Starting epoch 6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss for Epoch 5: 0.6161 \n",
      "Train Accuracy for Epoch 5: 82.12 %\n",
      "Val Loss for Epoch 5: 0.6484 \n",
      "Val Accuracy for Epoch 5: 70.00 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Early Stop Count 4\n",
      "Starting epoch 7\n",
      "Train Loss for Epoch 6: 0.6213 \n",
      "Train Accuracy for Epoch 6: 74.58 %\n",
      "Val Loss for Epoch 6: 0.6422 \n",
      "Val Accuracy for Epoch 6: 74.44 %\n",
      "--------------------------------\n",
      "Found better model...saving\n",
      "Early Stop Count 0\n",
      "Starting epoch 8\n",
      "Train Loss for Epoch 7: 0.5808 \n",
      "Train Accuracy for Epoch 7: 84.08 %\n",
      "Val Loss for Epoch 7: 0.6307 \n",
      "Val Accuracy for Epoch 7: 73.33 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Early Stop Count 1\n",
      "Starting epoch 9\n",
      "Train Loss for Epoch 8: 0.5568 \n",
      "Train Accuracy for Epoch 8: 84.92 %\n",
      "Val Loss for Epoch 8: 0.6068 \n",
      "Val Accuracy for Epoch 8: 75.56 %\n",
      "--------------------------------\n",
      "Found better model...saving\n",
      "Early Stop Count 0\n",
      "Starting epoch 10\n",
      "Train Loss for Epoch 9: 0.5083 \n",
      "Train Accuracy for Epoch 9: 87.99 %\n",
      "Val Loss for Epoch 9: 0.5972 \n",
      "Val Accuracy for Epoch 9: 74.44 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Early Stop Count 1\n",
      "Starting epoch 11\n",
      "Train Loss for Epoch 10: 0.4876 \n",
      "Train Accuracy for Epoch 10: 87.71 %\n",
      "Val Loss for Epoch 10: 0.5580 \n",
      "Val Accuracy for Epoch 10: 75.56 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Early Stop Count 2\n",
      "Starting epoch 12\n",
      "Train Loss for Epoch 11: 0.4835 \n",
      "Train Accuracy for Epoch 11: 87.99 %\n",
      "Val Loss for Epoch 11: 0.5431 \n",
      "Val Accuracy for Epoch 11: 77.78 %\n",
      "--------------------------------\n",
      "Found better model...saving\n",
      "Early Stop Count 0\n",
      "Starting epoch 13\n",
      "Train Loss for Epoch 12: 0.4572 \n",
      "Train Accuracy for Epoch 12: 87.99 %\n",
      "Val Loss for Epoch 12: 0.4971 \n",
      "Val Accuracy for Epoch 12: 81.11 %\n",
      "--------------------------------\n",
      "Early Stop Count 0\n",
      "Starting epoch 14\n",
      "Train Loss for Epoch 13: 0.4440 \n",
      "Train Accuracy for Epoch 13: 86.87 %\n",
      "Val Loss for Epoch 13: 0.4950 \n",
      "Val Accuracy for Epoch 13: 80.00 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Early Stop Count 1\n",
      "Starting epoch 15\n",
      "Train Loss for Epoch 14: 0.4598 \n",
      "Train Accuracy for Epoch 14: 85.75 %\n",
      "Val Loss for Epoch 14: 0.5301 \n",
      "Val Accuracy for Epoch 14: 75.56 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Early Stop Count 2\n",
      "Starting epoch 16\n",
      "Train Loss for Epoch 15: 0.4068 \n",
      "Train Accuracy for Epoch 15: 89.39 %\n",
      "Val Loss for Epoch 15: 0.4621 \n",
      "Val Accuracy for Epoch 15: 81.11 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Early Stop Count 3\n",
      "Starting epoch 17\n",
      "Train Loss for Epoch 16: 0.3760 \n",
      "Train Accuracy for Epoch 16: 89.94 %\n",
      "Val Loss for Epoch 16: 0.4684 \n",
      "Val Accuracy for Epoch 16: 80.00 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Early Stop Count 4\n",
      "Starting epoch 18\n",
      "Train Loss for Epoch 17: 0.3434 \n",
      "Train Accuracy for Epoch 17: 90.22 %\n",
      "Val Loss for Epoch 17: 0.4486 \n",
      "Val Accuracy for Epoch 17: 82.22 %\n",
      "--------------------------------\n",
      "Found better model...saving\n",
      "Early Stop Count 0\n",
      "Starting epoch 19\n",
      "Train Loss for Epoch 18: 0.3464 \n",
      "Train Accuracy for Epoch 18: 90.50 %\n",
      "Val Loss for Epoch 18: 0.4291 \n",
      "Val Accuracy for Epoch 18: 82.22 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Early Stop Count 1\n",
      "Starting epoch 20\n",
      "Train Loss for Epoch 19: 0.3287 \n",
      "Train Accuracy for Epoch 19: 91.90 %\n",
      "Val Loss for Epoch 19: 0.4640 \n",
      "Val Accuracy for Epoch 19: 82.22 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Early Stop Count 2\n",
      "Starting epoch 21\n",
      "Train Loss for Epoch 20: 0.3201 \n",
      "Train Accuracy for Epoch 20: 89.94 %\n",
      "Val Loss for Epoch 20: 0.4015 \n",
      "Val Accuracy for Epoch 20: 86.67 %\n",
      "--------------------------------\n",
      "Early Stop Count 0\n",
      "Starting epoch 22\n",
      "Train Loss for Epoch 21: 0.2788 \n",
      "Train Accuracy for Epoch 21: 93.02 %\n",
      "Val Loss for Epoch 21: 0.3883 \n",
      "Val Accuracy for Epoch 21: 84.44 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Early Stop Count 1\n",
      "Starting epoch 23\n",
      "Train Loss for Epoch 22: 0.2751 \n",
      "Train Accuracy for Epoch 22: 93.02 %\n",
      "Val Loss for Epoch 22: 0.3656 \n",
      "Val Accuracy for Epoch 22: 85.56 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Early Stop Count 2\n",
      "Starting epoch 24\n",
      "Train Loss for Epoch 23: 0.2856 \n",
      "Train Accuracy for Epoch 23: 90.22 %\n",
      "Val Loss for Epoch 23: 0.3979 \n",
      "Val Accuracy for Epoch 23: 83.33 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Early Stop Count 3\n",
      "Starting epoch 25\n",
      "Train Loss for Epoch 24: 0.2433 \n",
      "Train Accuracy for Epoch 24: 95.53 %\n",
      "Val Loss for Epoch 24: 0.4016 \n",
      "Val Accuracy for Epoch 24: 83.33 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Early Stop Count 4\n",
      "Starting epoch 26\n",
      "Train Loss for Epoch 25: 0.2211 \n",
      "Train Accuracy for Epoch 25: 94.69 %\n",
      "Val Loss for Epoch 25: 0.4937 \n",
      "Val Accuracy for Epoch 25: 74.44 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Early Stop Count 5\n",
      "Starting epoch 27\n",
      "Train Loss for Epoch 26: 0.2006 \n",
      "Train Accuracy for Epoch 26: 95.25 %\n",
      "Val Loss for Epoch 26: 0.4686 \n",
      "Val Accuracy for Epoch 26: 78.89 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Early Stop Count 6\n",
      "Starting epoch 28\n",
      "Train Loss for Epoch 27: 0.1964 \n",
      "Train Accuracy for Epoch 27: 95.25 %\n",
      "Val Loss for Epoch 27: 0.5151 \n",
      "Val Accuracy for Epoch 27: 76.67 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Early Stop Count 7\n",
      "Starting epoch 29\n",
      "Train Loss for Epoch 28: 0.1874 \n",
      "Train Accuracy for Epoch 28: 95.81 %\n",
      "Val Loss for Epoch 28: 0.3835 \n",
      "Val Accuracy for Epoch 28: 82.22 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Early Stop Count 8\n",
      "Starting epoch 30\n",
      "Train Loss for Epoch 29: 0.1647 \n",
      "Train Accuracy for Epoch 29: 95.81 %\n",
      "Val Loss for Epoch 29: 0.3176 \n",
      "Val Accuracy for Epoch 29: 90.00 %\n",
      "--------------------------------\n",
      "Found better model...saving\n",
      "Early Stop Count 0\n",
      "Starting epoch 31\n",
      "Train Loss for Epoch 30: 0.1762 \n",
      "Train Accuracy for Epoch 30: 95.25 %\n",
      "Val Loss for Epoch 30: 0.3532 \n",
      "Val Accuracy for Epoch 30: 84.44 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Early Stop Count 1\n",
      "Starting epoch 32\n",
      "Train Loss for Epoch 31: 0.1801 \n",
      "Train Accuracy for Epoch 31: 95.25 %\n",
      "Val Loss for Epoch 31: 0.4026 \n",
      "Val Accuracy for Epoch 31: 82.22 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Early Stop Count 2\n",
      "Starting epoch 33\n",
      "Train Loss for Epoch 32: 0.1852 \n",
      "Train Accuracy for Epoch 32: 93.30 %\n",
      "Val Loss for Epoch 32: 0.5374 \n",
      "Val Accuracy for Epoch 32: 76.67 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Early Stop Count 3\n",
      "Starting epoch 34\n",
      "Train Loss for Epoch 33: 0.1597 \n",
      "Train Accuracy for Epoch 33: 96.93 %\n",
      "Val Loss for Epoch 33: 0.3875 \n",
      "Val Accuracy for Epoch 33: 83.33 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Early Stop Count 4\n",
      "Starting epoch 35\n",
      "Train Loss for Epoch 34: 0.1763 \n",
      "Train Accuracy for Epoch 34: 93.02 %\n",
      "Val Loss for Epoch 34: 0.4878 \n",
      "Val Accuracy for Epoch 34: 77.78 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Early Stop Count 5\n",
      "Starting epoch 36\n",
      "Train Loss for Epoch 35: 0.1377 \n",
      "Train Accuracy for Epoch 35: 96.37 %\n",
      "Val Loss for Epoch 35: 0.3535 \n",
      "Val Accuracy for Epoch 35: 84.44 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Early Stop Count 6\n",
      "Starting epoch 37\n",
      "Train Loss for Epoch 36: 0.1547 \n",
      "Train Accuracy for Epoch 36: 96.37 %\n",
      "Val Loss for Epoch 36: 0.3872 \n",
      "Val Accuracy for Epoch 36: 85.56 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Early Stop Count 7\n",
      "Starting epoch 38\n",
      "Train Loss for Epoch 37: 0.1270 \n",
      "Train Accuracy for Epoch 37: 97.49 %\n",
      "Val Loss for Epoch 37: 0.3082 \n",
      "Val Accuracy for Epoch 37: 88.89 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Early Stop Count 8\n",
      "Starting epoch 39\n",
      "Train Loss for Epoch 38: 0.1239 \n",
      "Train Accuracy for Epoch 38: 96.93 %\n",
      "Val Loss for Epoch 38: 0.3317 \n",
      "Val Accuracy for Epoch 38: 85.56 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Early Stop Count 9\n",
      "Starting epoch 40\n",
      "Train Loss for Epoch 39: 0.1084 \n",
      "Train Accuracy for Epoch 39: 97.49 %\n",
      "Val Loss for Epoch 39: 0.3975 \n",
      "Val Accuracy for Epoch 39: 82.22 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Early Stop Count 10\n",
      "Early stopping at Epoch 39\n",
      "Training process has finished. Saving trained model.\n",
      "Starting testing\n",
      "Accuracy for fold 1: 87.78 %\n",
      "--------------------------------\n",
      "FOLD 2\n",
      "--------------------------------\n",
      "Starting epoch 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss for Epoch 0: 0.6943 \n",
      "Train Accuracy for Epoch 0: 51.12 %\n",
      "Val Loss for Epoch 0: 0.6870 \n",
      "Val Accuracy for Epoch 0: 47.78 %\n",
      "--------------------------------\n",
      "Found better model...saving\n",
      "Early Stop Count 0\n",
      "Starting epoch 2\n",
      "Train Loss for Epoch 1: 0.6730 \n",
      "Train Accuracy for Epoch 1: 62.85 %\n",
      "Val Loss for Epoch 1: 0.6711 \n",
      "Val Accuracy for Epoch 1: 63.33 %\n",
      "--------------------------------\n",
      "Found better model...saving\n",
      "Early Stop Count 0\n",
      "Starting epoch 3\n",
      "Train Loss for Epoch 2: 0.6552 \n",
      "Train Accuracy for Epoch 2: 75.42 %\n",
      "Val Loss for Epoch 2: 0.6566 \n",
      "Val Accuracy for Epoch 2: 66.67 %\n",
      "--------------------------------\n",
      "Found better model...saving\n",
      "Early Stop Count 0\n",
      "Starting epoch 4\n",
      "Train Loss for Epoch 3: 0.6370 \n",
      "Train Accuracy for Epoch 3: 75.42 %\n",
      "Val Loss for Epoch 3: 0.6412 \n",
      "Val Accuracy for Epoch 3: 70.00 %\n",
      "--------------------------------\n",
      "Early Stop Count 0\n",
      "Starting epoch 5\n",
      "Train Loss for Epoch 4: 0.6197 \n",
      "Train Accuracy for Epoch 4: 78.21 %\n",
      "Val Loss for Epoch 4: 0.6202 \n",
      "Val Accuracy for Epoch 4: 77.78 %\n",
      "--------------------------------\n",
      "Found better model...saving\n",
      "Early Stop Count 0\n",
      "Starting epoch 6\n",
      "Train Loss for Epoch 5: 0.5917 \n",
      "Train Accuracy for Epoch 5: 88.27 %\n",
      "Val Loss for Epoch 5: 0.6155 \n",
      "Val Accuracy for Epoch 5: 80.00 %\n",
      "--------------------------------\n",
      "Found better model...saving\n",
      "Early Stop Count 0\n",
      "Starting epoch 7\n",
      "Train Loss for Epoch 6: 0.5803 \n",
      "Train Accuracy for Epoch 6: 84.08 %\n",
      "Val Loss for Epoch 6: 0.5718 \n",
      "Val Accuracy for Epoch 6: 83.33 %\n",
      "--------------------------------\n",
      "Early Stop Count 0\n",
      "Starting epoch 8\n",
      "Train Loss for Epoch 7: 0.5427 \n",
      "Train Accuracy for Epoch 7: 87.15 %\n",
      "Val Loss for Epoch 7: 0.5500 \n",
      "Val Accuracy for Epoch 7: 83.33 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Early Stop Count 1\n",
      "Starting epoch 9\n",
      "Train Loss for Epoch 8: 0.5081 \n",
      "Train Accuracy for Epoch 8: 90.50 %\n",
      "Val Loss for Epoch 8: 0.5156 \n",
      "Val Accuracy for Epoch 8: 88.89 %\n",
      "--------------------------------\n",
      "Found better model...saving\n",
      "Early Stop Count 0\n",
      "Starting epoch 10\n",
      "Train Loss for Epoch 9: 0.4654 \n",
      "Train Accuracy for Epoch 9: 92.74 %\n",
      "Val Loss for Epoch 9: 0.4979 \n",
      "Val Accuracy for Epoch 9: 86.67 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Early Stop Count 1\n",
      "Starting epoch 11\n",
      "Train Loss for Epoch 10: 0.4350 \n",
      "Train Accuracy for Epoch 10: 93.02 %\n",
      "Val Loss for Epoch 10: 0.4572 \n",
      "Val Accuracy for Epoch 10: 90.00 %\n",
      "--------------------------------\n",
      "Found better model...saving\n",
      "Early Stop Count 0\n",
      "Starting epoch 12\n",
      "Train Loss for Epoch 11: 0.4137 \n",
      "Train Accuracy for Epoch 11: 92.18 %\n",
      "Val Loss for Epoch 11: 0.4533 \n",
      "Val Accuracy for Epoch 11: 84.44 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Early Stop Count 1\n",
      "Starting epoch 13\n",
      "Train Loss for Epoch 12: 0.3704 \n",
      "Train Accuracy for Epoch 12: 93.58 %\n",
      "Val Loss for Epoch 12: 0.4183 \n",
      "Val Accuracy for Epoch 12: 87.78 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Early Stop Count 2\n",
      "Starting epoch 14\n",
      "Train Loss for Epoch 13: 0.3300 \n",
      "Train Accuracy for Epoch 13: 95.25 %\n",
      "Val Loss for Epoch 13: 0.3997 \n",
      "Val Accuracy for Epoch 13: 86.67 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Early Stop Count 3\n",
      "Starting epoch 15\n",
      "Train Loss for Epoch 14: 0.2902 \n",
      "Train Accuracy for Epoch 14: 94.97 %\n",
      "Val Loss for Epoch 14: 0.3842 \n",
      "Val Accuracy for Epoch 14: 87.78 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Early Stop Count 4\n",
      "Starting epoch 16\n",
      "Train Loss for Epoch 15: 0.2729 \n",
      "Train Accuracy for Epoch 15: 95.25 %\n",
      "Val Loss for Epoch 15: 0.3537 \n",
      "Val Accuracy for Epoch 15: 86.67 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Early Stop Count 5\n",
      "Starting epoch 17\n",
      "Train Loss for Epoch 16: 0.2634 \n",
      "Train Accuracy for Epoch 16: 95.53 %\n",
      "Val Loss for Epoch 16: 0.4046 \n",
      "Val Accuracy for Epoch 16: 82.22 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Early Stop Count 6\n",
      "Starting epoch 18\n",
      "Train Loss for Epoch 17: 0.2242 \n",
      "Train Accuracy for Epoch 17: 96.37 %\n",
      "Val Loss for Epoch 17: 0.3151 \n",
      "Val Accuracy for Epoch 17: 88.89 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Early Stop Count 7\n",
      "Starting epoch 19\n",
      "Train Loss for Epoch 18: 0.2036 \n",
      "Train Accuracy for Epoch 18: 96.93 %\n",
      "Val Loss for Epoch 18: 0.3786 \n",
      "Val Accuracy for Epoch 18: 86.67 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Early Stop Count 8\n",
      "Starting epoch 20\n",
      "Train Loss for Epoch 19: 0.1714 \n",
      "Train Accuracy for Epoch 19: 98.04 %\n",
      "Val Loss for Epoch 19: 0.3220 \n",
      "Val Accuracy for Epoch 19: 87.78 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Early Stop Count 9\n",
      "Starting epoch 21\n",
      "Train Loss for Epoch 20: 0.1842 \n",
      "Train Accuracy for Epoch 20: 98.04 %\n",
      "Val Loss for Epoch 20: 0.3400 \n",
      "Val Accuracy for Epoch 20: 87.78 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Early Stop Count 10\n",
      "Early stopping at Epoch 20\n",
      "Training process has finished. Saving trained model.\n",
      "Starting testing\n",
      "Accuracy for fold 2: 88.89 %\n",
      "--------------------------------\n",
      "FOLD 3\n",
      "--------------------------------\n",
      "Starting epoch 1\n",
      "Train Loss for Epoch 0: 0.6927 \n",
      "Train Accuracy for Epoch 0: 52.65 %\n",
      "Val Loss for Epoch 0: 0.6873 \n",
      "Val Accuracy for Epoch 0: 61.80 %\n",
      "--------------------------------\n",
      "Found better model...saving\n",
      "Early Stop Count 0\n",
      "Starting epoch 2\n",
      "Train Loss for Epoch 1: 0.6835 \n",
      "Train Accuracy for Epoch 1: 53.48 %\n",
      "Val Loss for Epoch 1: 0.6769 \n",
      "Val Accuracy for Epoch 1: 77.53 %\n",
      "--------------------------------\n",
      "Found better model...saving\n",
      "Early Stop Count 0\n",
      "Starting epoch 3\n",
      "Train Loss for Epoch 2: 0.6708 \n",
      "Train Accuracy for Epoch 2: 81.62 %\n",
      "Val Loss for Epoch 2: 0.6640 \n",
      "Val Accuracy for Epoch 2: 82.02 %\n",
      "--------------------------------\n",
      "Found better model...saving\n",
      "Early Stop Count 0\n",
      "Starting epoch 4\n",
      "Train Loss for Epoch 3: 0.6555 \n",
      "Train Accuracy for Epoch 3: 83.01 %\n",
      "Val Loss for Epoch 3: 0.6501 \n",
      "Val Accuracy for Epoch 3: 77.53 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Early Stop Count 1\n",
      "Starting epoch 5\n",
      "Train Loss for Epoch 4: 0.6416 \n",
      "Train Accuracy for Epoch 4: 81.89 %\n",
      "Val Loss for Epoch 4: 0.6516 \n",
      "Val Accuracy for Epoch 4: 67.42 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Early Stop Count 2\n",
      "Starting epoch 6\n",
      "Train Loss for Epoch 5: 0.6313 \n",
      "Train Accuracy for Epoch 5: 78.83 %\n",
      "Val Loss for Epoch 5: 0.6183 \n",
      "Val Accuracy for Epoch 5: 79.78 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Early Stop Count 3\n",
      "Starting epoch 7\n",
      "Train Loss for Epoch 6: 0.6078 \n",
      "Train Accuracy for Epoch 6: 83.29 %\n",
      "Val Loss for Epoch 6: 0.5892 \n",
      "Val Accuracy for Epoch 6: 85.39 %\n",
      "--------------------------------\n",
      "Found better model...saving\n",
      "Early Stop Count 0\n",
      "Starting epoch 8\n",
      "Train Loss for Epoch 7: 0.5741 \n",
      "Train Accuracy for Epoch 7: 85.79 %\n",
      "Val Loss for Epoch 7: 0.5613 \n",
      "Val Accuracy for Epoch 7: 87.64 %\n",
      "--------------------------------\n",
      "Found better model...saving\n",
      "Early Stop Count 0\n",
      "Starting epoch 9\n",
      "Train Loss for Epoch 8: 0.5475 \n",
      "Train Accuracy for Epoch 8: 87.47 %\n",
      "Val Loss for Epoch 8: 0.5257 \n",
      "Val Accuracy for Epoch 8: 91.01 %\n",
      "--------------------------------\n",
      "Found better model...saving\n",
      "Early Stop Count 0\n",
      "Starting epoch 10\n",
      "Train Loss for Epoch 9: 0.5191 \n",
      "Train Accuracy for Epoch 9: 87.19 %\n",
      "Val Loss for Epoch 9: 0.5167 \n",
      "Val Accuracy for Epoch 9: 80.90 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Early Stop Count 1\n",
      "Starting epoch 11\n",
      "Train Loss for Epoch 10: 0.4803 \n",
      "Train Accuracy for Epoch 10: 89.42 %\n",
      "Val Loss for Epoch 10: 0.4670 \n",
      "Val Accuracy for Epoch 10: 89.89 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Early Stop Count 2\n",
      "Starting epoch 12\n",
      "Train Loss for Epoch 11: 0.4528 \n",
      "Train Accuracy for Epoch 11: 89.69 %\n",
      "Val Loss for Epoch 11: 0.4582 \n",
      "Val Accuracy for Epoch 11: 88.76 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Early Stop Count 3\n",
      "Starting epoch 13\n",
      "Train Loss for Epoch 12: 0.4102 \n",
      "Train Accuracy for Epoch 12: 92.76 %\n",
      "Val Loss for Epoch 12: 0.4065 \n",
      "Val Accuracy for Epoch 12: 91.01 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Early Stop Count 4\n",
      "Starting epoch 14\n",
      "Train Loss for Epoch 13: 0.3765 \n",
      "Train Accuracy for Epoch 13: 93.87 %\n",
      "Val Loss for Epoch 13: 0.4665 \n",
      "Val Accuracy for Epoch 13: 80.90 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Early Stop Count 5\n",
      "Starting epoch 15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss for Epoch 14: 0.3620 \n",
      "Train Accuracy for Epoch 14: 93.31 %\n",
      "Val Loss for Epoch 14: 0.3669 \n",
      "Val Accuracy for Epoch 14: 92.13 %\n",
      "--------------------------------\n",
      "Found better model...saving\n",
      "Early Stop Count 0\n",
      "Starting epoch 16\n",
      "Train Loss for Epoch 15: 0.3396 \n",
      "Train Accuracy for Epoch 15: 90.53 %\n",
      "Val Loss for Epoch 15: 0.3542 \n",
      "Val Accuracy for Epoch 15: 92.13 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Early Stop Count 1\n",
      "Starting epoch 17\n",
      "Train Loss for Epoch 16: 0.3252 \n",
      "Train Accuracy for Epoch 16: 93.04 %\n",
      "Val Loss for Epoch 16: 0.4452 \n",
      "Val Accuracy for Epoch 16: 79.78 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Early Stop Count 2\n",
      "Starting epoch 18\n",
      "Train Loss for Epoch 17: 0.3671 \n",
      "Train Accuracy for Epoch 17: 86.91 %\n",
      "Val Loss for Epoch 17: 0.3629 \n",
      "Val Accuracy for Epoch 17: 87.64 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Early Stop Count 3\n",
      "Starting epoch 19\n",
      "Train Loss for Epoch 18: 0.2885 \n",
      "Train Accuracy for Epoch 18: 93.04 %\n",
      "Val Loss for Epoch 18: 0.3408 \n",
      "Val Accuracy for Epoch 18: 87.64 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Early Stop Count 4\n",
      "Starting epoch 20\n",
      "Train Loss for Epoch 19: 0.2421 \n",
      "Train Accuracy for Epoch 19: 95.54 %\n",
      "Val Loss for Epoch 19: 0.2984 \n",
      "Val Accuracy for Epoch 19: 89.89 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Early Stop Count 5\n",
      "Starting epoch 21\n",
      "Train Loss for Epoch 20: 0.2308 \n",
      "Train Accuracy for Epoch 20: 96.10 %\n",
      "Val Loss for Epoch 20: 0.3600 \n",
      "Val Accuracy for Epoch 20: 87.64 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Early Stop Count 6\n",
      "Starting epoch 22\n",
      "Train Loss for Epoch 21: 0.2492 \n",
      "Train Accuracy for Epoch 21: 92.20 %\n",
      "Val Loss for Epoch 21: 0.3233 \n",
      "Val Accuracy for Epoch 21: 85.39 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Early Stop Count 7\n",
      "Starting epoch 23\n",
      "Train Loss for Epoch 22: 0.2457 \n",
      "Train Accuracy for Epoch 22: 93.87 %\n",
      "Val Loss for Epoch 22: 0.2586 \n",
      "Val Accuracy for Epoch 22: 94.38 %\n",
      "--------------------------------\n",
      "Found better model...saving\n",
      "Early Stop Count 0\n",
      "Starting epoch 24\n",
      "Train Loss for Epoch 23: 0.2238 \n",
      "Train Accuracy for Epoch 23: 94.43 %\n",
      "Val Loss for Epoch 23: 0.3487 \n",
      "Val Accuracy for Epoch 23: 86.52 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Early Stop Count 1\n",
      "Starting epoch 25\n",
      "Train Loss for Epoch 24: 0.2456 \n",
      "Train Accuracy for Epoch 24: 92.76 %\n",
      "Val Loss for Epoch 24: 0.3098 \n",
      "Val Accuracy for Epoch 24: 87.64 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Early Stop Count 2\n",
      "Starting epoch 26\n",
      "Train Loss for Epoch 25: 0.2096 \n",
      "Train Accuracy for Epoch 25: 93.87 %\n",
      "Val Loss for Epoch 25: 0.2486 \n",
      "Val Accuracy for Epoch 25: 94.38 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Early Stop Count 3\n",
      "Starting epoch 27\n",
      "Train Loss for Epoch 26: 0.1679 \n",
      "Train Accuracy for Epoch 26: 95.26 %\n",
      "Val Loss for Epoch 26: 0.3176 \n",
      "Val Accuracy for Epoch 26: 88.76 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Early Stop Count 4\n",
      "Starting epoch 28\n",
      "Train Loss for Epoch 27: 0.1299 \n",
      "Train Accuracy for Epoch 27: 98.05 %\n",
      "Val Loss for Epoch 27: 0.2970 \n",
      "Val Accuracy for Epoch 27: 92.13 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Early Stop Count 5\n",
      "Starting epoch 29\n",
      "Train Loss for Epoch 28: 0.1131 \n",
      "Train Accuracy for Epoch 28: 98.33 %\n",
      "Val Loss for Epoch 28: 0.2533 \n",
      "Val Accuracy for Epoch 28: 91.01 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Early Stop Count 6\n",
      "Starting epoch 30\n",
      "Train Loss for Epoch 29: 0.1099 \n",
      "Train Accuracy for Epoch 29: 98.05 %\n",
      "Val Loss for Epoch 29: 0.3247 \n",
      "Val Accuracy for Epoch 29: 89.89 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Early Stop Count 7\n",
      "Starting epoch 31\n",
      "Train Loss for Epoch 30: 0.1246 \n",
      "Train Accuracy for Epoch 30: 98.33 %\n",
      "Val Loss for Epoch 30: 0.2584 \n",
      "Val Accuracy for Epoch 30: 91.01 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Early Stop Count 8\n",
      "Starting epoch 32\n",
      "Train Loss for Epoch 31: 0.1640 \n",
      "Train Accuracy for Epoch 31: 96.10 %\n",
      "Val Loss for Epoch 31: 0.2614 \n",
      "Val Accuracy for Epoch 31: 89.89 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Early Stop Count 9\n",
      "Starting epoch 33\n",
      "Train Loss for Epoch 32: 0.2055 \n",
      "Train Accuracy for Epoch 32: 93.31 %\n",
      "Val Loss for Epoch 32: 0.2886 \n",
      "Val Accuracy for Epoch 32: 91.01 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Early Stop Count 10\n",
      "Early stopping at Epoch 32\n",
      "Training process has finished. Saving trained model.\n",
      "Starting testing\n",
      "Accuracy for fold 3: 88.76 %\n",
      "--------------------------------\n",
      "FOLD 4\n",
      "--------------------------------\n",
      "Starting epoch 1\n",
      "Train Loss for Epoch 0: 0.7069 \n",
      "Train Accuracy for Epoch 0: 49.03 %\n",
      "Val Loss for Epoch 0: 0.6700 \n",
      "Val Accuracy for Epoch 0: 59.55 %\n",
      "--------------------------------\n",
      "Found better model...saving\n",
      "Early Stop Count 0\n",
      "Starting epoch 2\n",
      "Train Loss for Epoch 1: 0.6645 \n",
      "Train Accuracy for Epoch 1: 74.93 %\n",
      "Val Loss for Epoch 1: 0.6489 \n",
      "Val Accuracy for Epoch 1: 85.39 %\n",
      "--------------------------------\n",
      "Found better model...saving\n",
      "Early Stop Count 0\n",
      "Starting epoch 3\n",
      "Train Loss for Epoch 2: 0.6402 \n",
      "Train Accuracy for Epoch 2: 81.06 %\n",
      "Val Loss for Epoch 2: 0.6362 \n",
      "Val Accuracy for Epoch 2: 76.40 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Early Stop Count 1\n",
      "Starting epoch 4\n",
      "Train Loss for Epoch 3: 0.6258 \n",
      "Train Accuracy for Epoch 3: 78.55 %\n",
      "Val Loss for Epoch 3: 0.6232 \n",
      "Val Accuracy for Epoch 3: 82.02 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Early Stop Count 2\n",
      "Starting epoch 5\n",
      "Train Loss for Epoch 4: 0.6117 \n",
      "Train Accuracy for Epoch 4: 79.94 %\n",
      "Val Loss for Epoch 4: 0.5948 \n",
      "Val Accuracy for Epoch 4: 83.15 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Early Stop Count 3\n",
      "Starting epoch 6\n",
      "Train Loss for Epoch 5: 0.5965 \n",
      "Train Accuracy for Epoch 5: 78.55 %\n",
      "Val Loss for Epoch 5: 0.5812 \n",
      "Val Accuracy for Epoch 5: 80.90 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Early Stop Count 4\n",
      "Starting epoch 7\n",
      "Train Loss for Epoch 6: 0.5591 \n",
      "Train Accuracy for Epoch 6: 88.58 %\n",
      "Val Loss for Epoch 6: 0.5399 \n",
      "Val Accuracy for Epoch 6: 87.64 %\n",
      "--------------------------------\n",
      "Found better model...saving\n",
      "Early Stop Count 0\n",
      "Starting epoch 8\n",
      "Train Loss for Epoch 7: 0.5264 \n",
      "Train Accuracy for Epoch 7: 88.02 %\n",
      "Val Loss for Epoch 7: 0.5186 \n",
      "Val Accuracy for Epoch 7: 86.52 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Early Stop Count 1\n",
      "Starting epoch 9\n",
      "Train Loss for Epoch 8: 0.4883 \n",
      "Train Accuracy for Epoch 8: 88.86 %\n",
      "Val Loss for Epoch 8: 0.4932 \n",
      "Val Accuracy for Epoch 8: 85.39 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Early Stop Count 2\n",
      "Starting epoch 10\n",
      "Train Loss for Epoch 9: 0.4699 \n",
      "Train Accuracy for Epoch 9: 88.30 %\n",
      "Val Loss for Epoch 9: 0.5365 \n",
      "Val Accuracy for Epoch 9: 76.40 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Early Stop Count 3\n",
      "Starting epoch 11\n",
      "Train Loss for Epoch 10: 0.4572 \n",
      "Train Accuracy for Epoch 10: 88.58 %\n",
      "Val Loss for Epoch 10: 0.4310 \n",
      "Val Accuracy for Epoch 10: 89.89 %\n",
      "--------------------------------\n",
      "Early Stop Count 0\n",
      "Starting epoch 12\n",
      "Train Loss for Epoch 11: 0.4073 \n",
      "Train Accuracy for Epoch 11: 90.25 %\n",
      "Val Loss for Epoch 11: 0.3839 \n",
      "Val Accuracy for Epoch 11: 92.13 %\n",
      "--------------------------------\n",
      "Found better model...saving\n",
      "Early Stop Count 0\n",
      "Starting epoch 13\n",
      "Train Loss for Epoch 12: 0.3514 \n",
      "Train Accuracy for Epoch 12: 94.15 %\n",
      "Val Loss for Epoch 12: 0.3965 \n",
      "Val Accuracy for Epoch 12: 87.64 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Early Stop Count 1\n",
      "Starting epoch 14\n",
      "Train Loss for Epoch 13: 0.3190 \n",
      "Train Accuracy for Epoch 13: 93.59 %\n",
      "Val Loss for Epoch 13: 0.3253 \n",
      "Val Accuracy for Epoch 13: 92.13 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Early Stop Count 2\n",
      "Starting epoch 15\n",
      "Train Loss for Epoch 14: 0.3008 \n",
      "Train Accuracy for Epoch 14: 93.59 %\n",
      "Val Loss for Epoch 14: 0.4039 \n",
      "Val Accuracy for Epoch 14: 86.52 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Early Stop Count 3\n",
      "Starting epoch 16\n",
      "Train Loss for Epoch 15: 0.3086 \n",
      "Train Accuracy for Epoch 15: 92.76 %\n",
      "Val Loss for Epoch 15: 0.3022 \n",
      "Val Accuracy for Epoch 15: 92.13 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Early Stop Count 4\n",
      "Starting epoch 17\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss for Epoch 16: 0.2871 \n",
      "Train Accuracy for Epoch 16: 92.76 %\n",
      "Val Loss for Epoch 16: 0.2694 \n",
      "Val Accuracy for Epoch 16: 93.26 %\n",
      "--------------------------------\n",
      "Found better model...saving\n",
      "Early Stop Count 0\n",
      "Starting epoch 18\n",
      "Train Loss for Epoch 17: 0.3135 \n",
      "Train Accuracy for Epoch 17: 90.53 %\n",
      "Val Loss for Epoch 17: 0.2725 \n",
      "Val Accuracy for Epoch 17: 93.26 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Early Stop Count 1\n",
      "Starting epoch 19\n",
      "Train Loss for Epoch 18: 0.2673 \n",
      "Train Accuracy for Epoch 18: 91.92 %\n",
      "Val Loss for Epoch 18: 0.3250 \n",
      "Val Accuracy for Epoch 18: 88.76 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Early Stop Count 2\n",
      "Starting epoch 20\n",
      "Train Loss for Epoch 19: 0.2419 \n",
      "Train Accuracy for Epoch 19: 94.71 %\n",
      "Val Loss for Epoch 19: 0.2829 \n",
      "Val Accuracy for Epoch 19: 89.89 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Early Stop Count 3\n",
      "Starting epoch 21\n",
      "Train Loss for Epoch 20: 0.2227 \n",
      "Train Accuracy for Epoch 20: 94.43 %\n",
      "Val Loss for Epoch 20: 0.2746 \n",
      "Val Accuracy for Epoch 20: 89.89 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Early Stop Count 4\n",
      "Starting epoch 22\n",
      "Train Loss for Epoch 21: 0.2308 \n",
      "Train Accuracy for Epoch 21: 93.31 %\n",
      "Val Loss for Epoch 21: 0.2567 \n",
      "Val Accuracy for Epoch 21: 94.38 %\n",
      "--------------------------------\n",
      "Found better model...saving\n",
      "Early Stop Count 0\n",
      "Starting epoch 23\n",
      "Train Loss for Epoch 22: 0.2227 \n",
      "Train Accuracy for Epoch 22: 94.99 %\n",
      "Val Loss for Epoch 22: 0.2650 \n",
      "Val Accuracy for Epoch 22: 92.13 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Early Stop Count 1\n",
      "Starting epoch 24\n",
      "Train Loss for Epoch 23: 0.2568 \n",
      "Train Accuracy for Epoch 23: 92.48 %\n",
      "Val Loss for Epoch 23: 0.2888 \n",
      "Val Accuracy for Epoch 23: 91.01 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Early Stop Count 2\n",
      "Starting epoch 25\n",
      "Train Loss for Epoch 24: 0.2050 \n",
      "Train Accuracy for Epoch 24: 94.15 %\n",
      "Val Loss for Epoch 24: 0.2781 \n",
      "Val Accuracy for Epoch 24: 89.89 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Early Stop Count 3\n",
      "Starting epoch 26\n",
      "Train Loss for Epoch 25: 0.2128 \n",
      "Train Accuracy for Epoch 25: 96.10 %\n",
      "Val Loss for Epoch 25: 0.2852 \n",
      "Val Accuracy for Epoch 25: 88.76 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Early Stop Count 4\n",
      "Starting epoch 27\n",
      "Train Loss for Epoch 26: 0.1826 \n",
      "Train Accuracy for Epoch 26: 95.26 %\n",
      "Val Loss for Epoch 26: 0.2372 \n",
      "Val Accuracy for Epoch 26: 91.01 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Early Stop Count 5\n",
      "Starting epoch 28\n",
      "Train Loss for Epoch 27: 0.1592 \n",
      "Train Accuracy for Epoch 27: 96.38 %\n",
      "Val Loss for Epoch 27: 0.2394 \n",
      "Val Accuracy for Epoch 27: 91.01 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Early Stop Count 6\n",
      "Starting epoch 29\n",
      "Train Loss for Epoch 28: 0.1546 \n",
      "Train Accuracy for Epoch 28: 95.54 %\n",
      "Val Loss for Epoch 28: 0.2778 \n",
      "Val Accuracy for Epoch 28: 89.89 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Early Stop Count 7\n",
      "Starting epoch 30\n",
      "Train Loss for Epoch 29: 0.1741 \n",
      "Train Accuracy for Epoch 29: 96.10 %\n",
      "Val Loss for Epoch 29: 0.2343 \n",
      "Val Accuracy for Epoch 29: 92.13 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Early Stop Count 8\n",
      "Starting epoch 31\n",
      "Train Loss for Epoch 30: 0.1558 \n",
      "Train Accuracy for Epoch 30: 95.54 %\n",
      "Val Loss for Epoch 30: 0.2241 \n",
      "Val Accuracy for Epoch 30: 93.26 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Early Stop Count 9\n",
      "Starting epoch 32\n",
      "Train Loss for Epoch 31: 0.1207 \n",
      "Train Accuracy for Epoch 31: 96.94 %\n",
      "Val Loss for Epoch 31: 0.2507 \n",
      "Val Accuracy for Epoch 31: 91.01 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Early Stop Count 10\n",
      "Early stopping at Epoch 31\n",
      "Training process has finished. Saving trained model.\n",
      "Starting testing\n",
      "Accuracy for fold 4: 92.13 %\n",
      "--------------------------------\n",
      "K-FOLD CROSS VALIDATION RESULTS FOR 5 FOLDS\n",
      "--------------------------------\n",
      "Fold 0: 93.33333333333333 %\n",
      "Fold 1: 87.77777777777777 %\n",
      "Fold 2: 88.88888888888889 %\n",
      "Fold 3: 88.76404494382022 %\n",
      "Fold 4: 92.13483146067416 %\n",
      "Average: 90.17977528089888 %\n"
     ]
    }
   ],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def evaluate():\n",
    "    avg_acc = 0\n",
    "    avg_f1 = 0\n",
    "    avg_conf = np.zeros((2,2))\n",
    "    \n",
    "    # Preparation\n",
    "    transformer = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5), (0.5)),\n",
    "    ])\n",
    "    test_data_dir = './Prepared_Data/Test/'\n",
    "    test_dataset = MyDataset(root_dir=test_data_dir, transform = transformer)\n",
    "\n",
    "    for i in range(5):\n",
    "        PATH = './Plan3_Models/best/model-fold-' + str(i) + '.pth'\n",
    "        encoder = build_encoder()\n",
    "        decoder = build_decoder()\n",
    "        trained_net = Net(encoder,decoder)\n",
    "        trained_net.load_state_dict(torch.load(PATH))\n",
    "        trained_net.to(device)\n",
    "\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        y_true, y_pred = [], []\n",
    "        testloader = torch.utils.data.DataLoader(\n",
    "            test_dataset,\n",
    "            batch_size = 50)\n",
    "\n",
    "        y_pred = []\n",
    "        y_true = []\n",
    "        with torch.no_grad():\n",
    "            # Iterate over the test data and generate predictions\n",
    "            for i, data in enumerate(testloader, 0):\n",
    "\n",
    "                # Get inputs\n",
    "                inputs = data['images']\n",
    "                targets = data['label']\n",
    "\n",
    "                outputs = None\n",
    "                for index, xbatch in enumerate(inputs):\n",
    "\n",
    "                    xbatch = xbatch.float().to(device)\n",
    "\n",
    "                    # Perform forward pass\n",
    "                    output = sliding_window(xbatch, trained_net)\n",
    "                    if index == 0:\n",
    "                        outputs = output\n",
    "                    else:\n",
    "                        outputs = torch.vstack([outputs, output])\n",
    "\n",
    "                # Compute loss\n",
    "                ybatches = targets.to(device)\n",
    "                outputs = torch.reshape(outputs, (ybatches.shape[0],NUM_CLASS))\n",
    "\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                _, truth = torch.max(ybatches, 1)\n",
    "                total += targets.size(0)\n",
    "                correct += (predicted == truth).sum().item()\n",
    "\n",
    "                y_pred.extend(predicted.cpu())\n",
    "                y_true.extend(truth.cpu())\n",
    "\n",
    "        # Print accuracy\n",
    "        print(\"Accuracy\", 100.0 * correct / total)\n",
    "        f1 = f1_score(y_true, y_pred, labels=[0,1], average = 'binary')\n",
    "        confusion_matr = confusion_matrix(y_true, y_pred, labels=[0,1])\n",
    "        print(\"F1\", f1)\n",
    "        print(confusion_matr)\n",
    "\n",
    "        avg_acc += 100.0 * correct / total\n",
    "        avg_f1 += f1\n",
    "        np.add(avg_conf, np.array(confusion_matr))\n",
    "\n",
    "    avg_acc = avg_acc/5\n",
    "    avg_f1 = avg_f1/5\n",
    "    np.true_divide(avg_conf, 5)\n",
    "    print(\"--------------Average------------\")\n",
    "    print('Avg Accuracy', avg_acc)\n",
    "    print('Avg F1', avg_f1)\n",
    "    print('Avg Confusion', avg_conf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 93.75\n",
      "F1 0.9393939393939394\n",
      "[[29  3]\n",
      " [ 1 31]]\n",
      "Accuracy 81.25\n",
      "F1 0.8421052631578948\n",
      "[[20 12]\n",
      " [ 0 32]]\n",
      "Accuracy 89.0625\n",
      "F1 0.8955223880597014\n",
      "[[27  5]\n",
      " [ 2 30]]\n",
      "Accuracy 84.375\n",
      "F1 0.8387096774193549\n",
      "[[28  4]\n",
      " [ 6 26]]\n",
      "Accuracy 90.625\n",
      "F1 0.911764705882353\n",
      "[[27  5]\n",
      " [ 1 31]]\n",
      "--------------Average------------\n",
      "Avg Accuracy 87.8125\n",
      "Avg F1 0.8854991947826487\n",
      "Avg Confusion [[0. 0.]\n",
      " [0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "class DomainADDataset(Dataset):\n",
    "    def __init__(self, root_dir=None, transform=None):\n",
    "        path = os.path.join(root_dir,'labels.csv')\n",
    "        self.ylabels = pd.read_csv(path)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.ylabels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        seq_len = 5\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    " \n",
    "        label = self.ylabels.iloc[idx]['Label']\n",
    "        parti_id = self.ylabels.iloc[idx]['ID']\n",
    "        label_str = str(label) + '/'\n",
    "        img_folder = os.path.join(self.root_dir, label_str)\n",
    "        \n",
    "        img_arr = np.zeros((5, 1, 64, 64))\n",
    "        for i in range (5):\n",
    "            img_name = img_folder + str(parti_id) + '-' + str(i) + '.jpg'\n",
    "            image = io.imread(img_name)\n",
    "            if self.transform:\n",
    "                image = self.transform(image)\n",
    "            img_arr[i][0] = image\n",
    "            \n",
    "        label_1hot = np.zeros(NUM_CLASS)\n",
    "        label_1hot[label] = 1.0\n",
    "        label_1hot = torch.Tensor(label_1hot)\n",
    "#         label = np.array([label])\n",
    "        label = torch.LongTensor(np.array([label]))\n",
    "        sample = {'images': img_arr, 'label': label_1hot}\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Supervised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def train_tf():\n",
    "    #---------------Config---------------\n",
    "    num_epochs = 50\n",
    "    k_folds = 5\n",
    "    patience = 5\n",
    "    batch_size = 1\n",
    "    PATH = './Plan3_Models/best/model-fold-' + str(0) + '.pth'\n",
    "    #---------------Config---------------\n",
    "    \n",
    "    # Preparation\n",
    "    weight = torch.tensor([1,1.03]).to(device)\n",
    "    \n",
    "    loss_function = nn.BCELoss(weight=weight)\n",
    "\n",
    "    transformer = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5), (0.5)),\n",
    "    ])\n",
    "    \n",
    "    train_data_dir = './SelfLabelEngagement_Prepared/Train/'\n",
    "    train_dataset = DomainADDataset(root_dir=train_data_dir, transform = transformer)\n",
    "\n",
    "    val_data_dir = './SelfLabelEngagement_Prepared/Validation/'\n",
    "    val_dataset = DomainADDataset(root_dir=val_data_dir, transform = transformer)\n",
    "\n",
    "    dataset = ConcatDataset([train_dataset, val_dataset])\n",
    "\n",
    "    kfold = KFold(n_splits=k_folds, shuffle=True)\n",
    "    \n",
    "    results = {}\n",
    "\n",
    "    # K-fold Cross Validation model evaluation\n",
    "    for fold, (train_ids, val_ids) in enumerate(kfold.split(dataset)):\n",
    "        \n",
    "        training_details = []\n",
    "        best_model = None\n",
    "\n",
    "        # Print\n",
    "        print(f'FOLD {fold}')\n",
    "        print('--------------------------------')\n",
    "\n",
    "        # Sample elements randomly from a given list of ids, no replacement.\n",
    "        train_subsampler = torch.utils.data.SubsetRandomSampler(train_ids)\n",
    "        val_subsampler = torch.utils.data.SubsetRandomSampler(val_ids)\n",
    "\n",
    "        # Define data loaders for training and testing data in this fold\n",
    "        trainloader = torch.utils.data.DataLoader(\n",
    "                        dataset,\n",
    "                        batch_size=batch_size, sampler=train_subsampler)\n",
    "        valloader = torch.utils.data.DataLoader(\n",
    "                        dataset,\n",
    "                        batch_size=batch_size, sampler=val_subsampler)\n",
    "\n",
    "        # Init the neural network\n",
    "        encoder = build_encoder()\n",
    "        decoder = build_decoder()\n",
    "        network = Net(encoder, decoder)\n",
    "        network.load_state_dict(torch.load(PATH))\n",
    "        for param in network.in_encoder.parameters():\n",
    "            param.requires_grad = False\n",
    "        network.to(device) #use GPU\n",
    "        use_gpu = True\n",
    "\n",
    "        # Initialize optimizer\n",
    "        optimizer = optim.Adam(network.parameters(), lr=0.0005)\n",
    "        max_train_acc, max_val_acc = 0, 0\n",
    "        early_stop_count = 0\n",
    "        # Run the training loop for defined number of epochs\n",
    "        for epoch in range(0, num_epochs):\n",
    "\n",
    "            correct, total = 0, 0\n",
    "            # Print epoch\n",
    "            print(f'Starting epoch {epoch+1}')\n",
    "            # Set current loss value\n",
    "            current_loss = 0.0\n",
    "            epoch_loss = 0.0\n",
    "            # Iterate over the DataLoader for training data\n",
    "            for i, data in enumerate(trainloader, 0):\n",
    "            # Starting 1 cycle of mini-batch\n",
    "\n",
    "                # Get inputs\n",
    "                # Get inputs\n",
    "                inputs = data['images']\n",
    "                targets = data['label']\n",
    "\n",
    "                outputs = None\n",
    "                for index, xbatch in enumerate(inputs):\n",
    "                    # Zero the gradients\n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "                    xbatch = xbatch.float().to(device)\n",
    "                    output = sliding_window(xbatch, network)\n",
    "\n",
    "                    # Perform forward pass\n",
    "                    if index == 0:\n",
    "                        outputs = output\n",
    "                    else:\n",
    "                        outputs = torch.vstack([outputs, output])\n",
    "\n",
    "                # Compute loss\n",
    "                ybatches = targets.to(device)\n",
    "                outputs = torch.reshape(outputs, (ybatches.shape[0],NUM_CLASS))\n",
    "                loss = loss_function(outputs, ybatches)\n",
    "\n",
    "                # Perform backward pass\n",
    "                loss.backward()\n",
    "\n",
    "                # Perform optimization\n",
    "                optimizer.step()\n",
    "\n",
    "                # Print statistics\n",
    "                current_loss += loss.item()\n",
    "                epoch_loss += loss.item()\n",
    "\n",
    "                # Compute Accuracy\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                _, truth = torch.max(ybatches, 1)\n",
    "                total += targets.size(0)\n",
    "                correct += (predicted == truth).sum().item()\n",
    "\n",
    "            epoch_loss = epoch_loss/(i+1)\n",
    "            epoch_acc = 100.0 * correct / total\n",
    "            print('Train Loss for Epoch %d: %.4f ' % (epoch, epoch_loss))\n",
    "            print('Train Accuracy for Epoch %d: %.2f %%' % (epoch, epoch_acc))\n",
    "            val_loss, val_acc = check_validation(network.state_dict(), valloader, loss_function)\n",
    "            print('Val Loss for Epoch %d: %.4f ' % (epoch, val_loss))\n",
    "            print('Val Accuracy for Epoch %d: %.2f %%' % (epoch, val_acc))\n",
    "            print('--------------------------------')\n",
    "\n",
    "            training_details.append([epoch_acc, epoch_loss, val_acc, val_loss])\n",
    "\n",
    "            stop_improving = False\n",
    "            if val_acc > max_val_acc:\n",
    "                max_val_acc = val_acc\n",
    "                early_stop_count = 0\n",
    "            else:\n",
    "                early_stop_count += 1\n",
    "                stop_improving = True\n",
    "                print(\"Early Stop Count Increased\")\n",
    "\n",
    "            if epoch_acc > max_train_acc and not stop_improving:\n",
    "                max_train_acc = copy.deepcopy(epoch_acc)\n",
    "                best_model = copy.deepcopy(network.state_dict())\n",
    "                print(\"Found better model...saving\")\n",
    "            \n",
    "            print(\"Early Stop Count\", early_stop_count)\n",
    "            if early_stop_count >= patience:\n",
    "                print(\"Early stopping at Epoch\", epoch)\n",
    "                break\n",
    "\n",
    "\n",
    "        # Process is complete.\n",
    "        print('Training process has finished. Saving trained model.')\n",
    "\n",
    "        # Print about testing\n",
    "        print('Starting testing')\n",
    "\n",
    "        # Saving the model\n",
    "        save_path = f'./models/model-fold-{fold}.pth'\n",
    "        save_path_csv = f'./models/model-fold-{fold}.csv'\n",
    "        torch.save(best_model, save_path)\n",
    "\n",
    "        training_details = np.array(training_details)\n",
    "        df = {'epoch acc': training_details[:,0], \n",
    "              'epoch loss': training_details[:,1], \n",
    "              'val acc': training_details[:,2], \n",
    "              'val loss': training_details[:,3], }\n",
    "        pd.DataFrame(df).to_csv(save_path_csv)\n",
    "\n",
    "        # Evaluationfor this fold\n",
    "        correct, total = 0, 0\n",
    "        with torch.no_grad():\n",
    "            val_loss, val_acc = check_validation(torch.load(save_path), valloader, loss_function)\n",
    "            # Print accuracy\n",
    "            print('Accuracy for fold %d: %.2f %%' % (fold, val_acc))\n",
    "            print('--------------------------------')\n",
    "            results[fold] = val_acc\n",
    "\n",
    "    # Print fold results\n",
    "    print(f'K-FOLD CROSS VALIDATION RESULTS FOR {k_folds} FOLDS')\n",
    "    print('--------------------------------')\n",
    "    sum = 0.0\n",
    "    for key, value in results.items():\n",
    "        print(f'Fold {key}: {value} %')\n",
    "        sum += value\n",
    "    print(f'Average: {sum/len(results.items())} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "--------------------------------\n",
      "Starting epoch 1\n",
      "Train Loss for Epoch 0: 0.7342 \n",
      "Train Accuracy for Epoch 0: 40.29 %\n",
      "Val Loss for Epoch 0: 0.7032 \n",
      "Val Accuracy for Epoch 0: 60.00 %\n",
      "--------------------------------\n",
      "Found better model...saving\n",
      "Early Stop Count 0\n",
      "Starting epoch 2\n",
      "Train Loss for Epoch 1: 0.7225 \n",
      "Train Accuracy for Epoch 1: 45.32 %\n",
      "Val Loss for Epoch 1: 0.6985 \n",
      "Val Accuracy for Epoch 1: 51.43 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Early Stop Count 1\n",
      "Starting epoch 3\n",
      "Train Loss for Epoch 2: 0.7164 \n",
      "Train Accuracy for Epoch 2: 50.36 %\n",
      "Val Loss for Epoch 2: 0.7236 \n",
      "Val Accuracy for Epoch 2: 42.86 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Early Stop Count 2\n",
      "Starting epoch 4\n",
      "Train Loss for Epoch 3: 0.7207 \n",
      "Train Accuracy for Epoch 3: 49.64 %\n",
      "Val Loss for Epoch 3: 0.6922 \n",
      "Val Accuracy for Epoch 3: 51.43 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Early Stop Count 3\n",
      "Starting epoch 5\n",
      "Train Loss for Epoch 4: 0.7210 \n",
      "Train Accuracy for Epoch 4: 53.96 %\n",
      "Val Loss for Epoch 4: 0.7154 \n",
      "Val Accuracy for Epoch 4: 48.57 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Early Stop Count 4\n",
      "Starting epoch 6\n",
      "Train Loss for Epoch 5: 0.7177 \n",
      "Train Accuracy for Epoch 5: 51.80 %\n",
      "Val Loss for Epoch 5: 0.7068 \n",
      "Val Accuracy for Epoch 5: 45.71 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Early Stop Count 5\n",
      "Early stopping at Epoch 5\n",
      "Training process has finished. Saving trained model.\n",
      "Starting testing\n",
      "Accuracy for fold 0: 62.86 %\n",
      "--------------------------------\n",
      "FOLD 1\n",
      "--------------------------------\n",
      "Starting epoch 1\n",
      "Train Loss for Epoch 0: 0.7361 \n",
      "Train Accuracy for Epoch 0: 43.88 %\n",
      "Val Loss for Epoch 0: 0.7179 \n",
      "Val Accuracy for Epoch 0: 45.71 %\n",
      "--------------------------------\n",
      "Found better model...saving\n",
      "Early Stop Count 0\n",
      "Starting epoch 2\n",
      "Train Loss for Epoch 1: 0.7142 \n",
      "Train Accuracy for Epoch 1: 47.48 %\n",
      "Val Loss for Epoch 1: 0.7080 \n",
      "Val Accuracy for Epoch 1: 42.86 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Early Stop Count 1\n",
      "Starting epoch 3\n",
      "Train Loss for Epoch 2: 0.7183 \n",
      "Train Accuracy for Epoch 2: 46.76 %\n",
      "Val Loss for Epoch 2: 0.7168 \n",
      "Val Accuracy for Epoch 2: 51.43 %\n",
      "--------------------------------\n",
      "Found better model...saving\n",
      "Early Stop Count 0\n",
      "Starting epoch 4\n",
      "Train Loss for Epoch 3: 0.7201 \n",
      "Train Accuracy for Epoch 3: 43.17 %\n",
      "Val Loss for Epoch 3: 0.7202 \n",
      "Val Accuracy for Epoch 3: 51.43 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Early Stop Count 1\n",
      "Starting epoch 5\n",
      "Train Loss for Epoch 4: 0.7181 \n",
      "Train Accuracy for Epoch 4: 46.04 %\n",
      "Val Loss for Epoch 4: 0.7137 \n",
      "Val Accuracy for Epoch 4: 48.57 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Early Stop Count 2\n",
      "Starting epoch 6\n",
      "Train Loss for Epoch 5: 0.7138 \n",
      "Train Accuracy for Epoch 5: 48.92 %\n",
      "Val Loss for Epoch 5: 0.7096 \n",
      "Val Accuracy for Epoch 5: 54.29 %\n",
      "--------------------------------\n",
      "Found better model...saving\n",
      "Early Stop Count 0\n",
      "Starting epoch 7\n",
      "Train Loss for Epoch 6: 0.7206 \n",
      "Train Accuracy for Epoch 6: 46.76 %\n",
      "Val Loss for Epoch 6: 0.7119 \n",
      "Val Accuracy for Epoch 6: 51.43 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Early Stop Count 1\n",
      "Starting epoch 8\n",
      "Train Loss for Epoch 7: 0.7110 \n",
      "Train Accuracy for Epoch 7: 48.20 %\n",
      "Val Loss for Epoch 7: 0.7134 \n",
      "Val Accuracy for Epoch 7: 48.57 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Early Stop Count 2\n",
      "Starting epoch 9\n",
      "Train Loss for Epoch 8: 0.7160 \n",
      "Train Accuracy for Epoch 8: 48.20 %\n",
      "Val Loss for Epoch 8: 0.7138 \n",
      "Val Accuracy for Epoch 8: 48.57 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Early Stop Count 3\n",
      "Starting epoch 10\n",
      "Train Loss for Epoch 9: 0.7157 \n",
      "Train Accuracy for Epoch 9: 46.04 %\n",
      "Val Loss for Epoch 9: 0.7143 \n",
      "Val Accuracy for Epoch 9: 51.43 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Early Stop Count 4\n",
      "Starting epoch 11\n",
      "Train Loss for Epoch 10: 0.7158 \n",
      "Train Accuracy for Epoch 10: 49.64 %\n",
      "Val Loss for Epoch 10: 0.7081 \n",
      "Val Accuracy for Epoch 10: 54.29 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Early Stop Count 5\n",
      "Early stopping at Epoch 10\n",
      "Training process has finished. Saving trained model.\n",
      "Starting testing\n",
      "Accuracy for fold 1: 51.43 %\n",
      "--------------------------------\n",
      "FOLD 2\n",
      "--------------------------------\n",
      "Starting epoch 1\n",
      "Train Loss for Epoch 0: 0.7220 \n",
      "Train Accuracy for Epoch 0: 48.92 %\n",
      "Val Loss for Epoch 0: 0.7282 \n",
      "Val Accuracy for Epoch 0: 42.86 %\n",
      "--------------------------------\n",
      "Found better model...saving\n",
      "Early Stop Count 0\n",
      "Starting epoch 2\n",
      "Train Loss for Epoch 1: 0.7157 \n",
      "Train Accuracy for Epoch 1: 48.20 %\n",
      "Val Loss for Epoch 1: 0.7256 \n",
      "Val Accuracy for Epoch 1: 45.71 %\n",
      "--------------------------------\n",
      "Early Stop Count 0\n",
      "Starting epoch 3\n",
      "Train Loss for Epoch 2: 0.7176 \n",
      "Train Accuracy for Epoch 2: 49.64 %\n",
      "Val Loss for Epoch 2: 0.7213 \n",
      "Val Accuracy for Epoch 2: 45.71 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Early Stop Count 1\n",
      "Starting epoch 4\n",
      "Train Loss for Epoch 3: 0.7131 \n",
      "Train Accuracy for Epoch 3: 46.76 %\n",
      "Val Loss for Epoch 3: 0.7260 \n",
      "Val Accuracy for Epoch 3: 42.86 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Early Stop Count 2\n",
      "Starting epoch 5\n",
      "Train Loss for Epoch 4: 0.7191 \n",
      "Train Accuracy for Epoch 4: 46.76 %\n",
      "Val Loss for Epoch 4: 0.7331 \n",
      "Val Accuracy for Epoch 4: 37.14 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Early Stop Count 3\n",
      "Starting epoch 6\n",
      "Train Loss for Epoch 5: 0.7204 \n",
      "Train Accuracy for Epoch 5: 43.17 %\n",
      "Val Loss for Epoch 5: 0.7116 \n",
      "Val Accuracy for Epoch 5: 51.43 %\n",
      "--------------------------------\n",
      "Early Stop Count 0\n",
      "Starting epoch 7\n",
      "Train Loss for Epoch 6: 0.7187 \n",
      "Train Accuracy for Epoch 6: 46.76 %\n",
      "Val Loss for Epoch 6: 0.7080 \n",
      "Val Accuracy for Epoch 6: 57.14 %\n",
      "--------------------------------\n",
      "Early Stop Count 0\n",
      "Starting epoch 8\n",
      "Train Loss for Epoch 7: 0.7138 \n",
      "Train Accuracy for Epoch 7: 48.20 %\n",
      "Val Loss for Epoch 7: 0.7155 \n",
      "Val Accuracy for Epoch 7: 51.43 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Early Stop Count 1\n",
      "Starting epoch 9\n",
      "Train Loss for Epoch 8: 0.7141 \n",
      "Train Accuracy for Epoch 8: 48.20 %\n",
      "Val Loss for Epoch 8: 0.7141 \n",
      "Val Accuracy for Epoch 8: 57.14 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Early Stop Count 2\n",
      "Starting epoch 10\n",
      "Train Loss for Epoch 9: 0.7154 \n",
      "Train Accuracy for Epoch 9: 50.36 %\n",
      "Val Loss for Epoch 9: 0.7166 \n",
      "Val Accuracy for Epoch 9: 51.43 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Early Stop Count 3\n",
      "Starting epoch 11\n",
      "Train Loss for Epoch 10: 0.7162 \n",
      "Train Accuracy for Epoch 10: 45.32 %\n",
      "Val Loss for Epoch 10: 0.7077 \n",
      "Val Accuracy for Epoch 10: 54.29 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Early Stop Count 4\n",
      "Starting epoch 12\n",
      "Train Loss for Epoch 11: 0.7150 \n",
      "Train Accuracy for Epoch 11: 47.48 %\n",
      "Val Loss for Epoch 11: 0.7146 \n",
      "Val Accuracy for Epoch 11: 51.43 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Early Stop Count 5\n",
      "Early stopping at Epoch 11\n",
      "Training process has finished. Saving trained model.\n",
      "Starting testing\n",
      "Accuracy for fold 2: 37.14 %\n",
      "--------------------------------\n",
      "FOLD 3\n",
      "--------------------------------\n",
      "Starting epoch 1\n",
      "Train Loss for Epoch 0: 0.7314 \n",
      "Train Accuracy for Epoch 0: 43.17 %\n",
      "Val Loss for Epoch 0: 0.7256 \n",
      "Val Accuracy for Epoch 0: 42.86 %\n",
      "--------------------------------\n",
      "Found better model...saving\n",
      "Early Stop Count 0\n",
      "Starting epoch 2\n",
      "Train Loss for Epoch 1: 0.7127 \n",
      "Train Accuracy for Epoch 1: 49.64 %\n",
      "Val Loss for Epoch 1: 0.7398 \n",
      "Val Accuracy for Epoch 1: 42.86 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Early Stop Count 1\n",
      "Starting epoch 3\n",
      "Train Loss for Epoch 2: 0.7097 \n",
      "Train Accuracy for Epoch 2: 51.80 %\n",
      "Val Loss for Epoch 2: 0.7375 \n",
      "Val Accuracy for Epoch 2: 40.00 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Early Stop Count 2\n",
      "Starting epoch 4\n",
      "Train Loss for Epoch 3: 0.7114 \n",
      "Train Accuracy for Epoch 3: 51.08 %\n",
      "Val Loss for Epoch 3: 0.7461 \n",
      "Val Accuracy for Epoch 3: 48.57 %\n",
      "--------------------------------\n",
      "Found better model...saving\n",
      "Early Stop Count 0\n",
      "Starting epoch 5\n",
      "Train Loss for Epoch 4: 0.7095 \n",
      "Train Accuracy for Epoch 4: 53.96 %\n",
      "Val Loss for Epoch 4: 0.7300 \n",
      "Val Accuracy for Epoch 4: 42.86 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Early Stop Count 1\n",
      "Starting epoch 6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss for Epoch 5: 0.7158 \n",
      "Train Accuracy for Epoch 5: 48.92 %\n",
      "Val Loss for Epoch 5: 0.7526 \n",
      "Val Accuracy for Epoch 5: 37.14 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Early Stop Count 2\n",
      "Starting epoch 7\n",
      "Train Loss for Epoch 6: 0.7093 \n",
      "Train Accuracy for Epoch 6: 56.12 %\n",
      "Val Loss for Epoch 6: 0.7527 \n",
      "Val Accuracy for Epoch 6: 45.71 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Early Stop Count 3\n",
      "Starting epoch 8\n",
      "Train Loss for Epoch 7: 0.7109 \n",
      "Train Accuracy for Epoch 7: 53.24 %\n",
      "Val Loss for Epoch 7: 0.7440 \n",
      "Val Accuracy for Epoch 7: 42.86 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Early Stop Count 4\n",
      "Starting epoch 9\n",
      "Train Loss for Epoch 8: 0.7111 \n",
      "Train Accuracy for Epoch 8: 51.80 %\n",
      "Val Loss for Epoch 8: 0.7430 \n",
      "Val Accuracy for Epoch 8: 48.57 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Early Stop Count 5\n",
      "Early stopping at Epoch 8\n",
      "Training process has finished. Saving trained model.\n",
      "Starting testing\n",
      "Accuracy for fold 3: 48.57 %\n",
      "--------------------------------\n",
      "FOLD 4\n",
      "--------------------------------\n",
      "Starting epoch 1\n",
      "Train Loss for Epoch 0: 0.7152 \n",
      "Train Accuracy for Epoch 0: 47.14 %\n",
      "Val Loss for Epoch 0: 0.7307 \n",
      "Val Accuracy for Epoch 0: 44.12 %\n",
      "--------------------------------\n",
      "Found better model...saving\n",
      "Early Stop Count 0\n",
      "Starting epoch 2\n",
      "Train Loss for Epoch 1: 0.7221 \n",
      "Train Accuracy for Epoch 1: 48.57 %\n",
      "Val Loss for Epoch 1: 0.7237 \n",
      "Val Accuracy for Epoch 1: 35.29 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Early Stop Count 1\n",
      "Starting epoch 3\n",
      "Train Loss for Epoch 2: 0.7098 \n",
      "Train Accuracy for Epoch 2: 52.14 %\n",
      "Val Loss for Epoch 2: 0.7184 \n",
      "Val Accuracy for Epoch 2: 47.06 %\n",
      "--------------------------------\n",
      "Found better model...saving\n",
      "Early Stop Count 0\n",
      "Starting epoch 4\n",
      "Train Loss for Epoch 3: 0.7171 \n",
      "Train Accuracy for Epoch 3: 45.00 %\n",
      "Val Loss for Epoch 3: 0.7263 \n",
      "Val Accuracy for Epoch 3: 38.24 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Early Stop Count 1\n",
      "Starting epoch 5\n",
      "Train Loss for Epoch 4: 0.7119 \n",
      "Train Accuracy for Epoch 4: 50.71 %\n",
      "Val Loss for Epoch 4: 0.7274 \n",
      "Val Accuracy for Epoch 4: 38.24 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Early Stop Count 2\n",
      "Starting epoch 6\n",
      "Train Loss for Epoch 5: 0.7143 \n",
      "Train Accuracy for Epoch 5: 50.00 %\n",
      "Val Loss for Epoch 5: 0.7212 \n",
      "Val Accuracy for Epoch 5: 38.24 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Early Stop Count 3\n",
      "Starting epoch 7\n",
      "Train Loss for Epoch 6: 0.7189 \n",
      "Train Accuracy for Epoch 6: 50.00 %\n",
      "Val Loss for Epoch 6: 0.7237 \n",
      "Val Accuracy for Epoch 6: 38.24 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Early Stop Count 4\n",
      "Starting epoch 8\n",
      "Train Loss for Epoch 7: 0.7148 \n",
      "Train Accuracy for Epoch 7: 50.71 %\n",
      "Val Loss for Epoch 7: 0.7189 \n",
      "Val Accuracy for Epoch 7: 38.24 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Early Stop Count 5\n",
      "Early stopping at Epoch 7\n",
      "Training process has finished. Saving trained model.\n",
      "Starting testing\n",
      "Accuracy for fold 4: 41.18 %\n",
      "--------------------------------\n",
      "K-FOLD CROSS VALIDATION RESULTS FOR 5 FOLDS\n",
      "--------------------------------\n",
      "Fold 0: 62.857142857142854 %\n",
      "Fold 1: 51.42857142857143 %\n",
      "Fold 2: 37.142857142857146 %\n",
      "Fold 3: 48.57142857142857 %\n",
      "Fold 4: 41.1764705882353 %\n",
      "Average: 48.23529411764706 %\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(32)\n",
    "train_tf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "code_folding": [
     1
    ]
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(32)\n",
    "def evaluate():\n",
    "    avg_acc = 0\n",
    "    avg_f1 = 0\n",
    "    avg_conf = np.zeros((2,2))\n",
    "    \n",
    "    # Preparation\n",
    "    transformer = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5), (0.5)),\n",
    "    ])\n",
    "    test_data_dir = './SelfLabelEngagement_Prepared/Test/'\n",
    "    test_dataset = DomainADDataset(root_dir=test_data_dir, transform = transformer)\n",
    "\n",
    "    for i in range(5):\n",
    "        PATH = './TF_Models/best/model-fold-' + str(i) + '.pth'\n",
    "        encoder = build_encoder()\n",
    "        decoder = build_decoder()\n",
    "        trained_net = Net(encoder,decoder)\n",
    "        trained_net.load_state_dict(torch.load(PATH))\n",
    "        trained_net.to(device)\n",
    "\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        y_true, y_pred = [], []\n",
    "        testloader = torch.utils.data.DataLoader(\n",
    "            test_dataset,\n",
    "            batch_size = 50)\n",
    "\n",
    "        y_pred = []\n",
    "        y_true = []\n",
    "        with torch.no_grad():\n",
    "            # Iterate over the test data and generate predictions\n",
    "            for i, data in enumerate(testloader, 0):\n",
    "\n",
    "                # Get inputs\n",
    "                inputs = data['images']\n",
    "                targets = data['label']\n",
    "\n",
    "                outputs = None\n",
    "                for index, xbatch in enumerate(inputs):\n",
    "\n",
    "                    xbatch = xbatch.float().to(device)\n",
    "\n",
    "                    # Perform forward pass\n",
    "                    output = sliding_window(xbatch, trained_net)\n",
    "                    if index == 0:\n",
    "                        outputs = output\n",
    "                    else:\n",
    "                        outputs = torch.vstack([outputs, output])\n",
    "\n",
    "                # Compute loss\n",
    "                ybatches = targets.to(device)\n",
    "                outputs = torch.reshape(outputs, (ybatches.shape[0],NUM_CLASS))\n",
    "\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                _, truth = torch.max(ybatches, 1)\n",
    "                total += targets.size(0)\n",
    "                correct += (predicted == truth).sum().item()\n",
    "\n",
    "                y_pred.extend(predicted.cpu())\n",
    "                y_true.extend(truth.cpu())\n",
    "\n",
    "        # Print accuracy\n",
    "        print(\"Accuracy\", 100.0 * correct / total)\n",
    "        f1 = f1_score(y_true, y_pred, labels=[0,1], average = 'binary')\n",
    "        confusion_matr = confusion_matrix(y_true, y_pred, labels=[0,1])\n",
    "        print(\"F1\", f1)\n",
    "        print(confusion_matr)\n",
    "\n",
    "        avg_acc += 100.0 * correct / total\n",
    "        avg_f1 += f1\n",
    "        np.add(avg_conf, np.array(confusion_matr))\n",
    "\n",
    "    avg_acc = avg_acc/5\n",
    "    avg_f1 = avg_f1/5\n",
    "    np.true_divide(avg_conf, 5)\n",
    "    print(\"--------------Average------------\")\n",
    "    print('Avg Accuracy', avg_acc)\n",
    "    print('Avg F1', avg_f1)\n",
    "    print('Avg Confusion', avg_conf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Semi - Supervised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def semi_train_tf():\n",
    "    #---------------Config---------------\n",
    "    num_epochs = 50\n",
    "    k_folds = 5\n",
    "    patience = 5\n",
    "    batch_size = 1\n",
    "    PATH = './Plan3_Models/best/model-fold-' + str(0) + '.pth'\n",
    "    #---------------Config---------------\n",
    "    \n",
    "    # Preparation\n",
    "    weight = torch.tensor([1,1.03]).to(device)\n",
    "    \n",
    "    loss_function = nn.BCELoss(weight=weight)\n",
    "\n",
    "    transformer = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5), (0.5)),\n",
    "    ])\n",
    "    \n",
    "    train_data_dir = './SelfLabelEngagement_Prepared2/Train/'\n",
    "    train_dataset = DomainADDataset(root_dir=train_data_dir, transform = transformer)\n",
    "\n",
    "    val_data_dir = './SelfLabelEngagement_Prepared2/Validation/'\n",
    "    val_dataset = DomainADDataset(root_dir=val_data_dir, transform = transformer)\n",
    "\n",
    "    dataset = ConcatDataset([train_dataset, val_dataset])\n",
    "\n",
    "    kfold = KFold(n_splits=k_folds, shuffle=True)\n",
    "    \n",
    "    results = {}\n",
    "\n",
    "    # K-fold Cross Validation model evaluation\n",
    "    for fold, (train_ids, val_ids) in enumerate(kfold.split(dataset)):\n",
    "        \n",
    "        training_details = []\n",
    "        best_model = None\n",
    "\n",
    "        # Print\n",
    "        print(f'FOLD {fold}')\n",
    "        print('--------------------------------')\n",
    "\n",
    "        # Sample elements randomly from a given list of ids, no replacement.\n",
    "        train_subsampler = torch.utils.data.SubsetRandomSampler(train_ids)\n",
    "        val_subsampler = torch.utils.data.SubsetRandomSampler(val_ids)\n",
    "\n",
    "        # Define data loaders for training and testing data in this fold\n",
    "        trainloader = torch.utils.data.DataLoader(\n",
    "                        dataset,\n",
    "                        batch_size=batch_size, sampler=train_subsampler)\n",
    "        valloader = torch.utils.data.DataLoader(\n",
    "                        dataset,\n",
    "                        batch_size=batch_size, sampler=val_subsampler)\n",
    "\n",
    "        # Init the neural network\n",
    "        encoder = build_encoder()\n",
    "        decoder = build_decoder()\n",
    "        network = Net(encoder, decoder)\n",
    "        network.load_state_dict(torch.load(PATH))\n",
    "        for param in network.in_encoder.parameters():\n",
    "            param.requires_grad = False\n",
    "        network.to(device) #use GPU\n",
    "        use_gpu = True\n",
    "\n",
    "        # Initialize optimizer\n",
    "        optimizer = optim.Adam(network.parameters(), lr=0.0005)\n",
    "        max_train_acc, max_val_acc = 0, 0\n",
    "        early_stop_count = 0\n",
    "        # Run the training loop for defined number of epochs\n",
    "        for epoch in range(0, num_epochs):\n",
    "\n",
    "            correct, total = 0, 0\n",
    "            # Print epoch\n",
    "            print(f'Starting epoch {epoch+1}')\n",
    "            # Set current loss value\n",
    "            current_loss = 0.0\n",
    "            epoch_loss = 0.0\n",
    "            # Iterate over the DataLoader for training data\n",
    "            for i, data in enumerate(trainloader, 0):\n",
    "            # Starting 1 cycle of mini-batch\n",
    "\n",
    "                # Get inputs\n",
    "                # Get inputs\n",
    "                inputs = data['images']\n",
    "                targets = data['label']\n",
    "\n",
    "                outputs = None\n",
    "                for index, xbatch in enumerate(inputs):\n",
    "                    # Zero the gradients\n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "                    xbatch = xbatch.float().to(device)\n",
    "                    output = sliding_window(xbatch, network)\n",
    "\n",
    "                    # Perform forward pass\n",
    "                    if index == 0:\n",
    "                        outputs = output\n",
    "                    else:\n",
    "                        outputs = torch.vstack([outputs, output])\n",
    "\n",
    "                # Compute loss\n",
    "                ybatches = targets.to(device)\n",
    "                outputs = torch.reshape(outputs, (ybatches.shape[0],NUM_CLASS))\n",
    "                loss = loss_function(outputs, ybatches)\n",
    "\n",
    "                # Perform backward pass\n",
    "                loss.backward()\n",
    "\n",
    "                # Perform optimization\n",
    "                optimizer.step()\n",
    "\n",
    "                # Print statistics\n",
    "                current_loss += loss.item()\n",
    "                epoch_loss += loss.item()\n",
    "\n",
    "                # Compute Accuracy\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                _, truth = torch.max(ybatches, 1)\n",
    "                total += targets.size(0)\n",
    "                correct += (predicted == truth).sum().item()\n",
    "\n",
    "            epoch_loss = epoch_loss/(i+1)\n",
    "            epoch_acc = 100.0 * correct / total\n",
    "            print('Train Loss for Epoch %d: %.4f ' % (epoch, epoch_loss))\n",
    "            print('Train Accuracy for Epoch %d: %.2f %%' % (epoch, epoch_acc))\n",
    "            val_loss, val_acc = check_validation(network.state_dict(), valloader, loss_function)\n",
    "            print('Val Loss for Epoch %d: %.4f ' % (epoch, val_loss))\n",
    "            print('Val Accuracy for Epoch %d: %.2f %%' % (epoch, val_acc))\n",
    "            print('--------------------------------')\n",
    "\n",
    "            training_details.append([epoch_acc, epoch_loss, val_acc, val_loss])\n",
    "\n",
    "            stop_improving = False\n",
    "            if val_acc > max_val_acc:\n",
    "                max_val_acc = val_acc\n",
    "                early_stop_count = 0\n",
    "            else:\n",
    "                early_stop_count += 1\n",
    "                stop_improving = True\n",
    "                print(\"Early Stop Count Increased\")\n",
    "\n",
    "            if epoch_acc > max_train_acc and not stop_improving:\n",
    "                max_train_acc = copy.deepcopy(epoch_acc)\n",
    "                best_model = copy.deepcopy(network.state_dict())\n",
    "                print(\"Found better model...saving\")\n",
    "            \n",
    "            print(\"Early Stop Count\", early_stop_count)\n",
    "            if early_stop_count >= patience:\n",
    "                print(\"Early stopping at Epoch\", epoch)\n",
    "                break\n",
    "\n",
    "\n",
    "        # Process is complete.\n",
    "        print('Training process has finished. Saving trained model.')\n",
    "\n",
    "        # Print about testing\n",
    "        print('Starting testing')\n",
    "\n",
    "        # Saving the model\n",
    "        save_path = f'./models/model-fold-{fold}.pth'\n",
    "        save_path_csv = f'./models/model-fold-{fold}.csv'\n",
    "        torch.save(best_model, save_path)\n",
    "\n",
    "        training_details = np.array(training_details)\n",
    "        df = {'epoch acc': training_details[:,0], \n",
    "              'epoch loss': training_details[:,1], \n",
    "              'val acc': training_details[:,2], \n",
    "              'val loss': training_details[:,3], }\n",
    "        pd.DataFrame(df).to_csv(save_path_csv)\n",
    "\n",
    "        # Evaluationfor this fold\n",
    "        correct, total = 0, 0\n",
    "        with torch.no_grad():\n",
    "            val_loss, val_acc = check_validation(torch.load(save_path), valloader, loss_function)\n",
    "            # Print accuracy\n",
    "            print('Accuracy for fold %d: %.2f %%' % (fold, val_acc))\n",
    "            print('--------------------------------')\n",
    "            results[fold] = val_acc\n",
    "\n",
    "    # Print fold results\n",
    "    print(f'K-FOLD CROSS VALIDATION RESULTS FOR {k_folds} FOLDS')\n",
    "    print('--------------------------------')\n",
    "    sum = 0.0\n",
    "    for key, value in results.items():\n",
    "        print(f'Fold {key}: {value} %')\n",
    "        sum += value\n",
    "    print(f'Average: {sum/len(results.items())} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "--------------------------------\n",
      "Starting epoch 1\n",
      "Train Loss for Epoch 0: 0.5993 \n",
      "Train Accuracy for Epoch 0: 63.48 %\n",
      "Val Loss for Epoch 0: 0.5906 \n",
      "Val Accuracy for Epoch 0: 68.97 %\n",
      "--------------------------------\n",
      "Found better model...saving\n",
      "Early Stop Count 0\n",
      "Starting epoch 2\n",
      "Train Loss for Epoch 1: 0.5974 \n",
      "Train Accuracy for Epoch 1: 66.09 %\n",
      "Val Loss for Epoch 1: 0.5831 \n",
      "Val Accuracy for Epoch 1: 68.97 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Early Stop Count 1\n",
      "Starting epoch 3\n",
      "Train Loss for Epoch 2: 0.5925 \n",
      "Train Accuracy for Epoch 2: 64.78 %\n",
      "Val Loss for Epoch 2: 0.5849 \n",
      "Val Accuracy for Epoch 2: 65.52 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Early Stop Count 2\n",
      "Starting epoch 4\n",
      "Train Loss for Epoch 3: 0.5959 \n",
      "Train Accuracy for Epoch 3: 65.65 %\n",
      "Val Loss for Epoch 3: 0.5882 \n",
      "Val Accuracy for Epoch 3: 60.34 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Early Stop Count 3\n",
      "Starting epoch 5\n",
      "Train Loss for Epoch 4: 0.5898 \n",
      "Train Accuracy for Epoch 4: 63.91 %\n",
      "Val Loss for Epoch 4: 0.5836 \n",
      "Val Accuracy for Epoch 4: 67.24 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Early Stop Count 4\n",
      "Starting epoch 6\n",
      "Train Loss for Epoch 5: 0.5908 \n",
      "Train Accuracy for Epoch 5: 63.48 %\n",
      "Val Loss for Epoch 5: 0.5865 \n",
      "Val Accuracy for Epoch 5: 67.24 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Early Stop Count 5\n",
      "Early stopping at Epoch 5\n",
      "Training process has finished. Saving trained model.\n",
      "Starting testing\n",
      "Accuracy for fold 0: 68.97 %\n",
      "--------------------------------\n",
      "FOLD 1\n",
      "--------------------------------\n",
      "Starting epoch 1\n",
      "Train Loss for Epoch 0: 0.5998 \n",
      "Train Accuracy for Epoch 0: 64.35 %\n",
      "Val Loss for Epoch 0: 0.6030 \n",
      "Val Accuracy for Epoch 0: 65.52 %\n",
      "--------------------------------\n",
      "Found better model...saving\n",
      "Early Stop Count 0\n",
      "Starting epoch 2\n",
      "Train Loss for Epoch 1: 0.5936 \n",
      "Train Accuracy for Epoch 1: 63.48 %\n",
      "Val Loss for Epoch 1: 0.6003 \n",
      "Val Accuracy for Epoch 1: 62.07 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Early Stop Count 1\n",
      "Starting epoch 3\n",
      "Train Loss for Epoch 2: 0.5981 \n",
      "Train Accuracy for Epoch 2: 63.04 %\n",
      "Val Loss for Epoch 2: 0.5981 \n",
      "Val Accuracy for Epoch 2: 67.24 %\n",
      "--------------------------------\n",
      "Early Stop Count 0\n",
      "Starting epoch 4\n",
      "Train Loss for Epoch 3: 0.5950 \n",
      "Train Accuracy for Epoch 3: 64.35 %\n",
      "Val Loss for Epoch 3: 0.5998 \n",
      "Val Accuracy for Epoch 3: 65.52 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Early Stop Count 1\n",
      "Starting epoch 5\n",
      "Train Loss for Epoch 4: 0.5879 \n",
      "Train Accuracy for Epoch 4: 65.22 %\n",
      "Val Loss for Epoch 4: 0.5934 \n",
      "Val Accuracy for Epoch 4: 65.52 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Early Stop Count 2\n",
      "Starting epoch 6\n",
      "Train Loss for Epoch 5: 0.5905 \n",
      "Train Accuracy for Epoch 5: 65.22 %\n",
      "Val Loss for Epoch 5: 0.5953 \n",
      "Val Accuracy for Epoch 5: 63.79 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Early Stop Count 3\n",
      "Starting epoch 7\n",
      "Train Loss for Epoch 6: 0.5871 \n",
      "Train Accuracy for Epoch 6: 62.61 %\n",
      "Val Loss for Epoch 6: 0.5857 \n",
      "Val Accuracy for Epoch 6: 68.97 %\n",
      "--------------------------------\n",
      "Early Stop Count 0\n",
      "Starting epoch 8\n",
      "Train Loss for Epoch 7: 0.5879 \n",
      "Train Accuracy for Epoch 7: 66.09 %\n",
      "Val Loss for Epoch 7: 0.5934 \n",
      "Val Accuracy for Epoch 7: 68.97 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Early Stop Count 1\n",
      "Starting epoch 9\n",
      "Train Loss for Epoch 8: 0.5852 \n",
      "Train Accuracy for Epoch 8: 66.09 %\n",
      "Val Loss for Epoch 8: 0.5911 \n",
      "Val Accuracy for Epoch 8: 67.24 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Early Stop Count 2\n",
      "Starting epoch 10\n",
      "Train Loss for Epoch 9: 0.5846 \n",
      "Train Accuracy for Epoch 9: 62.61 %\n",
      "Val Loss for Epoch 9: 0.5784 \n",
      "Val Accuracy for Epoch 9: 70.69 %\n",
      "--------------------------------\n",
      "Early Stop Count 0\n",
      "Starting epoch 11\n",
      "Train Loss for Epoch 10: 0.5831 \n",
      "Train Accuracy for Epoch 10: 64.35 %\n",
      "Val Loss for Epoch 10: 0.5915 \n",
      "Val Accuracy for Epoch 10: 65.52 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Early Stop Count 1\n",
      "Starting epoch 12\n",
      "Train Loss for Epoch 11: 0.5817 \n",
      "Train Accuracy for Epoch 11: 62.61 %\n",
      "Val Loss for Epoch 11: 0.5879 \n",
      "Val Accuracy for Epoch 11: 65.52 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Early Stop Count 2\n",
      "Starting epoch 13\n",
      "Train Loss for Epoch 12: 0.5843 \n",
      "Train Accuracy for Epoch 12: 65.22 %\n",
      "Val Loss for Epoch 12: 0.5906 \n",
      "Val Accuracy for Epoch 12: 67.24 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Early Stop Count 3\n",
      "Starting epoch 14\n",
      "Train Loss for Epoch 13: 0.5834 \n",
      "Train Accuracy for Epoch 13: 65.65 %\n",
      "Val Loss for Epoch 13: 0.5845 \n",
      "Val Accuracy for Epoch 13: 67.24 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Early Stop Count 4\n",
      "Starting epoch 15\n",
      "Train Loss for Epoch 14: 0.5787 \n",
      "Train Accuracy for Epoch 14: 64.35 %\n",
      "Val Loss for Epoch 14: 0.5812 \n",
      "Val Accuracy for Epoch 14: 68.97 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Early Stop Count 5\n",
      "Early stopping at Epoch 14\n",
      "Training process has finished. Saving trained model.\n",
      "Starting testing\n",
      "Accuracy for fold 1: 68.97 %\n",
      "--------------------------------\n",
      "FOLD 2\n",
      "--------------------------------\n",
      "Starting epoch 1\n",
      "Train Loss for Epoch 0: 0.5993 \n",
      "Train Accuracy for Epoch 0: 66.96 %\n",
      "Val Loss for Epoch 0: 0.5754 \n",
      "Val Accuracy for Epoch 0: 63.79 %\n",
      "--------------------------------\n",
      "Found better model...saving\n",
      "Early Stop Count 0\n",
      "Starting epoch 2\n",
      "Train Loss for Epoch 1: 0.6022 \n",
      "Train Accuracy for Epoch 1: 63.04 %\n",
      "Val Loss for Epoch 1: 0.5782 \n",
      "Val Accuracy for Epoch 1: 65.52 %\n",
      "--------------------------------\n",
      "Early Stop Count 0\n",
      "Starting epoch 3\n",
      "Train Loss for Epoch 2: 0.5984 \n",
      "Train Accuracy for Epoch 2: 65.65 %\n",
      "Val Loss for Epoch 2: 0.5787 \n",
      "Val Accuracy for Epoch 2: 68.97 %\n",
      "--------------------------------\n",
      "Early Stop Count 0\n",
      "Starting epoch 4\n",
      "Train Loss for Epoch 3: 0.5979 \n",
      "Train Accuracy for Epoch 3: 66.96 %\n",
      "Val Loss for Epoch 3: 0.5747 \n",
      "Val Accuracy for Epoch 3: 65.52 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Early Stop Count 1\n",
      "Starting epoch 5\n",
      "Train Loss for Epoch 4: 0.5961 \n",
      "Train Accuracy for Epoch 4: 62.17 %\n",
      "Val Loss for Epoch 4: 0.5706 \n",
      "Val Accuracy for Epoch 4: 63.79 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Early Stop Count 2\n",
      "Starting epoch 6\n",
      "Train Loss for Epoch 5: 0.5989 \n",
      "Train Accuracy for Epoch 5: 63.48 %\n",
      "Val Loss for Epoch 5: 0.5795 \n",
      "Val Accuracy for Epoch 5: 60.34 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Early Stop Count 3\n",
      "Starting epoch 7\n",
      "Train Loss for Epoch 6: 0.5937 \n",
      "Train Accuracy for Epoch 6: 65.22 %\n",
      "Val Loss for Epoch 6: 0.5701 \n",
      "Val Accuracy for Epoch 6: 68.97 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Early Stop Count 4\n",
      "Starting epoch 8\n",
      "Train Loss for Epoch 7: 0.5934 \n",
      "Train Accuracy for Epoch 7: 63.04 %\n",
      "Val Loss for Epoch 7: 0.5544 \n",
      "Val Accuracy for Epoch 7: 72.41 %\n",
      "--------------------------------\n",
      "Early Stop Count 0\n",
      "Starting epoch 9\n",
      "Train Loss for Epoch 8: 0.5969 \n",
      "Train Accuracy for Epoch 8: 60.87 %\n",
      "Val Loss for Epoch 8: 0.5630 \n",
      "Val Accuracy for Epoch 8: 68.97 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Early Stop Count 1\n",
      "Starting epoch 10\n",
      "Train Loss for Epoch 9: 0.5904 \n",
      "Train Accuracy for Epoch 9: 65.22 %\n",
      "Val Loss for Epoch 9: 0.5573 \n",
      "Val Accuracy for Epoch 9: 67.24 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Early Stop Count 2\n",
      "Starting epoch 11\n",
      "Train Loss for Epoch 10: 0.5920 \n",
      "Train Accuracy for Epoch 10: 60.43 %\n",
      "Val Loss for Epoch 10: 0.5579 \n",
      "Val Accuracy for Epoch 10: 67.24 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Early Stop Count 3\n",
      "Starting epoch 12\n",
      "Train Loss for Epoch 11: 0.5913 \n",
      "Train Accuracy for Epoch 11: 65.65 %\n",
      "Val Loss for Epoch 11: 0.5612 \n",
      "Val Accuracy for Epoch 11: 63.79 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Early Stop Count 4\n",
      "Starting epoch 13\n",
      "Train Loss for Epoch 12: 0.5952 \n",
      "Train Accuracy for Epoch 12: 64.78 %\n",
      "Val Loss for Epoch 12: 0.5586 \n",
      "Val Accuracy for Epoch 12: 68.97 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Early Stop Count 5\n",
      "Early stopping at Epoch 12\n",
      "Training process has finished. Saving trained model.\n",
      "Starting testing\n",
      "Accuracy for fold 2: 62.07 %\n",
      "--------------------------------\n",
      "FOLD 3\n",
      "--------------------------------\n",
      "Starting epoch 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss for Epoch 0: 0.6009 \n",
      "Train Accuracy for Epoch 0: 62.77 %\n",
      "Val Loss for Epoch 0: 0.6000 \n",
      "Val Accuracy for Epoch 0: 70.18 %\n",
      "--------------------------------\n",
      "Found better model...saving\n",
      "Early Stop Count 0\n",
      "Starting epoch 2\n",
      "Train Loss for Epoch 1: 0.5994 \n",
      "Train Accuracy for Epoch 1: 61.90 %\n",
      "Val Loss for Epoch 1: 0.6182 \n",
      "Val Accuracy for Epoch 1: 63.16 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Early Stop Count 1\n",
      "Starting epoch 3\n",
      "Train Loss for Epoch 2: 0.5903 \n",
      "Train Accuracy for Epoch 2: 65.37 %\n",
      "Val Loss for Epoch 2: 0.6093 \n",
      "Val Accuracy for Epoch 2: 63.16 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Early Stop Count 2\n",
      "Starting epoch 4\n",
      "Train Loss for Epoch 3: 0.5853 \n",
      "Train Accuracy for Epoch 3: 66.67 %\n",
      "Val Loss for Epoch 3: 0.6155 \n",
      "Val Accuracy for Epoch 3: 61.40 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Early Stop Count 3\n",
      "Starting epoch 5\n",
      "Train Loss for Epoch 4: 0.5814 \n",
      "Train Accuracy for Epoch 4: 67.10 %\n",
      "Val Loss for Epoch 4: 0.6033 \n",
      "Val Accuracy for Epoch 4: 61.40 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Early Stop Count 4\n",
      "Starting epoch 6\n",
      "Train Loss for Epoch 5: 0.5837 \n",
      "Train Accuracy for Epoch 5: 64.50 %\n",
      "Val Loss for Epoch 5: 0.6067 \n",
      "Val Accuracy for Epoch 5: 61.40 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Early Stop Count 5\n",
      "Early stopping at Epoch 5\n",
      "Training process has finished. Saving trained model.\n",
      "Starting testing\n",
      "Accuracy for fold 3: 64.91 %\n",
      "--------------------------------\n",
      "FOLD 4\n",
      "--------------------------------\n",
      "Starting epoch 1\n",
      "Train Loss for Epoch 0: 0.6021 \n",
      "Train Accuracy for Epoch 0: 65.37 %\n",
      "Val Loss for Epoch 0: 0.6102 \n",
      "Val Accuracy for Epoch 0: 61.40 %\n",
      "--------------------------------\n",
      "Found better model...saving\n",
      "Early Stop Count 0\n",
      "Starting epoch 2\n",
      "Train Loss for Epoch 1: 0.5940 \n",
      "Train Accuracy for Epoch 1: 66.67 %\n",
      "Val Loss for Epoch 1: 0.5969 \n",
      "Val Accuracy for Epoch 1: 61.40 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Early Stop Count 1\n",
      "Starting epoch 3\n",
      "Train Loss for Epoch 2: 0.5888 \n",
      "Train Accuracy for Epoch 2: 67.53 %\n",
      "Val Loss for Epoch 2: 0.6101 \n",
      "Val Accuracy for Epoch 2: 57.89 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Early Stop Count 2\n",
      "Starting epoch 4\n",
      "Train Loss for Epoch 3: 0.5892 \n",
      "Train Accuracy for Epoch 3: 65.37 %\n",
      "Val Loss for Epoch 3: 0.6049 \n",
      "Val Accuracy for Epoch 3: 61.40 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Early Stop Count 3\n",
      "Starting epoch 5\n",
      "Train Loss for Epoch 4: 0.5920 \n",
      "Train Accuracy for Epoch 4: 66.23 %\n",
      "Val Loss for Epoch 4: 0.6031 \n",
      "Val Accuracy for Epoch 4: 63.16 %\n",
      "--------------------------------\n",
      "Found better model...saving\n",
      "Early Stop Count 0\n",
      "Starting epoch 6\n",
      "Train Loss for Epoch 5: 0.5883 \n",
      "Train Accuracy for Epoch 5: 65.80 %\n",
      "Val Loss for Epoch 5: 0.5918 \n",
      "Val Accuracy for Epoch 5: 59.65 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Early Stop Count 1\n",
      "Starting epoch 7\n",
      "Train Loss for Epoch 6: 0.5850 \n",
      "Train Accuracy for Epoch 6: 69.70 %\n",
      "Val Loss for Epoch 6: 0.5954 \n",
      "Val Accuracy for Epoch 6: 64.91 %\n",
      "--------------------------------\n",
      "Found better model...saving\n",
      "Early Stop Count 0\n",
      "Starting epoch 8\n",
      "Train Loss for Epoch 7: 0.5905 \n",
      "Train Accuracy for Epoch 7: 64.50 %\n",
      "Val Loss for Epoch 7: 0.5929 \n",
      "Val Accuracy for Epoch 7: 63.16 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Early Stop Count 1\n",
      "Starting epoch 9\n",
      "Train Loss for Epoch 8: 0.5841 \n",
      "Train Accuracy for Epoch 8: 66.67 %\n",
      "Val Loss for Epoch 8: 0.5831 \n",
      "Val Accuracy for Epoch 8: 59.65 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Early Stop Count 2\n",
      "Starting epoch 10\n",
      "Train Loss for Epoch 9: 0.5834 \n",
      "Train Accuracy for Epoch 9: 67.97 %\n",
      "Val Loss for Epoch 9: 0.5954 \n",
      "Val Accuracy for Epoch 9: 57.89 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Early Stop Count 3\n",
      "Starting epoch 11\n",
      "Train Loss for Epoch 10: 0.5850 \n",
      "Train Accuracy for Epoch 10: 66.67 %\n",
      "Val Loss for Epoch 10: 0.5881 \n",
      "Val Accuracy for Epoch 10: 59.65 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Early Stop Count 4\n",
      "Starting epoch 12\n",
      "Train Loss for Epoch 11: 0.5836 \n",
      "Train Accuracy for Epoch 11: 65.37 %\n",
      "Val Loss for Epoch 11: 0.5802 \n",
      "Val Accuracy for Epoch 11: 63.16 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Early Stop Count 5\n",
      "Early stopping at Epoch 11\n",
      "Training process has finished. Saving trained model.\n",
      "Starting testing\n",
      "Accuracy for fold 4: 56.14 %\n",
      "--------------------------------\n",
      "K-FOLD CROSS VALIDATION RESULTS FOR 5 FOLDS\n",
      "--------------------------------\n",
      "Fold 0: 68.96551724137932 %\n",
      "Fold 1: 68.96551724137932 %\n",
      "Fold 2: 62.06896551724138 %\n",
      "Fold 3: 64.91228070175438 %\n",
      "Fold 4: 56.14035087719298 %\n",
      "Average: 64.21052631578948 %\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(32)\n",
    "semi_train_tf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "code_folding": [
     1
    ]
   },
   "outputs": [],
   "source": [
    "def semi_evaluate():\n",
    "    avg_acc = 0\n",
    "    avg_f1 = 0\n",
    "    avg_conf = np.zeros((2,2))\n",
    "    \n",
    "    # Preparation\n",
    "    transformer = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5), (0.5)),\n",
    "    ])\n",
    "    test_data_dir = './SelfLabelEngagement_Prepared2/Test/'\n",
    "    test_dataset = DomainADDataset(root_dir=test_data_dir, transform = transformer)\n",
    "\n",
    "    for i in range(5):\n",
    "        PATH = './TF_Models/semi-best/model-fold-' + str(i) + '.pth'\n",
    "        encoder = build_encoder()\n",
    "        decoder = build_decoder()\n",
    "        trained_net = Net(encoder,decoder)\n",
    "        trained_net.load_state_dict(torch.load(PATH))\n",
    "        trained_net.to(device)\n",
    "\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        y_true, y_pred = [], []\n",
    "        testloader = torch.utils.data.DataLoader(\n",
    "            test_dataset,\n",
    "            batch_size = 50)\n",
    "\n",
    "        y_pred = []\n",
    "        y_true = []\n",
    "        with torch.no_grad():\n",
    "            # Iterate over the test data and generate predictions\n",
    "            for i, data in enumerate(testloader, 0):\n",
    "\n",
    "                # Get inputs\n",
    "                inputs = data['images']\n",
    "                targets = data['label']\n",
    "\n",
    "                outputs = None\n",
    "                for index, xbatch in enumerate(inputs):\n",
    "\n",
    "                    xbatch = xbatch.float().to(device)\n",
    "\n",
    "                    # Perform forward pass\n",
    "                    output = sliding_window(xbatch, trained_net)\n",
    "                    if index == 0:\n",
    "                        outputs = output\n",
    "                    else:\n",
    "                        outputs = torch.vstack([outputs, output])\n",
    "\n",
    "                # Compute loss\n",
    "                ybatches = targets.to(device)\n",
    "                outputs = torch.reshape(outputs, (ybatches.shape[0],NUM_CLASS))\n",
    "\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                _, truth = torch.max(ybatches, 1)\n",
    "                total += targets.size(0)\n",
    "                correct += (predicted == truth).sum().item()\n",
    "\n",
    "                y_pred.extend(predicted.cpu())\n",
    "                y_true.extend(truth.cpu())\n",
    "\n",
    "        # Print accuracy\n",
    "        print(\"Accuracy\", 100.0 * correct / total)\n",
    "        f1 = f1_score(y_true, y_pred, labels=[0,1], average = 'binary')\n",
    "        confusion_matr = confusion_matrix(y_true, y_pred, labels=[0,1])\n",
    "        print(\"F1\", f1)\n",
    "        print(confusion_matr)\n",
    "\n",
    "        avg_acc += 100.0 * correct / total\n",
    "        avg_f1 += f1\n",
    "        np.add(avg_conf, np.array(confusion_matr))\n",
    "\n",
    "    avg_acc = avg_acc/5\n",
    "    avg_f1 = avg_f1/5\n",
    "    np.true_divide(avg_conf, 5)\n",
    "    print(\"--------------Average------------\")\n",
    "    print('Avg Accuracy', avg_acc)\n",
    "    print('Avg F1', avg_f1)\n",
    "    print('Avg Confusion', avg_conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 45.833333333333336\n",
      "F1 0.13333333333333333\n",
      "[[10  2]\n",
      " [11  1]]\n",
      "Accuracy 45.833333333333336\n",
      "F1 0.13333333333333333\n",
      "[[10  2]\n",
      " [11  1]]\n",
      "Accuracy 50.0\n",
      "F1 0.25\n",
      "[[10  2]\n",
      " [10  2]]\n",
      "Accuracy 45.833333333333336\n",
      "F1 0.23529411764705882\n",
      "[[ 9  3]\n",
      " [10  2]]\n",
      "Accuracy 58.333333333333336\n",
      "F1 0.5833333333333334\n",
      "[[7 5]\n",
      " [5 7]]\n",
      "--------------Average------------\n",
      "Avg Accuracy 49.16666666666667\n",
      "Avg F1 0.2670588235294118\n",
      "Avg Confusion [[0. 0.]\n",
      " [0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "semi_evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No K-fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def train_tf_nokfold():\n",
    "    #---------------Config---------------\n",
    "    num_epochs = 50\n",
    "    k_folds = 1\n",
    "    patience = 10\n",
    "    batch_size = 1\n",
    "    PATH = './Plan3_Models/best/model-fold-' + str(0) + '.pth'\n",
    "    #---------------Config---------------\n",
    "    \n",
    "    # Preparation\n",
    "    weight = torch.tensor([1,1.03]).to(device)\n",
    "    \n",
    "    loss_function = nn.BCELoss(weight=weight)\n",
    "\n",
    "    transformer = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5), (0.5)),\n",
    "    ])\n",
    "    \n",
    "    train_data_dir = './SelfLabelEngagement_Prepared/Train/'\n",
    "    train_dataset = DomainADDataset(root_dir=train_data_dir, transform = transformer)\n",
    "\n",
    "    val_data_dir = './SelfLabelEngagement_Prepared/Validation/'\n",
    "    val_dataset = DomainADDataset(root_dir=val_data_dir, transform = transformer)\n",
    "\n",
    "#     dataset = ConcatDataset([train_dataset, val_dataset])\n",
    "#     kfold = KFold(n_splits=k_folds, shuffle=True)\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    # Define data loaders for training and testing data in this fold\n",
    "    trainloader = torch.utils.data.DataLoader(\n",
    "        train_dataset,\n",
    "        shuffle = True,\n",
    "        batch_size=batch_size)\n",
    "    valloader = torch.utils.data.DataLoader(\n",
    "        val_dataset,\n",
    "        shuffle = True,\n",
    "        batch_size=batch_size)\n",
    "    \n",
    "\n",
    "    for fold in range(1):\n",
    "        \n",
    "        training_details = []\n",
    "        best_model = None\n",
    "        \n",
    "        print(f'FOLD {fold}')\n",
    "        print('--------------------------------')\n",
    "\n",
    "        # Init the neural network\n",
    "        encoder = build_encoder()\n",
    "        decoder = build_decoder()\n",
    "        network = Net(encoder, decoder)\n",
    "        network.load_state_dict(torch.load(PATH))\n",
    "        for param in network.in_encoder.parameters():\n",
    "            param.requires_grad = False\n",
    "        network.to(device) #use GPU\n",
    "        use_gpu = True\n",
    "\n",
    "        # Initialize optimizer\n",
    "        optimizer = optim.Adam(network.parameters(), lr=0.0001)\n",
    "        max_train_acc, max_val_acc = 0, 0\n",
    "        early_stop_count = 0\n",
    "        # Run the training loop for defined number of epochs\n",
    "        for epoch in range(0, num_epochs):\n",
    "\n",
    "            correct, total = 0, 0\n",
    "            # Print epoch\n",
    "            print(f'Starting epoch {epoch+1}')\n",
    "            # Set current loss value\n",
    "            current_loss = 0.0\n",
    "            epoch_loss = 0.0\n",
    "            # Iterate over the DataLoader for training data\n",
    "            for i, data in enumerate(trainloader, 0):\n",
    "            # Starting 1 cycle of mini-batch\n",
    "\n",
    "                # Get inputs\n",
    "                # Get inputs\n",
    "                inputs = data['images']\n",
    "                targets = data['label']\n",
    "\n",
    "                outputs = None\n",
    "                for index, xbatch in enumerate(inputs):\n",
    "                    # Zero the gradients\n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "                    xbatch = xbatch.float().to(device)\n",
    "                    output = sliding_window(xbatch, network)\n",
    "\n",
    "                    # Perform forward pass\n",
    "                    if index == 0:\n",
    "                        outputs = output\n",
    "                    else:\n",
    "                        outputs = torch.vstack([outputs, output])\n",
    "\n",
    "                # Compute loss\n",
    "                ybatches = targets.to(device)\n",
    "                outputs = torch.reshape(outputs, (ybatches.shape[0],NUM_CLASS))\n",
    "                loss = loss_function(outputs, ybatches)\n",
    "\n",
    "                # Perform backward pass\n",
    "                loss.backward()\n",
    "\n",
    "                # Perform optimization\n",
    "                optimizer.step()\n",
    "\n",
    "                # Print statistics\n",
    "                current_loss += loss.item()\n",
    "                epoch_loss += loss.item()\n",
    "\n",
    "                # Compute Accuracy\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                _, truth = torch.max(ybatches, 1)\n",
    "                total += targets.size(0)\n",
    "                correct += (predicted == truth).sum().item()\n",
    "\n",
    "            epoch_loss = epoch_loss/(i+1)\n",
    "            epoch_acc = 100.0 * correct / total\n",
    "            print('Train Loss for Epoch %d: %.4f ' % (epoch, epoch_loss))\n",
    "            print('Train Accuracy for Epoch %d: %.2f %%' % (epoch, epoch_acc))\n",
    "            val_loss, val_acc = check_validation(network.state_dict(), valloader, loss_function)\n",
    "            print('Val Loss for Epoch %d: %.4f ' % (epoch, val_loss))\n",
    "            print('Val Accuracy for Epoch %d: %.2f %%' % (epoch, val_acc))\n",
    "            print('--------------------------------')\n",
    "\n",
    "            training_details.append([epoch_acc, epoch_loss, val_acc, val_loss])\n",
    "\n",
    "            stop_improving = False\n",
    "            if val_acc > max_val_acc:\n",
    "                max_val_acc = val_acc\n",
    "                early_stop_count = 0\n",
    "            else:\n",
    "                early_stop_count += 1\n",
    "                stop_improving = True\n",
    "                print(\"Early Stop Count Increased\")\n",
    "\n",
    "            if epoch_acc > max_train_acc and not stop_improving:\n",
    "                max_train_acc = copy.deepcopy(epoch_acc)\n",
    "                best_model = copy.deepcopy(network.state_dict())\n",
    "                print(\"Found better model...saving\")\n",
    "            \n",
    "            print(\"Early Stop Count\", early_stop_count)\n",
    "            if early_stop_count >= patience:\n",
    "                print(\"Early stopping at Epoch\", epoch)\n",
    "                break\n",
    "\n",
    "\n",
    "        # Process is complete.\n",
    "        print('Training process has finished. Saving trained model.')\n",
    "\n",
    "        # Print about testing\n",
    "        print('Starting testing')\n",
    "\n",
    "        # Saving the model\n",
    "        save_path = f'./models/model-fold-{fold}.pth'\n",
    "        save_path_csv = f'./models/model-fold-{fold}.csv'\n",
    "        torch.save(best_model, save_path)\n",
    "\n",
    "        training_details = np.array(training_details)\n",
    "        df = {'epoch acc': training_details[:,0], \n",
    "              'epoch loss': training_details[:,1], \n",
    "              'val acc': training_details[:,2], \n",
    "              'val loss': training_details[:,3], }\n",
    "        pd.DataFrame(df).to_csv(save_path_csv)\n",
    "\n",
    "    # Evaluationfor this fold\n",
    "    correct, total = 0, 0\n",
    "    with torch.no_grad():\n",
    "        val_loss, val_acc = check_validation(torch.load(save_path), valloader, loss_function)\n",
    "        # Print accuracy\n",
    "        print('Accuracy for fold %d: %.2f %%' % (fold, val_acc))\n",
    "        print('--------------------------------')\n",
    "        results[fold] = val_acc\n",
    "\n",
    "    # Print fold results\n",
    "    print(f'K-FOLD CROSS VALIDATION RESULTS FOR {k_folds} FOLDS')\n",
    "    print('--------------------------------')\n",
    "    sum = 0.0\n",
    "    for key, value in results.items():\n",
    "        print(f'Fold {key}: {value} %')\n",
    "        sum += value\n",
    "    print(f'Average: {sum/len(results.items())} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "--------------------------------\n",
      "Starting epoch 1\n",
      "Train Loss for Epoch 0: 0.7321 \n",
      "Train Accuracy for Epoch 0: 45.45 %\n",
      "Val Loss for Epoch 0: 0.7344 \n",
      "Val Accuracy for Epoch 0: 40.00 %\n",
      "--------------------------------\n",
      "Found better model...saving\n",
      "Early Stop Count 0\n",
      "Starting epoch 2\n",
      "Train Loss for Epoch 1: 0.7249 \n",
      "Train Accuracy for Epoch 1: 44.81 %\n",
      "Val Loss for Epoch 1: 0.7191 \n",
      "Val Accuracy for Epoch 1: 40.00 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Early Stop Count 1\n",
      "Starting epoch 3\n",
      "Train Loss for Epoch 2: 0.7192 \n",
      "Train Accuracy for Epoch 2: 44.81 %\n",
      "Val Loss for Epoch 2: 0.7284 \n",
      "Val Accuracy for Epoch 2: 45.00 %\n",
      "--------------------------------\n",
      "Early Stop Count 0\n",
      "Starting epoch 4\n",
      "Train Loss for Epoch 3: 0.7254 \n",
      "Train Accuracy for Epoch 3: 47.40 %\n",
      "Val Loss for Epoch 3: 0.7212 \n",
      "Val Accuracy for Epoch 3: 50.00 %\n",
      "--------------------------------\n",
      "Found better model...saving\n",
      "Early Stop Count 0\n",
      "Starting epoch 5\n",
      "Train Loss for Epoch 4: 0.7172 \n",
      "Train Accuracy for Epoch 4: 43.51 %\n",
      "Val Loss for Epoch 4: 0.7188 \n",
      "Val Accuracy for Epoch 4: 55.00 %\n",
      "--------------------------------\n",
      "Early Stop Count 0\n",
      "Starting epoch 6\n",
      "Train Loss for Epoch 5: 0.7232 \n",
      "Train Accuracy for Epoch 5: 44.16 %\n",
      "Val Loss for Epoch 5: 0.7190 \n",
      "Val Accuracy for Epoch 5: 60.00 %\n",
      "--------------------------------\n",
      "Early Stop Count 0\n",
      "Starting epoch 7\n",
      "Train Loss for Epoch 6: 0.7141 \n",
      "Train Accuracy for Epoch 6: 47.40 %\n",
      "Val Loss for Epoch 6: 0.7191 \n",
      "Val Accuracy for Epoch 6: 60.00 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Early Stop Count 1\n",
      "Starting epoch 8\n",
      "Train Loss for Epoch 7: 0.7150 \n",
      "Train Accuracy for Epoch 7: 48.05 %\n",
      "Val Loss for Epoch 7: 0.7225 \n",
      "Val Accuracy for Epoch 7: 50.00 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Early Stop Count 2\n",
      "Starting epoch 9\n",
      "Train Loss for Epoch 8: 0.7098 \n",
      "Train Accuracy for Epoch 8: 48.05 %\n",
      "Val Loss for Epoch 8: 0.7287 \n",
      "Val Accuracy for Epoch 8: 45.00 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Early Stop Count 3\n",
      "Starting epoch 10\n",
      "Train Loss for Epoch 9: 0.7189 \n",
      "Train Accuracy for Epoch 9: 46.75 %\n",
      "Val Loss for Epoch 9: 0.7212 \n",
      "Val Accuracy for Epoch 9: 50.00 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Early Stop Count 4\n",
      "Starting epoch 11\n",
      "Train Loss for Epoch 10: 0.7117 \n",
      "Train Accuracy for Epoch 10: 47.40 %\n",
      "Val Loss for Epoch 10: 0.7162 \n",
      "Val Accuracy for Epoch 10: 60.00 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Early Stop Count 5\n",
      "Starting epoch 12\n",
      "Train Loss for Epoch 11: 0.7174 \n",
      "Train Accuracy for Epoch 11: 48.70 %\n",
      "Val Loss for Epoch 11: 0.7195 \n",
      "Val Accuracy for Epoch 11: 45.00 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Early Stop Count 6\n",
      "Starting epoch 13\n",
      "Train Loss for Epoch 12: 0.7159 \n",
      "Train Accuracy for Epoch 12: 46.10 %\n",
      "Val Loss for Epoch 12: 0.7195 \n",
      "Val Accuracy for Epoch 12: 55.00 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Early Stop Count 7\n",
      "Starting epoch 14\n",
      "Train Loss for Epoch 13: 0.7164 \n",
      "Train Accuracy for Epoch 13: 48.70 %\n",
      "Val Loss for Epoch 13: 0.7148 \n",
      "Val Accuracy for Epoch 13: 50.00 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Early Stop Count 8\n",
      "Starting epoch 15\n",
      "Train Loss for Epoch 14: 0.7122 \n",
      "Train Accuracy for Epoch 14: 48.05 %\n",
      "Val Loss for Epoch 14: 0.7155 \n",
      "Val Accuracy for Epoch 14: 55.00 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Early Stop Count 9\n",
      "Starting epoch 16\n",
      "Train Loss for Epoch 15: 0.7178 \n",
      "Train Accuracy for Epoch 15: 46.75 %\n",
      "Val Loss for Epoch 15: 0.7250 \n",
      "Val Accuracy for Epoch 15: 40.00 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Early Stop Count 10\n",
      "Early stopping at Epoch 15\n",
      "Training process has finished. Saving trained model.\n",
      "Starting testing\n",
      "Accuracy for fold 0: 55.00 %\n",
      "--------------------------------\n",
      "K-FOLD CROSS VALIDATION RESULTS FOR 1 FOLDS\n",
      "--------------------------------\n",
      "Fold 0: 55.0 %\n",
      "Average: 55.0 %\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(32)\n",
    "torch.manual_seed(32)\n",
    "train_tf_nokfold()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 93.75\n",
      "F1 0.9393939393939394\n",
      "[[29  3]\n",
      " [ 1 31]]\n",
      "Accuracy 79.6875\n",
      "F1 0.8311688311688311\n",
      "[[19 13]\n",
      " [ 0 32]]\n",
      "Accuracy 89.0625\n",
      "F1 0.8955223880597014\n",
      "[[27  5]\n",
      " [ 2 30]]\n",
      "Accuracy 84.375\n",
      "F1 0.8333333333333334\n",
      "[[29  3]\n",
      " [ 7 25]]\n",
      "Accuracy 87.5\n",
      "F1 0.8857142857142857\n",
      "[[25  7]\n",
      " [ 1 31]]\n",
      "--------------Average------------\n",
      "Avg Accuracy 86.875\n",
      "Avg F1 0.8770265555340181\n",
      "Avg Confusion [[0. 0.]\n",
      " [0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply to Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "class TargetDataset(Dataset):\n",
    "    def __init__(self, root_dir=None, transform=None):\n",
    "        path = os.path.join(root_dir,'ylabels.csv')\n",
    "        self.ylabels = pd.read_csv(path)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.ylabels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        seq_len = 5\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        \n",
    "        label = 0\n",
    "        user = self.ylabels.iloc[idx]['Participant ID']\n",
    "        \n",
    "        img_arr = np.zeros((5, 1, 64, 64))\n",
    "        for i in range (5):\n",
    "            img_name = self.root_dir + 'p_' + str(user) + '-' + str(i) + '.jpg'\n",
    "            image = io.imread(img_name)\n",
    "            if self.transform:\n",
    "                image = self.transform(image)\n",
    "            img_arr[i][0] = image\n",
    "\n",
    "        label_1hot = np.zeros(3)\n",
    "        label_1hot[label] = 1.0\n",
    "        label_1hot = torch.Tensor(label_1hot)\n",
    "#         label = torch.LongTensor(np.array([label]))\n",
    "        sample = {'images': img_arr, 'label': label_1hot}\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def apply():\n",
    "    PATH = './TF_Models/best/model-fold-' + str(0) + '.pth'\n",
    "    encoder = build_encoder()\n",
    "    decoder = build_decoder()\n",
    "    trained_net = Net(encoder,decoder)\n",
    "    trained_net.load_state_dict(torch.load(PATH))\n",
    "    trained_net.to(device)\n",
    "\n",
    "    transformer = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5), (0.5))\n",
    "    ])\n",
    "\n",
    "    train_data_dir = './Target_Prepared_Data/S4/'\n",
    "    train_dataset = TargetDataset(root_dir=train_data_dir, transform = transformer)\n",
    "    testloader = torch.utils.data.DataLoader(train_dataset, batch_size=1)\n",
    "    outputs = []\n",
    "    for i, data in enumerate(testloader, 1):\n",
    "        # Get inputs\n",
    "        inputs = data['images']\n",
    "        targets = data['label']\n",
    "        inputs = inputs.float().to(device)\n",
    "        inputs = torch.reshape(inputs,(5,1,64,64))\n",
    "        inputs = Variable(inputs)\n",
    "        out = sliding_window(inputs, trained_net)\n",
    "#         out = trained_net(inputs)\n",
    "        output = out.cpu().detach().numpy()\n",
    "        outputs.append(output)\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "out=apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(np.argmax(out, axis=1)).to_csv('results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
