{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from statistics import mode\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics import f1_score\n",
    "from heapq import * \n",
    "import time\n",
    "import copy\n",
    "\n",
    "#Pytorch\n",
    "import torch\n",
    "import torchvision\n",
    "# import torchvision.transforms as transforms\n",
    "from torchvision import datasets, models, transforms\n",
    "from skimage import io\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader, ConcatDataset\n",
    "from sklearn.model_selection import KFold\n",
    "from scipy import stats\n",
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "\n",
    "import pytorch_model_summary as pms\n",
    "from torchviz import make_dot\n",
    "np.random.seed(42)\n",
    "\n",
    "# import tensorflow as tf\n",
    "NUM_CLASS = 2\n",
    "WINDOW = 5\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, root_dir=None, transform=None):\n",
    "        path = os.path.join(root_dir,'labels.csv')\n",
    "        self.ylabels = pd.read_csv(path)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.ylabels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        seq_len = 5\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    " \n",
    "        label = self.ylabels.iloc[idx,1]\n",
    "        label_str = str(label) + '/'\n",
    "        img_folder = os.path.join(self.root_dir, label_str)\n",
    "        \n",
    "        img_arr = np.zeros((5, 1, 64, 64))\n",
    "        for i in range (5):\n",
    "            img_name = img_folder + str(idx) + '-' + str(i) + '.jpg'\n",
    "            image = io.imread(img_name)\n",
    "            if self.transform:\n",
    "                image = self.transform(image)\n",
    "            img_arr[i][0] = image\n",
    "            \n",
    "        label_1hot = np.zeros(NUM_CLASS)\n",
    "        label_1hot[label] = 1.0\n",
    "        label_1hot = torch.Tensor(label_1hot)\n",
    "#         label = np.array([label])\n",
    "        label = torch.LongTensor(np.array([label]))\n",
    "        sample = {'images': img_arr, 'label': label_1hot}\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": [
     0,
     1,
     5,
     10,
     49
    ]
   },
   "outputs": [],
   "source": [
    "class Reshape1(torch.nn.Module):\n",
    "    def forward(self, x):\n",
    "        batch_size = torch.Size([1,5,1,64,64])\n",
    "        return x.view(batch_size, -1)\n",
    "    \n",
    "class Reshape2(torch.nn.Module):\n",
    "    def forward(self, x):\n",
    "        batch_size = torch.Size([1,1,64,64])\n",
    "        return x.view(batch_size, -1)\n",
    "\n",
    "def build_encoder():\n",
    "    encoder = nn.Sequential(\n",
    "        Reshape1(),\n",
    "        nn.Conv3d(in_channels=5, out_channels=1, kernel_size=1),\n",
    "        Reshape2(),\n",
    "        nn.Conv2d(in_channels=1, out_channels=192, kernel_size=3),\n",
    "        nn.BatchNorm2d(num_features=192),\n",
    "        nn.ReLU(),\n",
    "        nn.Conv2d(in_channels=192, out_channels=192, kernel_size=1),\n",
    "        nn.ReLU(),\n",
    "        \n",
    "        nn.Conv2d(in_channels=192, out_channels=192, kernel_size=3, stride=2),\n",
    "        nn.BatchNorm2d(num_features=192),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(p=0.5),\n",
    "        \n",
    "        nn.Conv2d(in_channels=192, out_channels=96, kernel_size=3),\n",
    "        nn.BatchNorm2d(num_features=96),\n",
    "        nn.ReLU(),\n",
    "        nn.Conv2d(in_channels=96, out_channels=96, kernel_size=1),\n",
    "        nn.ReLU(),\n",
    "        nn.Conv2d(in_channels=96, out_channels=96, kernel_size=1),\n",
    "        nn.ReLU(),\n",
    "        \n",
    "        nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "        nn.Dropout(p=0.5),\n",
    "        \n",
    "        nn.Conv2d(in_channels=96, out_channels=32, kernel_size=3),\n",
    "        nn.BatchNorm2d(num_features=32),\n",
    "        nn.ReLU(),\n",
    "        nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3),\n",
    "        nn.BatchNorm2d(num_features=32),\n",
    "        nn.ReLU(),\n",
    "        nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, padding=2),\n",
    "        nn.BatchNorm2d(num_features=32),\n",
    "        nn.ReLU()\n",
    "    )\n",
    "    return encoder\n",
    "\n",
    "def build_decoder():\n",
    "    decoder = nn.Sequential(\n",
    "        nn.Conv2d(in_channels=32, out_channels=NUM_CLASS, kernel_size=1),\n",
    "        nn.AdaptiveAvgPool2d((1,1)),\n",
    "        nn.Softmax(dim=1)\n",
    "    )\n",
    "    return decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super(Net, self).__init__()\n",
    "        self.in_encoder = encoder\n",
    "        self.in_decoder = decoder\n",
    "        \n",
    "    def forward(self, x):\n",
    "        tmp = self.in_encoder(x)\n",
    "        y = self.in_decoder(tmp)\n",
    "        return y\n",
    "    def encoder(self, x):\n",
    "        return self.in_encoder(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoder = build_encoder()\n",
    "# decoder = build_decoder()\n",
    "# net = Net(encoder, decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# pms.summary(net.cpu(), \n",
    "#             torch.zeros((1,5,1,64,64)), \n",
    "#             batch_size=1, \n",
    "#             show_hierarchical=True, \n",
    "#             print_summary=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training on Engagement Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def check_validation(model, valloader, loss_function):\n",
    "    # Evaluationfor this fold\n",
    "    correct, total = 0, 0\n",
    "    current_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        # Init the neural network\n",
    "        encoder = build_encoder()\n",
    "        decoder = build_decoder()\n",
    "        trained_net = Net(encoder, decoder)\n",
    "        trained_net.load_state_dict(model)\n",
    "        trained_net.to(device)\n",
    "\n",
    "        # Iterate over the test data and generate predictions\n",
    "        for i, data in enumerate(valloader, 0):\n",
    "\n",
    "            # Get inputs\n",
    "            inputs = data['images']\n",
    "            targets = data['label']\n",
    "\n",
    "            outputs = None\n",
    "            for index, xbatch in enumerate(inputs):\n",
    "\n",
    "                xbatch = xbatch.float().to(device)\n",
    "\n",
    "                # Perform forward pass\n",
    "                output = trained_net(xbatch)\n",
    "                if index == 0:\n",
    "                    outputs = output\n",
    "                else:\n",
    "                    outputs = torch.vstack([outputs, output])\n",
    "\n",
    "            # Compute loss\n",
    "            ybatches = targets.to(device)\n",
    "            outputs = torch.reshape(outputs, (ybatches.shape[0],NUM_CLASS))\n",
    "            ybatches.squeeze_(1)\n",
    "            loss = loss_function(outputs, ybatches)\n",
    "            current_loss += loss.item()\n",
    "\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            _, truth = torch.max(ybatches, 1)\n",
    "            total += targets.size(0)\n",
    "            correct += (predicted == truth).sum().item()\n",
    "    val_loss = current_loss/(i+1)\n",
    "    val_acc = 100.0 * correct / total\n",
    "    return val_loss, val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def train():\n",
    "    #---------------Config---------------\n",
    "    torch.manual_seed(42)\n",
    "    num_epochs = 50\n",
    "    k_folds = 5\n",
    "    patience = 10\n",
    "    batch_size = 32\n",
    "    #---------------Config---------------\n",
    "    \n",
    "    # Preparation\n",
    "    weight = torch.tensor([1,1]).to(device)\n",
    "    \n",
    "    loss_function = nn.BCELoss(weight=weight)\n",
    "\n",
    "    transformer = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5), (0.5)),\n",
    "    ])\n",
    "\n",
    "    train_data_dir = './Prepared_Data/Train/'\n",
    "    train_dataset = MyDataset(root_dir=train_data_dir, transform = transformer)\n",
    "\n",
    "    val_data_dir = './Prepared_Data/Validation/'\n",
    "    val_dataset = MyDataset(root_dir=val_data_dir, transform = transformer)\n",
    "\n",
    "    dataset = ConcatDataset([train_dataset, val_dataset])\n",
    "\n",
    "    kfold = KFold(n_splits=k_folds, shuffle=True)\n",
    "    \n",
    "    results = {}\n",
    "\n",
    "    # K-fold Cross Validation model evaluation\n",
    "    for fold, (train_ids, val_ids) in enumerate(kfold.split(dataset)):\n",
    "        training_details = []\n",
    "        best_model = None\n",
    "\n",
    "        # Print\n",
    "        print(f'FOLD {fold}')\n",
    "        print('--------------------------------')\n",
    "\n",
    "        # Sample elements randomly from a given list of ids, no replacement.\n",
    "        train_subsampler = torch.utils.data.SubsetRandomSampler(train_ids)\n",
    "        val_subsampler = torch.utils.data.SubsetRandomSampler(val_ids)\n",
    "\n",
    "        # Define data loaders for training and testing data in this fold\n",
    "        trainloader = torch.utils.data.DataLoader(\n",
    "                        dataset,\n",
    "                        batch_size=batch_size, sampler=train_subsampler)\n",
    "        valloader = torch.utils.data.DataLoader(\n",
    "                        dataset,\n",
    "                        batch_size=batch_size, sampler=val_subsampler)\n",
    "\n",
    "        # Init the neural network\n",
    "        encoder = build_encoder()\n",
    "        decoder = build_decoder()\n",
    "        network = Net(encoder, decoder)\n",
    "        network.to(device) #use GPU\n",
    "        use_gpu = True\n",
    "\n",
    "        # Initialize optimizer\n",
    "        optimizer = optim.Adam(network.parameters(), lr=0.001)\n",
    "        max_train_acc, max_val_acc = 0, 0\n",
    "        early_stop_count = 0\n",
    "        # Run the training loop for defined number of epochs\n",
    "        for epoch in range(0, num_epochs):\n",
    "\n",
    "            correct, total = 0, 0\n",
    "            # Print epoch\n",
    "            print(f'Starting epoch {epoch+1}')\n",
    "            # Set current loss value\n",
    "            current_loss = 0.0\n",
    "            epoch_loss = 0.0\n",
    "            # Iterate over the DataLoader for training data\n",
    "            for i, data in enumerate(trainloader, 0):\n",
    "            # Starting 1 cycle of mini-batch\n",
    "\n",
    "                # Get inputs\n",
    "                inputs = data['images']\n",
    "                targets = data['label']\n",
    "\n",
    "                outputs = None\n",
    "                for index, xbatch in enumerate(inputs):\n",
    "                    # Zero the gradients\n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "                    xbatch = xbatch.float() .to(device)\n",
    "\n",
    "                    # Perform forward pass\n",
    "                    output = network(xbatch)\n",
    "                    if index == 0:\n",
    "                        outputs = output\n",
    "                    else:\n",
    "                        outputs = torch.vstack([outputs, output])\n",
    "\n",
    "                # Compute loss\n",
    "                ybatches = targets.to(device)\n",
    "                outputs = torch.reshape(outputs, (ybatches.shape[0],NUM_CLASS))\n",
    "                loss = loss_function(outputs, ybatches)\n",
    "\n",
    "                # Perform backward pass\n",
    "                loss.backward()\n",
    "\n",
    "                # Perform optimization\n",
    "                optimizer.step()\n",
    "\n",
    "                # Print statistics\n",
    "                current_loss += loss.item()\n",
    "                epoch_loss += loss.item()\n",
    "\n",
    "                # Compute Accuracy\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                _, truth = torch.max(ybatches, 1)\n",
    "                total += targets.size(0)\n",
    "                correct += (predicted == truth).sum().item()\n",
    "\n",
    "            epoch_loss = epoch_loss/(i+1)\n",
    "            epoch_acc = 100.0 * correct / total\n",
    "            print('Train Loss for Epoch %d: %.4f ' % (epoch, epoch_loss))\n",
    "            print('Train Accuracy for Epoch %d: %.2f %%' % (epoch, epoch_acc))\n",
    "            val_loss, val_acc = check_validation(network.state_dict(), valloader, loss_function)\n",
    "            print('Val Loss for Epoch %d: %.4f ' % (epoch, val_loss))\n",
    "            print('Val Accuracy for Epoch %d: %.2f %%' % (epoch, val_acc))\n",
    "            print('--------------------------------')\n",
    "\n",
    "            training_details.append([epoch_acc, epoch_loss, val_acc, val_loss])\n",
    "\n",
    "            stop_improving = False\n",
    "            if val_acc > max_val_acc:\n",
    "                max_val_acc = val_acc\n",
    "                early_stop_count = 0\n",
    "            else:\n",
    "                early_stop_count += 1\n",
    "                stop_improving = True\n",
    "                print(\"Early Stop Count Increased\")\n",
    "\n",
    "            if epoch_acc > max_train_acc:\n",
    "                max_train_acc = copy.deepcopy(epoch_acc)\n",
    "                best_model = copy.deepcopy(network.state_dict())\n",
    "                print(\"Found better model...saving\")\n",
    "\n",
    "            if early_stop_count >= patience:\n",
    "                print(\"Early stopping at Epoch\", epoch)\n",
    "                break\n",
    "\n",
    "\n",
    "        # Process is complete.\n",
    "        print('Training process has finished. Saving trained model.')\n",
    "\n",
    "        # Print about testing\n",
    "        print('Starting testing')\n",
    "\n",
    "        # Saving the model\n",
    "        save_path = f'./models/model-fold-{fold}.pth'\n",
    "        save_path_csv = f'./models/model-fold-{fold}.csv'\n",
    "        torch.save(best_model, save_path)\n",
    "\n",
    "        training_details = np.array(training_details)\n",
    "        df = {'epoch acc': training_details[:,0], \n",
    "              'epoch loss': training_details[:,1], \n",
    "              'val acc': training_details[:,2], \n",
    "              'val loss': training_details[:,3], }\n",
    "        pd.DataFrame(df).to_csv(save_path_csv)\n",
    "\n",
    "        # Evaluationfor this fold\n",
    "        correct, total = 0, 0\n",
    "        with torch.no_grad():\n",
    "            val_loss, val_acc = check_validation(torch.load(save_path), valloader, loss_function)\n",
    "            # Print accuracy\n",
    "            print('Accuracy for fold %d: %.2f %%' % (fold, val_acc))\n",
    "            print('--------------------------------')\n",
    "            results[fold] = val_acc\n",
    "\n",
    "    # Print fold results\n",
    "    print(f'K-FOLD CROSS VALIDATION RESULTS FOR {k_folds} FOLDS')\n",
    "    print('--------------------------------')\n",
    "    sum = 0.0\n",
    "    for key, value in results.items():\n",
    "        print(f'Fold {key}: {value} %')\n",
    "        sum += value\n",
    "    print(f'Average: {sum/len(results.items())} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "--------------------------------\n",
      "Starting epoch 1\n",
      "Train Loss for Epoch 0: 0.6958 \n",
      "Train Accuracy for Epoch 0: 50.28 %\n",
      "Val Loss for Epoch 0: 0.6885 \n",
      "Val Accuracy for Epoch 0: 48.89 %\n",
      "--------------------------------\n",
      "Found better model...saving\n",
      "Starting epoch 2\n",
      "Train Loss for Epoch 1: 0.6866 \n",
      "Train Accuracy for Epoch 1: 51.96 %\n",
      "Val Loss for Epoch 1: 0.6776 \n",
      "Val Accuracy for Epoch 1: 62.22 %\n",
      "--------------------------------\n",
      "Found better model...saving\n",
      "Starting epoch 3\n",
      "Train Loss for Epoch 2: 0.6764 \n",
      "Train Accuracy for Epoch 2: 65.36 %\n",
      "Val Loss for Epoch 2: 0.6657 \n",
      "Val Accuracy for Epoch 2: 80.00 %\n",
      "--------------------------------\n",
      "Found better model...saving\n",
      "Starting epoch 4\n",
      "Train Loss for Epoch 3: 0.6660 \n",
      "Train Accuracy for Epoch 3: 78.77 %\n",
      "Val Loss for Epoch 3: 0.6529 \n",
      "Val Accuracy for Epoch 3: 90.00 %\n",
      "--------------------------------\n",
      "Found better model...saving\n",
      "Starting epoch 5\n",
      "Train Loss for Epoch 4: 0.6533 \n",
      "Train Accuracy for Epoch 4: 82.40 %\n",
      "Val Loss for Epoch 4: 0.6395 \n",
      "Val Accuracy for Epoch 4: 90.00 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Found better model...saving\n",
      "Starting epoch 6\n",
      "Train Loss for Epoch 5: 0.6386 \n",
      "Train Accuracy for Epoch 5: 84.92 %\n",
      "Val Loss for Epoch 5: 0.6230 \n",
      "Val Accuracy for Epoch 5: 85.56 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Found better model...saving\n",
      "Starting epoch 7\n",
      "Train Loss for Epoch 6: 0.6237 \n",
      "Train Accuracy for Epoch 6: 85.47 %\n",
      "Val Loss for Epoch 6: 0.6011 \n",
      "Val Accuracy for Epoch 6: 91.11 %\n",
      "--------------------------------\n",
      "Found better model...saving\n",
      "Starting epoch 8\n",
      "Train Loss for Epoch 7: 0.6059 \n",
      "Train Accuracy for Epoch 7: 89.39 %\n",
      "Val Loss for Epoch 7: 0.5771 \n",
      "Val Accuracy for Epoch 7: 90.00 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Found better model...saving\n",
      "Starting epoch 9\n",
      "Train Loss for Epoch 8: 0.5767 \n",
      "Train Accuracy for Epoch 8: 91.62 %\n",
      "Val Loss for Epoch 8: 0.5566 \n",
      "Val Accuracy for Epoch 8: 92.22 %\n",
      "--------------------------------\n",
      "Found better model...saving\n",
      "Starting epoch 10\n",
      "Train Loss for Epoch 9: 0.5474 \n",
      "Train Accuracy for Epoch 9: 91.06 %\n",
      "Val Loss for Epoch 9: 0.5235 \n",
      "Val Accuracy for Epoch 9: 94.44 %\n",
      "--------------------------------\n",
      "Starting epoch 11\n",
      "Train Loss for Epoch 10: 0.5120 \n",
      "Train Accuracy for Epoch 10: 90.78 %\n",
      "Val Loss for Epoch 10: 0.4934 \n",
      "Val Accuracy for Epoch 10: 91.11 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Starting epoch 12\n",
      "Train Loss for Epoch 11: 0.4860 \n",
      "Train Accuracy for Epoch 11: 91.06 %\n",
      "Val Loss for Epoch 11: 0.4681 \n",
      "Val Accuracy for Epoch 11: 91.11 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Starting epoch 13\n",
      "Train Loss for Epoch 12: 0.4486 \n",
      "Train Accuracy for Epoch 12: 93.30 %\n",
      "Val Loss for Epoch 12: 0.4538 \n",
      "Val Accuracy for Epoch 12: 87.78 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Found better model...saving\n",
      "Starting epoch 14\n",
      "Train Loss for Epoch 13: 0.4301 \n",
      "Train Accuracy for Epoch 13: 90.78 %\n",
      "Val Loss for Epoch 13: 0.4348 \n",
      "Val Accuracy for Epoch 13: 90.00 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Starting epoch 15\n",
      "Train Loss for Epoch 14: 0.4088 \n",
      "Train Accuracy for Epoch 14: 92.46 %\n",
      "Val Loss for Epoch 14: 0.3829 \n",
      "Val Accuracy for Epoch 14: 92.22 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Starting epoch 16\n",
      "Train Loss for Epoch 15: 0.3482 \n",
      "Train Accuracy for Epoch 15: 94.69 %\n",
      "Val Loss for Epoch 15: 0.3579 \n",
      "Val Accuracy for Epoch 15: 91.11 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Found better model...saving\n",
      "Starting epoch 17\n",
      "Train Loss for Epoch 16: 0.3193 \n",
      "Train Accuracy for Epoch 16: 94.69 %\n",
      "Val Loss for Epoch 16: 0.3668 \n",
      "Val Accuracy for Epoch 16: 90.00 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Starting epoch 18\n",
      "Train Loss for Epoch 17: 0.2886 \n",
      "Train Accuracy for Epoch 17: 96.09 %\n",
      "Val Loss for Epoch 17: 0.3278 \n",
      "Val Accuracy for Epoch 17: 90.00 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Found better model...saving\n",
      "Starting epoch 19\n",
      "Train Loss for Epoch 18: 0.2616 \n",
      "Train Accuracy for Epoch 18: 96.09 %\n",
      "Val Loss for Epoch 18: 0.2999 \n",
      "Val Accuracy for Epoch 18: 90.00 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Starting epoch 20\n",
      "Train Loss for Epoch 19: 0.2378 \n",
      "Train Accuracy for Epoch 19: 96.65 %\n",
      "Val Loss for Epoch 19: 0.3060 \n",
      "Val Accuracy for Epoch 19: 91.11 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Found better model...saving\n",
      "Early stopping at Epoch 19\n",
      "Training process has finished. Saving trained model.\n",
      "Starting testing\n",
      "Accuracy for fold 0: 93.33 %\n",
      "--------------------------------\n",
      "FOLD 1\n",
      "--------------------------------\n",
      "Starting epoch 1\n",
      "Train Loss for Epoch 0: 0.6973 \n",
      "Train Accuracy for Epoch 0: 48.04 %\n",
      "Val Loss for Epoch 0: 0.6866 \n",
      "Val Accuracy for Epoch 0: 61.11 %\n",
      "--------------------------------\n",
      "Found better model...saving\n",
      "Starting epoch 2\n",
      "Train Loss for Epoch 1: 0.6782 \n",
      "Train Accuracy for Epoch 1: 74.58 %\n",
      "Val Loss for Epoch 1: 0.6871 \n",
      "Val Accuracy for Epoch 1: 52.22 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Found better model...saving\n",
      "Starting epoch 3\n",
      "Train Loss for Epoch 2: 0.6662 \n",
      "Train Accuracy for Epoch 2: 60.06 %\n",
      "Val Loss for Epoch 2: 0.6812 \n",
      "Val Accuracy for Epoch 2: 58.89 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Starting epoch 4\n",
      "Train Loss for Epoch 3: 0.6506 \n",
      "Train Accuracy for Epoch 3: 77.37 %\n",
      "Val Loss for Epoch 3: 0.6714 \n",
      "Val Accuracy for Epoch 3: 64.44 %\n",
      "--------------------------------\n",
      "Found better model...saving\n",
      "Starting epoch 5\n",
      "Train Loss for Epoch 4: 0.6364 \n",
      "Train Accuracy for Epoch 4: 81.84 %\n",
      "Val Loss for Epoch 4: 0.6557 \n",
      "Val Accuracy for Epoch 4: 66.67 %\n",
      "--------------------------------\n",
      "Found better model...saving\n",
      "Starting epoch 6\n",
      "Train Loss for Epoch 5: 0.6184 \n",
      "Train Accuracy for Epoch 5: 86.59 %\n",
      "Val Loss for Epoch 5: 0.6448 \n",
      "Val Accuracy for Epoch 5: 71.11 %\n",
      "--------------------------------\n",
      "Found better model...saving\n",
      "Starting epoch 7\n",
      "Train Loss for Epoch 6: 0.5948 \n",
      "Train Accuracy for Epoch 6: 87.99 %\n",
      "Val Loss for Epoch 6: 0.6316 \n",
      "Val Accuracy for Epoch 6: 74.44 %\n",
      "--------------------------------\n",
      "Found better model...saving\n",
      "Starting epoch 8\n",
      "Train Loss for Epoch 7: 0.5730 \n",
      "Train Accuracy for Epoch 7: 89.66 %\n",
      "Val Loss for Epoch 7: 0.6114 \n",
      "Val Accuracy for Epoch 7: 81.11 %\n",
      "--------------------------------\n",
      "Found better model...saving\n",
      "Starting epoch 9\n",
      "Train Loss for Epoch 8: 0.5371 \n",
      "Train Accuracy for Epoch 8: 90.78 %\n",
      "Val Loss for Epoch 8: 0.6256 \n",
      "Val Accuracy for Epoch 8: 66.67 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Found better model...saving\n",
      "Starting epoch 10\n",
      "Train Loss for Epoch 9: 0.5282 \n",
      "Train Accuracy for Epoch 9: 89.94 %\n",
      "Val Loss for Epoch 9: 0.5663 \n",
      "Val Accuracy for Epoch 9: 83.33 %\n",
      "--------------------------------\n",
      "Starting epoch 11\n",
      "Train Loss for Epoch 10: 0.4895 \n",
      "Train Accuracy for Epoch 10: 93.02 %\n",
      "Val Loss for Epoch 10: 0.5409 \n",
      "Val Accuracy for Epoch 10: 83.33 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Found better model...saving\n",
      "Starting epoch 12\n",
      "Train Loss for Epoch 11: 0.4612 \n",
      "Train Accuracy for Epoch 11: 93.02 %\n",
      "Val Loss for Epoch 11: 0.5128 \n",
      "Val Accuracy for Epoch 11: 85.56 %\n",
      "--------------------------------\n",
      "Starting epoch 13\n",
      "Train Loss for Epoch 12: 0.4271 \n",
      "Train Accuracy for Epoch 12: 93.58 %\n",
      "Val Loss for Epoch 12: 0.5426 \n",
      "Val Accuracy for Epoch 12: 72.22 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Found better model...saving\n",
      "Starting epoch 14\n",
      "Train Loss for Epoch 13: 0.3933 \n",
      "Train Accuracy for Epoch 13: 93.30 %\n",
      "Val Loss for Epoch 13: 0.4636 \n",
      "Val Accuracy for Epoch 13: 86.67 %\n",
      "--------------------------------\n",
      "Starting epoch 15\n",
      "Train Loss for Epoch 14: 0.3481 \n",
      "Train Accuracy for Epoch 14: 95.81 %\n",
      "Val Loss for Epoch 14: 0.4297 \n",
      "Val Accuracy for Epoch 14: 87.78 %\n",
      "--------------------------------\n",
      "Found better model...saving\n",
      "Starting epoch 16\n",
      "Train Loss for Epoch 15: 0.3106 \n",
      "Train Accuracy for Epoch 15: 95.53 %\n",
      "Val Loss for Epoch 15: 0.4401 \n",
      "Val Accuracy for Epoch 15: 83.33 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Starting epoch 17\n",
      "Train Loss for Epoch 16: 0.2795 \n",
      "Train Accuracy for Epoch 16: 96.65 %\n",
      "Val Loss for Epoch 16: 0.3891 \n",
      "Val Accuracy for Epoch 16: 87.78 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Found better model...saving\n",
      "Starting epoch 18\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss for Epoch 17: 0.2564 \n",
      "Train Accuracy for Epoch 17: 97.21 %\n",
      "Val Loss for Epoch 17: 0.4025 \n",
      "Val Accuracy for Epoch 17: 84.44 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Found better model...saving\n",
      "Starting epoch 19\n",
      "Train Loss for Epoch 18: 0.2568 \n",
      "Train Accuracy for Epoch 18: 96.65 %\n",
      "Val Loss for Epoch 18: 0.4269 \n",
      "Val Accuracy for Epoch 18: 80.00 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Starting epoch 20\n",
      "Train Loss for Epoch 19: 0.2179 \n",
      "Train Accuracy for Epoch 19: 97.21 %\n",
      "Val Loss for Epoch 19: 0.3753 \n",
      "Val Accuracy for Epoch 19: 83.33 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Starting epoch 21\n",
      "Train Loss for Epoch 20: 0.2223 \n",
      "Train Accuracy for Epoch 20: 97.77 %\n",
      "Val Loss for Epoch 20: 0.4133 \n",
      "Val Accuracy for Epoch 20: 81.11 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Found better model...saving\n",
      "Starting epoch 22\n",
      "Train Loss for Epoch 21: 0.2122 \n",
      "Train Accuracy for Epoch 21: 96.93 %\n",
      "Val Loss for Epoch 21: 0.4209 \n",
      "Val Accuracy for Epoch 21: 81.11 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Starting epoch 23\n",
      "Train Loss for Epoch 22: 0.1849 \n",
      "Train Accuracy for Epoch 22: 96.37 %\n",
      "Val Loss for Epoch 22: 0.3965 \n",
      "Val Accuracy for Epoch 22: 86.67 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Starting epoch 24\n",
      "Train Loss for Epoch 23: 0.1603 \n",
      "Train Accuracy for Epoch 23: 98.32 %\n",
      "Val Loss for Epoch 23: 0.4168 \n",
      "Val Accuracy for Epoch 23: 82.22 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Found better model...saving\n",
      "Starting epoch 25\n",
      "Train Loss for Epoch 24: 0.1393 \n",
      "Train Accuracy for Epoch 24: 98.32 %\n",
      "Val Loss for Epoch 24: 0.3946 \n",
      "Val Accuracy for Epoch 24: 83.33 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Early stopping at Epoch 24\n",
      "Training process has finished. Saving trained model.\n",
      "Starting testing\n",
      "Accuracy for fold 1: 80.00 %\n",
      "--------------------------------\n",
      "FOLD 2\n",
      "--------------------------------\n",
      "Starting epoch 1\n",
      "Train Loss for Epoch 0: 0.6995 \n",
      "Train Accuracy for Epoch 0: 48.88 %\n",
      "Val Loss for Epoch 0: 0.6895 \n",
      "Val Accuracy for Epoch 0: 54.44 %\n",
      "--------------------------------\n",
      "Found better model...saving\n",
      "Starting epoch 2\n",
      "Train Loss for Epoch 1: 0.6950 \n",
      "Train Accuracy for Epoch 1: 48.88 %\n",
      "Val Loss for Epoch 1: 0.6919 \n",
      "Val Accuracy for Epoch 1: 51.11 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Starting epoch 3\n",
      "Train Loss for Epoch 2: 0.6900 \n",
      "Train Accuracy for Epoch 2: 50.84 %\n",
      "Val Loss for Epoch 2: 0.6947 \n",
      "Val Accuracy for Epoch 2: 45.56 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Found better model...saving\n",
      "Starting epoch 4\n",
      "Train Loss for Epoch 3: 0.6867 \n",
      "Train Accuracy for Epoch 3: 51.12 %\n",
      "Val Loss for Epoch 3: 0.6925 \n",
      "Val Accuracy for Epoch 3: 45.56 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Found better model...saving\n",
      "Starting epoch 5\n",
      "Train Loss for Epoch 4: 0.6829 \n",
      "Train Accuracy for Epoch 4: 51.12 %\n",
      "Val Loss for Epoch 4: 0.6882 \n",
      "Val Accuracy for Epoch 4: 48.89 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Starting epoch 6\n",
      "Train Loss for Epoch 5: 0.6806 \n",
      "Train Accuracy for Epoch 5: 56.15 %\n",
      "Val Loss for Epoch 5: 0.6848 \n",
      "Val Accuracy for Epoch 5: 50.00 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Found better model...saving\n",
      "Starting epoch 7\n",
      "Train Loss for Epoch 6: 0.6725 \n",
      "Train Accuracy for Epoch 6: 65.92 %\n",
      "Val Loss for Epoch 6: 0.6769 \n",
      "Val Accuracy for Epoch 6: 62.22 %\n",
      "--------------------------------\n",
      "Found better model...saving\n",
      "Starting epoch 8\n",
      "Train Loss for Epoch 7: 0.6599 \n",
      "Train Accuracy for Epoch 7: 79.05 %\n",
      "Val Loss for Epoch 7: 0.6690 \n",
      "Val Accuracy for Epoch 7: 70.00 %\n",
      "--------------------------------\n",
      "Found better model...saving\n",
      "Starting epoch 9\n",
      "Train Loss for Epoch 8: 0.6520 \n",
      "Train Accuracy for Epoch 8: 77.09 %\n",
      "Val Loss for Epoch 8: 0.6556 \n",
      "Val Accuracy for Epoch 8: 75.56 %\n",
      "--------------------------------\n",
      "Starting epoch 10\n",
      "Train Loss for Epoch 9: 0.6360 \n",
      "Train Accuracy for Epoch 9: 84.08 %\n",
      "Val Loss for Epoch 9: 0.6449 \n",
      "Val Accuracy for Epoch 9: 75.56 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Found better model...saving\n",
      "Starting epoch 11\n",
      "Train Loss for Epoch 10: 0.6150 \n",
      "Train Accuracy for Epoch 10: 83.80 %\n",
      "Val Loss for Epoch 10: 0.6315 \n",
      "Val Accuracy for Epoch 10: 75.56 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Starting epoch 12\n",
      "Train Loss for Epoch 11: 0.5900 \n",
      "Train Accuracy for Epoch 11: 86.31 %\n",
      "Val Loss for Epoch 11: 0.6128 \n",
      "Val Accuracy for Epoch 11: 70.00 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Found better model...saving\n",
      "Starting epoch 13\n",
      "Train Loss for Epoch 12: 0.5763 \n",
      "Train Accuracy for Epoch 12: 84.64 %\n",
      "Val Loss for Epoch 12: 0.5887 \n",
      "Val Accuracy for Epoch 12: 82.22 %\n",
      "--------------------------------\n",
      "Starting epoch 14\n",
      "Train Loss for Epoch 13: 0.5387 \n",
      "Train Accuracy for Epoch 13: 86.03 %\n",
      "Val Loss for Epoch 13: 0.5785 \n",
      "Val Accuracy for Epoch 13: 74.44 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Starting epoch 15\n",
      "Train Loss for Epoch 14: 0.5042 \n",
      "Train Accuracy for Epoch 14: 89.66 %\n",
      "Val Loss for Epoch 14: 0.5712 \n",
      "Val Accuracy for Epoch 14: 76.67 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Found better model...saving\n",
      "Starting epoch 16\n",
      "Train Loss for Epoch 15: 0.4543 \n",
      "Train Accuracy for Epoch 15: 91.62 %\n",
      "Val Loss for Epoch 15: 0.4914 \n",
      "Val Accuracy for Epoch 15: 87.78 %\n",
      "--------------------------------\n",
      "Found better model...saving\n",
      "Starting epoch 17\n",
      "Train Loss for Epoch 16: 0.4523 \n",
      "Train Accuracy for Epoch 16: 89.39 %\n",
      "Val Loss for Epoch 16: 0.4857 \n",
      "Val Accuracy for Epoch 16: 85.56 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Starting epoch 18\n",
      "Train Loss for Epoch 17: 0.4229 \n",
      "Train Accuracy for Epoch 17: 92.18 %\n",
      "Val Loss for Epoch 17: 0.4784 \n",
      "Val Accuracy for Epoch 17: 85.56 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Found better model...saving\n",
      "Starting epoch 19\n",
      "Train Loss for Epoch 18: 0.3901 \n",
      "Train Accuracy for Epoch 18: 91.90 %\n",
      "Val Loss for Epoch 18: 0.4627 \n",
      "Val Accuracy for Epoch 18: 84.44 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Starting epoch 20\n",
      "Train Loss for Epoch 19: 0.3494 \n",
      "Train Accuracy for Epoch 19: 94.69 %\n",
      "Val Loss for Epoch 19: 0.4583 \n",
      "Val Accuracy for Epoch 19: 80.00 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Found better model...saving\n",
      "Starting epoch 21\n",
      "Train Loss for Epoch 20: 0.3253 \n",
      "Train Accuracy for Epoch 20: 93.58 %\n",
      "Val Loss for Epoch 20: 0.4057 \n",
      "Val Accuracy for Epoch 20: 86.67 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Starting epoch 22\n",
      "Train Loss for Epoch 21: 0.3067 \n",
      "Train Accuracy for Epoch 21: 93.58 %\n",
      "Val Loss for Epoch 21: 0.4781 \n",
      "Val Accuracy for Epoch 21: 77.78 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Starting epoch 23\n",
      "Train Loss for Epoch 22: 0.3028 \n",
      "Train Accuracy for Epoch 22: 92.18 %\n",
      "Val Loss for Epoch 22: 0.4346 \n",
      "Val Accuracy for Epoch 22: 78.89 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Starting epoch 24\n",
      "Train Loss for Epoch 23: 0.2339 \n",
      "Train Accuracy for Epoch 23: 96.65 %\n",
      "Val Loss for Epoch 23: 0.4368 \n",
      "Val Accuracy for Epoch 23: 81.11 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Found better model...saving\n",
      "Starting epoch 25\n",
      "Train Loss for Epoch 24: 0.2000 \n",
      "Train Accuracy for Epoch 24: 97.49 %\n",
      "Val Loss for Epoch 24: 0.4277 \n",
      "Val Accuracy for Epoch 24: 82.22 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Found better model...saving\n",
      "Starting epoch 26\n",
      "Train Loss for Epoch 25: 0.1804 \n",
      "Train Accuracy for Epoch 25: 97.21 %\n",
      "Val Loss for Epoch 25: 0.4897 \n",
      "Val Accuracy for Epoch 25: 76.67 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Early stopping at Epoch 25\n",
      "Training process has finished. Saving trained model.\n",
      "Starting testing\n",
      "Accuracy for fold 2: 78.89 %\n",
      "--------------------------------\n",
      "FOLD 3\n",
      "--------------------------------\n",
      "Starting epoch 1\n",
      "Train Loss for Epoch 0: 0.6933 \n",
      "Train Accuracy for Epoch 0: 49.86 %\n",
      "Val Loss for Epoch 0: 0.6908 \n",
      "Val Accuracy for Epoch 0: 52.81 %\n",
      "--------------------------------\n",
      "Found better model...saving\n",
      "Starting epoch 2\n",
      "Train Loss for Epoch 1: 0.6888 \n",
      "Train Accuracy for Epoch 1: 59.05 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss for Epoch 1: 0.6851 \n",
      "Val Accuracy for Epoch 1: 50.56 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Found better model...saving\n",
      "Starting epoch 3\n",
      "Train Loss for Epoch 2: 0.6796 \n",
      "Train Accuracy for Epoch 2: 53.20 %\n",
      "Val Loss for Epoch 2: 0.6729 \n",
      "Val Accuracy for Epoch 2: 62.92 %\n",
      "--------------------------------\n",
      "Starting epoch 4\n",
      "Train Loss for Epoch 3: 0.6716 \n",
      "Train Accuracy for Epoch 3: 64.35 %\n",
      "Val Loss for Epoch 3: 0.6636 \n",
      "Val Accuracy for Epoch 3: 73.03 %\n",
      "--------------------------------\n",
      "Found better model...saving\n",
      "Starting epoch 5\n",
      "Train Loss for Epoch 4: 0.6619 \n",
      "Train Accuracy for Epoch 4: 75.49 %\n",
      "Val Loss for Epoch 4: 0.6518 \n",
      "Val Accuracy for Epoch 4: 79.78 %\n",
      "--------------------------------\n",
      "Found better model...saving\n",
      "Starting epoch 6\n",
      "Train Loss for Epoch 5: 0.6482 \n",
      "Train Accuracy for Epoch 5: 79.39 %\n",
      "Val Loss for Epoch 5: 0.6381 \n",
      "Val Accuracy for Epoch 5: 84.27 %\n",
      "--------------------------------\n",
      "Found better model...saving\n",
      "Starting epoch 7\n",
      "Train Loss for Epoch 6: 0.6345 \n",
      "Train Accuracy for Epoch 6: 84.40 %\n",
      "Val Loss for Epoch 6: 0.6195 \n",
      "Val Accuracy for Epoch 6: 83.15 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Found better model...saving\n",
      "Starting epoch 8\n",
      "Train Loss for Epoch 7: 0.6204 \n",
      "Train Accuracy for Epoch 7: 84.68 %\n",
      "Val Loss for Epoch 7: 0.6090 \n",
      "Val Accuracy for Epoch 7: 80.90 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Found better model...saving\n",
      "Starting epoch 9\n",
      "Train Loss for Epoch 8: 0.6026 \n",
      "Train Accuracy for Epoch 8: 87.74 %\n",
      "Val Loss for Epoch 8: 0.5898 \n",
      "Val Accuracy for Epoch 8: 87.64 %\n",
      "--------------------------------\n",
      "Found better model...saving\n",
      "Starting epoch 10\n",
      "Train Loss for Epoch 9: 0.5731 \n",
      "Train Accuracy for Epoch 9: 90.81 %\n",
      "Val Loss for Epoch 9: 0.5610 \n",
      "Val Accuracy for Epoch 9: 87.64 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Found better model...saving\n",
      "Starting epoch 11\n",
      "Train Loss for Epoch 10: 0.5507 \n",
      "Train Accuracy for Epoch 10: 89.69 %\n",
      "Val Loss for Epoch 10: 0.5295 \n",
      "Val Accuracy for Epoch 10: 91.01 %\n",
      "--------------------------------\n",
      "Starting epoch 12\n",
      "Train Loss for Epoch 11: 0.5070 \n",
      "Train Accuracy for Epoch 11: 91.92 %\n",
      "Val Loss for Epoch 11: 0.5107 \n",
      "Val Accuracy for Epoch 11: 91.01 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Found better model...saving\n",
      "Starting epoch 13\n",
      "Train Loss for Epoch 12: 0.4856 \n",
      "Train Accuracy for Epoch 12: 92.48 %\n",
      "Val Loss for Epoch 12: 0.4727 \n",
      "Val Accuracy for Epoch 12: 91.01 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Found better model...saving\n",
      "Starting epoch 14\n",
      "Train Loss for Epoch 13: 0.4429 \n",
      "Train Accuracy for Epoch 13: 93.04 %\n",
      "Val Loss for Epoch 13: 0.4622 \n",
      "Val Accuracy for Epoch 13: 84.27 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Found better model...saving\n",
      "Starting epoch 15\n",
      "Train Loss for Epoch 14: 0.4021 \n",
      "Train Accuracy for Epoch 14: 94.71 %\n",
      "Val Loss for Epoch 14: 0.4173 \n",
      "Val Accuracy for Epoch 14: 88.76 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Found better model...saving\n",
      "Starting epoch 16\n",
      "Train Loss for Epoch 15: 0.3714 \n",
      "Train Accuracy for Epoch 15: 95.82 %\n",
      "Val Loss for Epoch 15: 0.3880 \n",
      "Val Accuracy for Epoch 15: 91.01 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Found better model...saving\n",
      "Starting epoch 17\n",
      "Train Loss for Epoch 16: 0.3408 \n",
      "Train Accuracy for Epoch 16: 94.99 %\n",
      "Val Loss for Epoch 16: 0.3891 \n",
      "Val Accuracy for Epoch 16: 88.76 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Starting epoch 18\n",
      "Train Loss for Epoch 17: 0.3099 \n",
      "Train Accuracy for Epoch 17: 94.71 %\n",
      "Val Loss for Epoch 17: 0.3721 \n",
      "Val Accuracy for Epoch 17: 88.76 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Starting epoch 19\n",
      "Train Loss for Epoch 18: 0.2692 \n",
      "Train Accuracy for Epoch 18: 97.49 %\n",
      "Val Loss for Epoch 18: 0.3445 \n",
      "Val Accuracy for Epoch 18: 89.89 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Found better model...saving\n",
      "Starting epoch 20\n",
      "Train Loss for Epoch 19: 0.2516 \n",
      "Train Accuracy for Epoch 19: 96.38 %\n",
      "Val Loss for Epoch 19: 0.3198 \n",
      "Val Accuracy for Epoch 19: 92.13 %\n",
      "--------------------------------\n",
      "Starting epoch 21\n",
      "Train Loss for Epoch 20: 0.2299 \n",
      "Train Accuracy for Epoch 20: 96.94 %\n",
      "Val Loss for Epoch 20: 0.3179 \n",
      "Val Accuracy for Epoch 20: 92.13 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Starting epoch 22\n",
      "Train Loss for Epoch 21: 0.1980 \n",
      "Train Accuracy for Epoch 21: 98.05 %\n",
      "Val Loss for Epoch 21: 0.2936 \n",
      "Val Accuracy for Epoch 21: 91.01 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Found better model...saving\n",
      "Starting epoch 23\n",
      "Train Loss for Epoch 22: 0.1809 \n",
      "Train Accuracy for Epoch 22: 98.05 %\n",
      "Val Loss for Epoch 22: 0.3034 \n",
      "Val Accuracy for Epoch 22: 91.01 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Starting epoch 24\n",
      "Train Loss for Epoch 23: 0.1538 \n",
      "Train Accuracy for Epoch 23: 98.33 %\n",
      "Val Loss for Epoch 23: 0.2632 \n",
      "Val Accuracy for Epoch 23: 92.13 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Found better model...saving\n",
      "Starting epoch 25\n",
      "Train Loss for Epoch 24: 0.1323 \n",
      "Train Accuracy for Epoch 24: 99.16 %\n",
      "Val Loss for Epoch 24: 0.2674 \n",
      "Val Accuracy for Epoch 24: 89.89 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Found better model...saving\n",
      "Starting epoch 26\n",
      "Train Loss for Epoch 25: 0.1211 \n",
      "Train Accuracy for Epoch 25: 99.16 %\n",
      "Val Loss for Epoch 25: 0.3282 \n",
      "Val Accuracy for Epoch 25: 87.64 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Starting epoch 27\n",
      "Train Loss for Epoch 26: 0.1191 \n",
      "Train Accuracy for Epoch 26: 98.89 %\n",
      "Val Loss for Epoch 26: 0.2958 \n",
      "Val Accuracy for Epoch 26: 87.64 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Starting epoch 28\n",
      "Train Loss for Epoch 27: 0.1178 \n",
      "Train Accuracy for Epoch 27: 98.61 %\n",
      "Val Loss for Epoch 27: 0.2337 \n",
      "Val Accuracy for Epoch 27: 93.26 %\n",
      "--------------------------------\n",
      "Starting epoch 29\n",
      "Train Loss for Epoch 28: 0.1081 \n",
      "Train Accuracy for Epoch 28: 98.89 %\n",
      "Val Loss for Epoch 28: 0.2732 \n",
      "Val Accuracy for Epoch 28: 89.89 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Starting epoch 30\n",
      "Train Loss for Epoch 29: 0.1241 \n",
      "Train Accuracy for Epoch 29: 98.89 %\n",
      "Val Loss for Epoch 29: 0.2380 \n",
      "Val Accuracy for Epoch 29: 92.13 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Starting epoch 31\n",
      "Train Loss for Epoch 30: 0.1310 \n",
      "Train Accuracy for Epoch 30: 98.61 %\n",
      "Val Loss for Epoch 30: 0.2948 \n",
      "Val Accuracy for Epoch 30: 88.76 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Starting epoch 32\n",
      "Train Loss for Epoch 31: 0.1134 \n",
      "Train Accuracy for Epoch 31: 98.61 %\n",
      "Val Loss for Epoch 31: 0.2945 \n",
      "Val Accuracy for Epoch 31: 91.01 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Starting epoch 33\n",
      "Train Loss for Epoch 32: 0.0805 \n",
      "Train Accuracy for Epoch 32: 99.44 %\n",
      "Val Loss for Epoch 32: 0.2626 \n",
      "Val Accuracy for Epoch 32: 89.89 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Found better model...saving\n",
      "Starting epoch 34\n",
      "Train Loss for Epoch 33: 0.0696 \n",
      "Train Accuracy for Epoch 33: 99.44 %\n",
      "Val Loss for Epoch 33: 0.2325 \n",
      "Val Accuracy for Epoch 33: 92.13 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Starting epoch 35\n",
      "Train Loss for Epoch 34: 0.0787 \n",
      "Train Accuracy for Epoch 34: 98.89 %\n",
      "Val Loss for Epoch 34: 0.2859 \n",
      "Val Accuracy for Epoch 34: 91.01 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Starting epoch 36\n",
      "Train Loss for Epoch 35: 0.1126 \n",
      "Train Accuracy for Epoch 35: 97.21 %\n",
      "Val Loss for Epoch 35: 0.3587 \n",
      "Val Accuracy for Epoch 35: 88.76 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Starting epoch 37\n",
      "Train Loss for Epoch 36: 0.0906 \n",
      "Train Accuracy for Epoch 36: 98.61 %\n",
      "Val Loss for Epoch 36: 0.2884 \n",
      "Val Accuracy for Epoch 36: 91.01 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Starting epoch 38\n",
      "Train Loss for Epoch 37: 0.0663 \n",
      "Train Accuracy for Epoch 37: 98.89 %\n",
      "Val Loss for Epoch 37: 0.2811 \n",
      "Val Accuracy for Epoch 37: 88.76 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Early stopping at Epoch 37\n",
      "Training process has finished. Saving trained model.\n",
      "Starting testing\n",
      "Accuracy for fold 3: 89.89 %\n",
      "--------------------------------\n",
      "FOLD 4\n",
      "--------------------------------\n",
      "Starting epoch 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss for Epoch 0: 0.6994 \n",
      "Train Accuracy for Epoch 0: 49.03 %\n",
      "Val Loss for Epoch 0: 0.6886 \n",
      "Val Accuracy for Epoch 0: 53.93 %\n",
      "--------------------------------\n",
      "Found better model...saving\n",
      "Starting epoch 2\n",
      "Train Loss for Epoch 1: 0.6936 \n",
      "Train Accuracy for Epoch 1: 47.63 %\n",
      "Val Loss for Epoch 1: 0.6940 \n",
      "Val Accuracy for Epoch 1: 46.07 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Starting epoch 3\n",
      "Train Loss for Epoch 2: 0.6959 \n",
      "Train Accuracy for Epoch 2: 50.97 %\n",
      "Val Loss for Epoch 2: 0.6941 \n",
      "Val Accuracy for Epoch 2: 46.07 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Found better model...saving\n",
      "Starting epoch 4\n",
      "Train Loss for Epoch 3: 0.6915 \n",
      "Train Accuracy for Epoch 3: 51.53 %\n",
      "Val Loss for Epoch 3: 0.6876 \n",
      "Val Accuracy for Epoch 3: 59.55 %\n",
      "--------------------------------\n",
      "Found better model...saving\n",
      "Starting epoch 5\n",
      "Train Loss for Epoch 4: 0.6863 \n",
      "Train Accuracy for Epoch 4: 60.72 %\n",
      "Val Loss for Epoch 4: 0.6861 \n",
      "Val Accuracy for Epoch 4: 58.43 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Found better model...saving\n",
      "Starting epoch 6\n",
      "Train Loss for Epoch 5: 0.6773 \n",
      "Train Accuracy for Epoch 5: 66.85 %\n",
      "Val Loss for Epoch 5: 0.6811 \n",
      "Val Accuracy for Epoch 5: 59.55 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Found better model...saving\n",
      "Starting epoch 7\n",
      "Train Loss for Epoch 6: 0.6694 \n",
      "Train Accuracy for Epoch 6: 73.82 %\n",
      "Val Loss for Epoch 6: 0.6741 \n",
      "Val Accuracy for Epoch 6: 65.17 %\n",
      "--------------------------------\n",
      "Found better model...saving\n",
      "Starting epoch 8\n",
      "Train Loss for Epoch 7: 0.6588 \n",
      "Train Accuracy for Epoch 7: 72.42 %\n",
      "Val Loss for Epoch 7: 0.6657 \n",
      "Val Accuracy for Epoch 7: 70.79 %\n",
      "--------------------------------\n",
      "Starting epoch 9\n",
      "Train Loss for Epoch 8: 0.6447 \n",
      "Train Accuracy for Epoch 8: 75.49 %\n",
      "Val Loss for Epoch 8: 0.6582 \n",
      "Val Accuracy for Epoch 8: 67.42 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Found better model...saving\n",
      "Starting epoch 10\n",
      "Train Loss for Epoch 9: 0.6352 \n",
      "Train Accuracy for Epoch 9: 77.16 %\n",
      "Val Loss for Epoch 9: 0.6485 \n",
      "Val Accuracy for Epoch 9: 68.54 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Found better model...saving\n",
      "Starting epoch 11\n",
      "Train Loss for Epoch 10: 0.6152 \n",
      "Train Accuracy for Epoch 10: 79.11 %\n",
      "Val Loss for Epoch 10: 0.6240 \n",
      "Val Accuracy for Epoch 10: 75.28 %\n",
      "--------------------------------\n",
      "Found better model...saving\n",
      "Starting epoch 12\n",
      "Train Loss for Epoch 11: 0.5958 \n",
      "Train Accuracy for Epoch 11: 82.45 %\n",
      "Val Loss for Epoch 11: 0.6111 \n",
      "Val Accuracy for Epoch 11: 75.28 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Found better model...saving\n",
      "Starting epoch 13\n",
      "Train Loss for Epoch 12: 0.5898 \n",
      "Train Accuracy for Epoch 12: 80.22 %\n",
      "Val Loss for Epoch 12: 0.5966 \n",
      "Val Accuracy for Epoch 12: 75.28 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Starting epoch 14\n",
      "Train Loss for Epoch 13: 0.5588 \n",
      "Train Accuracy for Epoch 13: 83.01 %\n",
      "Val Loss for Epoch 13: 0.5834 \n",
      "Val Accuracy for Epoch 13: 76.40 %\n",
      "--------------------------------\n",
      "Found better model...saving\n",
      "Starting epoch 15\n",
      "Train Loss for Epoch 14: 0.5335 \n",
      "Train Accuracy for Epoch 14: 83.84 %\n",
      "Val Loss for Epoch 14: 0.5685 \n",
      "Val Accuracy for Epoch 14: 77.53 %\n",
      "--------------------------------\n",
      "Found better model...saving\n",
      "Starting epoch 16\n",
      "Train Loss for Epoch 15: 0.5089 \n",
      "Train Accuracy for Epoch 15: 87.19 %\n",
      "Val Loss for Epoch 15: 0.5440 \n",
      "Val Accuracy for Epoch 15: 78.65 %\n",
      "--------------------------------\n",
      "Found better model...saving\n",
      "Starting epoch 17\n",
      "Train Loss for Epoch 16: 0.4698 \n",
      "Train Accuracy for Epoch 16: 89.42 %\n",
      "Val Loss for Epoch 16: 0.5092 \n",
      "Val Accuracy for Epoch 16: 80.90 %\n",
      "--------------------------------\n",
      "Found better model...saving\n",
      "Starting epoch 18\n",
      "Train Loss for Epoch 17: 0.4693 \n",
      "Train Accuracy for Epoch 17: 86.91 %\n",
      "Val Loss for Epoch 17: 0.5264 \n",
      "Val Accuracy for Epoch 17: 76.40 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Starting epoch 19\n",
      "Train Loss for Epoch 18: 0.4533 \n",
      "Train Accuracy for Epoch 18: 87.74 %\n",
      "Val Loss for Epoch 18: 0.4857 \n",
      "Val Accuracy for Epoch 18: 84.27 %\n",
      "--------------------------------\n",
      "Starting epoch 20\n",
      "Train Loss for Epoch 19: 0.4443 \n",
      "Train Accuracy for Epoch 19: 87.74 %\n",
      "Val Loss for Epoch 19: 0.4825 \n",
      "Val Accuracy for Epoch 19: 79.78 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Starting epoch 21\n",
      "Train Loss for Epoch 20: 0.3962 \n",
      "Train Accuracy for Epoch 20: 91.92 %\n",
      "Val Loss for Epoch 20: 0.4541 \n",
      "Val Accuracy for Epoch 20: 78.65 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Found better model...saving\n",
      "Starting epoch 22\n",
      "Train Loss for Epoch 21: 0.3823 \n",
      "Train Accuracy for Epoch 21: 90.53 %\n",
      "Val Loss for Epoch 21: 0.4363 \n",
      "Val Accuracy for Epoch 21: 82.02 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Starting epoch 23\n",
      "Train Loss for Epoch 22: 0.3385 \n",
      "Train Accuracy for Epoch 22: 93.59 %\n",
      "Val Loss for Epoch 22: 0.4561 \n",
      "Val Accuracy for Epoch 22: 77.53 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Found better model...saving\n",
      "Starting epoch 24\n",
      "Train Loss for Epoch 23: 0.3122 \n",
      "Train Accuracy for Epoch 23: 91.09 %\n",
      "Val Loss for Epoch 23: 0.3987 \n",
      "Val Accuracy for Epoch 23: 85.39 %\n",
      "--------------------------------\n",
      "Starting epoch 25\n",
      "Train Loss for Epoch 24: 0.2762 \n",
      "Train Accuracy for Epoch 24: 93.87 %\n",
      "Val Loss for Epoch 24: 0.4289 \n",
      "Val Accuracy for Epoch 24: 84.27 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Found better model...saving\n",
      "Starting epoch 26\n",
      "Train Loss for Epoch 25: 0.2570 \n",
      "Train Accuracy for Epoch 25: 94.43 %\n",
      "Val Loss for Epoch 25: 0.3958 \n",
      "Val Accuracy for Epoch 25: 84.27 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Found better model...saving\n",
      "Starting epoch 27\n",
      "Train Loss for Epoch 26: 0.2320 \n",
      "Train Accuracy for Epoch 26: 94.43 %\n",
      "Val Loss for Epoch 26: 0.3984 \n",
      "Val Accuracy for Epoch 26: 85.39 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Starting epoch 28\n",
      "Train Loss for Epoch 27: 0.2077 \n",
      "Train Accuracy for Epoch 27: 96.38 %\n",
      "Val Loss for Epoch 27: 0.4835 \n",
      "Val Accuracy for Epoch 27: 78.65 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Found better model...saving\n",
      "Starting epoch 29\n",
      "Train Loss for Epoch 28: 0.2166 \n",
      "Train Accuracy for Epoch 28: 94.15 %\n",
      "Val Loss for Epoch 28: 0.4239 \n",
      "Val Accuracy for Epoch 28: 80.90 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Starting epoch 30\n",
      "Train Loss for Epoch 29: 0.1829 \n",
      "Train Accuracy for Epoch 29: 96.94 %\n",
      "Val Loss for Epoch 29: 0.4653 \n",
      "Val Accuracy for Epoch 29: 80.90 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Found better model...saving\n",
      "Starting epoch 31\n",
      "Train Loss for Epoch 30: 0.1881 \n",
      "Train Accuracy for Epoch 30: 95.82 %\n",
      "Val Loss for Epoch 30: 0.4745 \n",
      "Val Accuracy for Epoch 30: 79.78 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Starting epoch 32\n",
      "Train Loss for Epoch 31: 0.1721 \n",
      "Train Accuracy for Epoch 31: 96.38 %\n",
      "Val Loss for Epoch 31: 0.3889 \n",
      "Val Accuracy for Epoch 31: 86.52 %\n",
      "--------------------------------\n",
      "Starting epoch 33\n",
      "Train Loss for Epoch 32: 0.1561 \n",
      "Train Accuracy for Epoch 32: 96.38 %\n",
      "Val Loss for Epoch 32: 0.3766 \n",
      "Val Accuracy for Epoch 32: 83.15 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Starting epoch 34\n",
      "Train Loss for Epoch 33: 0.1293 \n",
      "Train Accuracy for Epoch 33: 97.77 %\n",
      "Val Loss for Epoch 33: 0.3785 \n",
      "Val Accuracy for Epoch 33: 85.39 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Found better model...saving\n",
      "Starting epoch 35\n",
      "Train Loss for Epoch 34: 0.1202 \n",
      "Train Accuracy for Epoch 34: 97.21 %\n",
      "Val Loss for Epoch 34: 0.3864 \n",
      "Val Accuracy for Epoch 34: 85.39 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Starting epoch 36\n",
      "Train Loss for Epoch 35: 0.1162 \n",
      "Train Accuracy for Epoch 35: 98.05 %\n",
      "Val Loss for Epoch 35: 0.4149 \n",
      "Val Accuracy for Epoch 35: 84.27 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Found better model...saving\n",
      "Starting epoch 37\n",
      "Train Loss for Epoch 36: 0.1602 \n",
      "Train Accuracy for Epoch 36: 95.26 %\n",
      "Val Loss for Epoch 36: 0.5478 \n",
      "Val Accuracy for Epoch 36: 78.65 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Starting epoch 38\n",
      "Train Loss for Epoch 37: 0.1200 \n",
      "Train Accuracy for Epoch 37: 97.49 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss for Epoch 37: 0.4049 \n",
      "Val Accuracy for Epoch 37: 84.27 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Starting epoch 39\n",
      "Train Loss for Epoch 38: 0.1129 \n",
      "Train Accuracy for Epoch 38: 97.21 %\n",
      "Val Loss for Epoch 38: 0.4641 \n",
      "Val Accuracy for Epoch 38: 80.90 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Starting epoch 40\n",
      "Train Loss for Epoch 39: 0.0881 \n",
      "Train Accuracy for Epoch 39: 98.05 %\n",
      "Val Loss for Epoch 39: 0.3823 \n",
      "Val Accuracy for Epoch 39: 83.15 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Starting epoch 41\n",
      "Train Loss for Epoch 40: 0.0805 \n",
      "Train Accuracy for Epoch 40: 99.16 %\n",
      "Val Loss for Epoch 40: 0.4436 \n",
      "Val Accuracy for Epoch 40: 79.78 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Found better model...saving\n",
      "Starting epoch 42\n",
      "Train Loss for Epoch 41: 0.0628 \n",
      "Train Accuracy for Epoch 41: 99.44 %\n",
      "Val Loss for Epoch 41: 0.4858 \n",
      "Val Accuracy for Epoch 41: 82.02 %\n",
      "--------------------------------\n",
      "Early Stop Count Increased\n",
      "Found better model...saving\n",
      "Early stopping at Epoch 41\n",
      "Training process has finished. Saving trained model.\n",
      "Starting testing\n",
      "Accuracy for fold 4: 84.27 %\n",
      "--------------------------------\n",
      "K-FOLD CROSS VALIDATION RESULTS FOR 5 FOLDS\n",
      "--------------------------------\n",
      "Fold 0: 93.33333333333333 %\n",
      "Fold 1: 80.0 %\n",
      "Fold 2: 78.88888888888889 %\n",
      "Fold 3: 89.88764044943821 %\n",
      "Fold 4: 84.26966292134831 %\n",
      "Average: 85.27590511860174 %\n"
     ]
    }
   ],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def evaluate():\n",
    "    avg_acc = 0\n",
    "    avg_f1 = 0\n",
    "    avg_conf = np.zeros((2,2))\n",
    "    \n",
    "    # Preparation\n",
    "    transformer = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5), (0.5)),\n",
    "    ])\n",
    "    test_data_dir = './Prepared_Data/Test/'\n",
    "    test_dataset = MyDataset(root_dir=test_data_dir, transform = transformer)\n",
    "\n",
    "    for i in range(5):\n",
    "        PATH = './Plan2_Models/best/model-fold-' + str(i) + '.pth'\n",
    "        encoder = build_encoder()\n",
    "        decoder = build_decoder()\n",
    "        trained_net = Net(encoder,decoder)\n",
    "        trained_net.load_state_dict(torch.load(PATH))\n",
    "        trained_net.to(device)\n",
    "\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        y_true, y_pred = [], []\n",
    "        testloader = torch.utils.data.DataLoader(\n",
    "            test_dataset,\n",
    "            batch_size = 50)\n",
    "\n",
    "        y_pred = []\n",
    "        y_true = []\n",
    "        with torch.no_grad():\n",
    "            # Iterate over the test data and generate predictions\n",
    "            for i, data in enumerate(testloader, 0):\n",
    "\n",
    "                # Get inputs\n",
    "                inputs = data['images']\n",
    "                targets = data['label']\n",
    "\n",
    "                outputs = None\n",
    "                for index, xbatch in enumerate(inputs):\n",
    "\n",
    "                    xbatch = xbatch.float().to(device)\n",
    "\n",
    "                    # Perform forward pass\n",
    "                    output = trained_net(xbatch)\n",
    "                    if index == 0:\n",
    "                        outputs = output\n",
    "                    else:\n",
    "                        outputs = torch.vstack([outputs, output])\n",
    "\n",
    "                # Compute loss\n",
    "                ybatches = targets.to(device)\n",
    "                outputs = torch.reshape(outputs, (ybatches.shape[0],NUM_CLASS))\n",
    "\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                _, truth = torch.max(ybatches, 1)\n",
    "                total += targets.size(0)\n",
    "                correct += (predicted == truth).sum().item()\n",
    "\n",
    "                y_pred.extend(predicted.cpu())\n",
    "                y_true.extend(truth.cpu())\n",
    "\n",
    "        # Print accuracy\n",
    "        print(\"Accuracy\", 100.0 * correct / total)\n",
    "        f1 = f1_score(y_true, y_pred, labels=[0,1], average = 'binary')\n",
    "        confusion_matr = confusion_matrix(y_true, y_pred, labels=[0,1])\n",
    "        print(\"F1\", f1)\n",
    "        print(confusion_matr)\n",
    "\n",
    "        avg_acc += 100.0 * correct / total\n",
    "        avg_f1 += f1\n",
    "        np.add(avg_conf, np.array(confusion_matr))\n",
    "\n",
    "    avg_acc = avg_acc/5\n",
    "    avg_f1 = avg_f1/5\n",
    "    np.true_divide(avg_conf, 5)\n",
    "    print(\"--------------Average------------\")\n",
    "    print('Avg Accuracy', avg_acc)\n",
    "    print('Avg F1', avg_f1)\n",
    "    print('Avg Confusion', avg_conf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 75.0\n",
      "F1 0.75\n",
      "[[24  8]\n",
      " [ 8 24]]\n",
      "Accuracy 51.5625\n",
      "F1 0.27906976744186046\n",
      "[[27  5]\n",
      " [26  6]]\n",
      "Accuracy 59.375\n",
      "F1 0.59375\n",
      "[[19 13]\n",
      " [13 19]]\n",
      "Accuracy 56.25\n",
      "F1 0.391304347826087\n",
      "[[27  5]\n",
      " [23  9]]\n",
      "Accuracy 89.0625\n",
      "F1 0.8955223880597014\n",
      "[[27  5]\n",
      " [ 2 30]]\n",
      "--------------Average------------\n",
      "Avg Accuracy 66.25\n",
      "Avg F1 0.5819293006655297\n",
      "Avg Confusion [[0. 0.]\n",
      " [0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training on Target Domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "code_folding": [
     1
    ]
   },
   "outputs": [],
   "source": [
    "# Training with Target Domain\n",
    "def train_tf():\n",
    "    #---------------Config---------------\n",
    "    torch.manual_seed(42)\n",
    "    num_epochs = 1\n",
    "    k_folds = 2\n",
    "    patience = 5\n",
    "    batch_size = 32\n",
    "    PATH = './models/model-fold-' + str(0) + '.pth'\n",
    "    #---------------Config---------------\n",
    "    \n",
    "    # Preparation\n",
    "    weight = torch.tensor([1,1]).to(device)\n",
    "    \n",
    "    loss_function = nn.BCELoss(weight=weight)\n",
    "\n",
    "    transformer = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5), (0.5)),\n",
    "    ])\n",
    "\n",
    "    train_data_dir = './Prepared_Data/Train/'\n",
    "    train_dataset = MyDataset(root_dir=train_data_dir, transform = transformer)\n",
    "\n",
    "    test_data_dir = './Prepared_Data/Test/'\n",
    "    test_dataset = MyDataset(root_dir=test_data_dir, transform = transformer)\n",
    "\n",
    "    val_data_dir = './Prepared_Data/Validation/'\n",
    "    val_dataset = MyDataset(root_dir=val_data_dir, transform = transformer)\n",
    "\n",
    "    dataset = ConcatDataset([train_dataset, val_dataset])\n",
    "\n",
    "    kfold = KFold(n_splits=k_folds, shuffle=True)\n",
    "    \n",
    "    results = {}\n",
    "\n",
    "    # K-fold Cross Validation model evaluation\n",
    "    for fold, (train_ids, val_ids) in enumerate(kfold.split(dataset)):\n",
    "        training_details = []\n",
    "        best_model = None\n",
    "\n",
    "        # Print\n",
    "        print(f'FOLD {fold}')\n",
    "        print('--------------------------------')\n",
    "\n",
    "        # Sample elements randomly from a given list of ids, no replacement.\n",
    "        train_subsampler = torch.utils.data.SubsetRandomSampler(train_ids)\n",
    "        val_subsampler = torch.utils.data.SubsetRandomSampler(val_ids)\n",
    "\n",
    "        # Define data loaders for training and testing data in this fold\n",
    "        trainloader = torch.utils.data.DataLoader(\n",
    "                        dataset,\n",
    "                        batch_size=batch_size, sampler=train_subsampler)\n",
    "        valloader = torch.utils.data.DataLoader(\n",
    "                        dataset,\n",
    "                        batch_size=batch_size, sampler=val_subsampler)\n",
    "\n",
    "        # Init the neural network\n",
    "        encoder = build_encoder()\n",
    "        decoder = build_decoder()\n",
    "        network = Net(encoder,decoder)\n",
    "        network.load_state_dict(torch.load(PATH))\n",
    "        for param in network.in_encoder.parameters():\n",
    "            param.requires_grad = False\n",
    "        network.to(device) #use GPU\n",
    "        use_gpu = True\n",
    "\n",
    "        # Initialize optimizer\n",
    "        optimizer = optim.Adam(network.parameters(), lr=0.001)\n",
    "        max_train_acc, max_val_acc = 0, 0\n",
    "        early_stop_count = 0\n",
    "        # Run the training loop for defined number of epochs\n",
    "        for epoch in range(0, num_epochs):\n",
    "\n",
    "            correct, total = 0, 0\n",
    "            # Print epoch\n",
    "            print(f'Starting epoch {epoch+1}')\n",
    "            # Set current loss value\n",
    "            current_loss = 0.0\n",
    "            epoch_loss = 0.0\n",
    "            # Iterate over the DataLoader for training data\n",
    "            for i, data in enumerate(trainloader, 0):\n",
    "            # Starting 1 cycle of mini-batch\n",
    "\n",
    "                # Get inputs\n",
    "                inputs = data['images']\n",
    "                targets = data['label']\n",
    "\n",
    "                outputs = None\n",
    "                for index, xbatch in enumerate(inputs):\n",
    "                    # Zero the gradients\n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "                    xbatch = xbatch.float() .to(device)\n",
    "\n",
    "                    # Perform forward pass\n",
    "                    output = network(xbatch)\n",
    "                    if index == 0:\n",
    "                        outputs = output\n",
    "                    else:\n",
    "                        outputs = torch.vstack([outputs, output])\n",
    "\n",
    "                # Compute loss\n",
    "                ybatches = targets.to(device)\n",
    "                outputs = torch.reshape(outputs, (ybatches.shape[0],NUM_CLASS))\n",
    "                loss = loss_function(outputs, ybatches)\n",
    "\n",
    "                # Perform backward pass\n",
    "                loss.backward()\n",
    "\n",
    "                # Perform optimization\n",
    "                optimizer.step()\n",
    "\n",
    "                # Print statistics\n",
    "                current_loss += loss.item()\n",
    "                epoch_loss += loss.item()\n",
    "\n",
    "                # Compute Accuracy\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                _, truth = torch.max(ybatches, 1)\n",
    "                total += targets.size(0)\n",
    "                correct += (predicted == truth).sum().item()\n",
    "\n",
    "            epoch_loss = epoch_loss/(i+1)\n",
    "            epoch_acc = 100.0 * correct / total\n",
    "            print('Train Loss for Epoch %d: %.4f ' % (epoch, epoch_loss))\n",
    "            print('Train Accuracy for Epoch %d: %.2f %%' % (epoch, epoch_acc))\n",
    "            val_loss, val_acc = check_validation(network.state_dict(), valloader, loss_function)\n",
    "            print('Val Loss for Epoch %d: %.4f ' % (epoch, val_loss))\n",
    "            print('Val Accuracy for Epoch %d: %.2f %%' % (epoch, val_acc))\n",
    "            print('--------------------------------')\n",
    "\n",
    "            training_details.append([epoch_acc, epoch_loss, val_acc, val_loss])\n",
    "\n",
    "            stop_improving = False\n",
    "            if val_acc > max_val_acc:\n",
    "                max_val_acc = val_acc\n",
    "                early_stop_count = 0\n",
    "            else:\n",
    "                early_stop_count += 1\n",
    "                stop_improving = True\n",
    "                print(\"Early Stop Count Increased\")\n",
    "\n",
    "            if epoch_acc > max_train_acc:\n",
    "                max_train_acc = copy.deepcopy(epoch_acc)\n",
    "                best_model = copy.deepcopy(network.state_dict())\n",
    "                print(\"Found better model...saving\")\n",
    "\n",
    "            if early_stop_count >= patience:\n",
    "                print(\"Early stopping at Epoch\", epoch)\n",
    "                break\n",
    "\n",
    "\n",
    "        # Process is complete.\n",
    "        print('Training process has finished. Saving trained model.')\n",
    "\n",
    "        # Print about testing\n",
    "        print('Starting testing')\n",
    "\n",
    "        # Saving the model\n",
    "        save_path = f'./models_tf/model-fold-{fold}.pth'\n",
    "        save_path_csv = f'./models_tf/model-fold-{fold}.csv'\n",
    "        torch.save(best_model, save_path)\n",
    "\n",
    "        training_details = np.array(training_details)\n",
    "        df = {'epoch acc': training_details[:,0], \n",
    "              'epoch loss': training_details[:,1], \n",
    "              'val acc': training_details[:,2], \n",
    "              'val loss': training_details[:,3], }\n",
    "        pd.DataFrame(df).to_csv(save_path_csv)\n",
    "\n",
    "        # Evaluationfor this fold\n",
    "        correct, total = 0, 0\n",
    "        with torch.no_grad():\n",
    "            val_loss, val_acc = check_validation(torch.load(save_path), valloader, loss_function)\n",
    "            # Print accuracy\n",
    "            print('Accuracy for fold %d: %.2f %%' % (fold, val_acc))\n",
    "            print('--------------------------------')\n",
    "            results[fold] = val_acc\n",
    "\n",
    "    # Print fold results\n",
    "    print(f'K-FOLD CROSS VALIDATION RESULTS FOR {k_folds} FOLDS')\n",
    "    print('--------------------------------')\n",
    "    sum = 0.0\n",
    "    for key, value in results.items():\n",
    "        print(f'Fold {key}: {value} %')\n",
    "        sum += value\n",
    "    print(f'Average: {sum/len(results.items())} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "--------------------------------\n",
      "Starting epoch 1\n",
      "Train Loss for Epoch 0: 0.6877 \n",
      "Train Accuracy for Epoch 0: 57.14 %\n",
      "Val Loss for Epoch 0: 0.6939 \n",
      "Val Accuracy for Epoch 0: 44.64 %\n",
      "--------------------------------\n",
      "Found better model...saving\n",
      "Training process has finished. Saving trained model.\n",
      "Starting testing\n",
      "Accuracy for fold 0: 44.64 %\n",
      "--------------------------------\n",
      "FOLD 1\n",
      "--------------------------------\n",
      "Starting epoch 1\n",
      "Train Loss for Epoch 0: 0.6944 \n",
      "Train Accuracy for Epoch 0: 50.45 %\n",
      "Val Loss for Epoch 0: 0.6920 \n",
      "Val Accuracy for Epoch 0: 52.23 %\n",
      "--------------------------------\n",
      "Found better model...saving\n",
      "Training process has finished. Saving trained model.\n",
      "Starting testing\n",
      "Accuracy for fold 1: 48.66 %\n",
      "--------------------------------\n",
      "K-FOLD CROSS VALIDATION RESULTS FOR 2 FOLDS\n",
      "--------------------------------\n",
      "Fold 0: 44.642857142857146 %\n",
      "Fold 1: 48.660714285714285 %\n",
      "Average: 46.651785714285715 %\n"
     ]
    }
   ],
   "source": [
    "train_tf()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
